{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === **Simulated Annealing (SA) for Feature Selection to optimize feature subsets for various ML classifiers** ===\n",
    "---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Stable Feature Pre-selection:**\n",
    "\n",
    "* Performed initial feature selection using **bootstrapped LASSO logistic regression** (`penalty='l1'`, `solver='liblinear'`, `cv=5`, `max_iter=5000`), repeated for **100 bootstrap samples** (`n_bootstrap=100`). Features were retained if selected in **≥70%** of bootstraps (`freq_threshold=0.7`), ensuring stability against sampling variance.\n",
    "\n",
    "\n",
    "**2. Metaheuristic Feature Selection:**\n",
    "\n",
    "* Applies **Particle Swarm Optimization (PSO)** for further feature selection from the stable set, using a population of **20 particles** (`n_particles=20`) and **50 iterations** (`max_iter=50`). Each particle represented a binary feature mask, and the swarm was optimized to maximize mean ROC AUC over 5-fold stratified cross-validation (`StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`).\n",
    "\n",
    "\n",
    "**3. Comprehensive Classifier Comparison:**\n",
    "\n",
    "* Evaluated a broad suite of classifiers:\n",
    "\n",
    "  * **Logistic Regression** (`max_iter=1000`), with grid search over `C=[0.001, 0.01, 0.1, 1, 10]` and `penalty=['l1', 'l2']`\n",
    "\n",
    "  * **Gaussian Naive Bayes** (default parameters)\n",
    "\n",
    "  * **Support Vector Machines** (linear and RBF kernels, `C=[0.01, 0.1, 1, 10]`, `gamma=['scale', 'auto']`)\n",
    "\n",
    "  * **Decision Tree** (`max_depth=[3, 5, 7]`, `min_samples_split=[5, 10]`, `min_samples_leaf=[2, 4]`)\n",
    "\n",
    "  * **Random Forest** (`n_estimators=[100, 200]`, `max_depth=[5, 10]`, `min_samples_split=[5, 10]`, `min_samples_leaf=[2, 4]`)\n",
    "\n",
    "  * **VotingClassifier** ensemble combining top-tuned base models with soft voting.\n",
    "\n",
    "* Hyperparameters were tuned for each classifier using **GridSearchCV** and 5-fold stratified cross-validation, optimizing for ROC AUC.\n",
    "\n",
    "\n",
    "**4. Class Imbalance and Data Integrity Handling:**\n",
    "\n",
    "* Maintained **class distribution balance** in all data splits using stratified sampling, both in train/test partitioning (`test_size=0.2`) and during cross-validation.\n",
    "\n",
    "* For bootstrapping and CI estimation, ensured that each resample included both classes—skipping samples otherwise to avoid invalid AUC calculations.\n",
    "\n",
    "\n",
    "**5. Feature Scaling and Pipeline Safety:**\n",
    "\n",
    "* Applied **feature standardization** (`StandardScaler()`) within all pipelines, fitting scalers only on training data to prevent information leakage.\n",
    "\n",
    "* Model pipelines (`make_pipeline(StandardScaler(), classifier)`) ensured consistent preprocessing during evaluation and prediction.\n",
    "\n",
    "\n",
    "**6. Model Evaluation & Uncertainty Quantification:**\n",
    "\n",
    "* Reported **ROC AUC and accuracy** for both training and testing sets at each PSO iteration.\n",
    "\n",
    "* Computed **bootstrapped confidence intervals** for test AUC (`n_bootstrap=1000`, `ci=0.95`), resampling test predictions to quantify model uncertainty and generalization performance.\n",
    "\n",
    "\n",
    "**7. Visualization and Monitoring:**\n",
    "\n",
    "* Plotted **train/test AUC trends** across PSO iterations for convergence analysis.\n",
    "\n",
    "* Displayed final **ROC curves** for both training and testing sets, including mean AUC and 95% confidence intervals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === IMPORTS ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                                            # Core numerical computation library for arrays and matrix operations\n",
    "import pandas as pd                                                                           # Library for data manipulation and analysis (tabular data, DataFrames)\n",
    "from sklearn.base import clone                                                                # For cloning estimators (useful when building pipelines or doing cross-validation)\n",
    "import matplotlib.pyplot as plt                                                               # For plotting graphs (e.g., ROC curves, feature importances, etc.)\n",
    "from scipy.stats import bootstrap                                                             # For statistical bootstrap resampling (scipy's bootstrap is for CI, sklearn's resample for random sampling)\n",
    "from sklearn.utils import resample                                                            # Utility to randomly resample datasets (e.g., for bootstrapping in ML)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold        # For splitting data, cross-validation, and stratified folds (for imbalanced classes)\n",
    "from sklearn.preprocessing import StandardScaler                                              # For scaling features to zero mean/unit variance (important for many ML algorithms)\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score                          # For evaluating model performance: ROC AUC, ROC curve points, accuracy\n",
    "from collections import Counter\n",
    "\n",
    "# === CLASSIFIERS ===\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB                                                    # Naive Bayes classifier for classification tasks\n",
    "from sklearn.svm import SVC                                                                   # Support Vector Classifier (linear & nonlinear SVMs)\n",
    "from sklearn.tree import DecisionTreeClassifier                                               # Decision Tree classifier (nonlinear, interpretable ML model)\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier                         # Random Forest classifier (ensemble of Decision Trees)\n",
    "from sklearn.pipeline import make_pipeline                                                    # For creating machine learning pipelines (combining preprocessing + models)\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV                     # Logistic Regression (standard and cross-validated, for classification)\n",
    "\n",
    "# === GRID SEARCH HYPERPARAMETER TUNING ===\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV                                              # For exhaustive grid search over hyperparameters with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === LOAD AND PREPROCESS DATA ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Load radiomics and clinical CSV files into DataFrames\n",
    "    radiomics = pd.read_csv(\"./HNC-Prospective-Radiomics-305.csv\")\n",
    "    clinical = pd.read_csv(\"./proceed_radiomics_166.csv\")\n",
    "\n",
    "    print(f\"Initial clinical data: {len(clinical)} patients\")\n",
    "    # print(f\"Unique locations in clinical data: {clinical['Location'].value_counts()}\")\n",
    "\n",
    "    # Filter clinical data to only include specific tumor locations\n",
    "    # clinical = clinical[clinical[\"Location\"].isin(['Larynx', 'Tonsil', 'Hypopharynx', 'Oropharynx', 'BOT', 'Other'])]\n",
    "    # print(f\"After location filtering: {len(clinical)} patients\")\n",
    "\n",
    "    # Standardize 'research_subject_uid' in radiomics by keeping only the part before \"_\"\n",
    "    radiomics[\"research_subject_uid\"] = radiomics[\"research_subject_uid\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "    # Remove any leading/trailing spaces from 'Project ID' in clinical data\n",
    "    clinical[\"Project ID\"] = clinical[\"Project ID\"].str.strip()\n",
    "\n",
    "    # Filter radiomics to only keep rows with research_subject_uid present in clinical Project IDs\n",
    "    radiomics_filtered = radiomics[radiomics[\"research_subject_uid\"].isin(clinical[\"Project ID\"])]\n",
    "    \n",
    "    # Filter clinical to only keep rows with Project ID present in radiomics research_subject_uid\n",
    "    clinical_filtered = clinical[clinical[\"Project ID\"].isin(radiomics[\"research_subject_uid\"])]\n",
    "\n",
    "    print(f\"Final matched data: {len(clinical_filtered)} patients\")\n",
    "\n",
    "    # Sort both DataFrames by their ID columns and reset their indices\n",
    "    radiomics_filtered = radiomics_filtered.sort_values(by=\"research_subject_uid\").reset_index(drop=True)\n",
    "    clinical_filtered = clinical_filtered.sort_values(by=\"Project ID\").reset_index(drop=True)\n",
    "\n",
    "    # Return the filtered and aligned DataFrames for further processing\n",
    "    return radiomics_filtered, clinical_filtered\n",
    "\n",
    "\n",
    "def get_radiomics_columns(data):\n",
    "    \"\"\"\n",
    "    Returns the columns from 'original_shape_Elongation' to 'original_ngtdm_Strength'.\n",
    "    These typically represent the set of radiomics features you want to extract.\n",
    "    \"\"\"\n",
    "    start_column = \"original_shape_Elongation\"\n",
    "    end_column = \"original_ngtdm_Strength\"\n",
    "    start_idx = data.columns.get_loc(start_column)\n",
    "    end_idx = data.columns.get_loc(end_column) + 1  # +1 to include the end column itself\n",
    "    return data.columns[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Define hyperparameter grids for each classifier ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These grids help tune the model to avoid overfitting by optimizing regularization and other key parameters.\n",
    "all_grid_params = {\n",
    "    'LogisticRegression': {\n",
    "        'C': [1e-3, 3e-3, 1e-2, 3e-2, 0.1, 0.3, 1, 3, 10],          # Regularization strength (lower = stronger regularization)\n",
    "        'penalty': ['l1', 'l2'],                                                # Type of regularization: L1 (Lasso), L2 (Ridge)\n",
    "        'solver': ['liblinear'],                                                # Solver that supports both l1 and l2\n",
    "        'class_weight': [None, \"balanced\"],\n",
    "        'max_iter': [1000],\n",
    "    },\n",
    "    'GaussianNB': {},                                                           # No tunable hyperparameters for basic Naive Bayes\n",
    "    'SVC': [\n",
    "        # Linear SVC\n",
    "        {\n",
    "            'C': [1e-3, 1e-2, 0.1, 1, 10],                                      # Regularization strength\n",
    "            'kernel': ['linear'],                                               # Linear kernel\n",
    "            'probability': [True],                                              # Needed for probability predictions (e.g., ROC AUC)\n",
    "            'class_weight': [None, \"balanced\"],\n",
    "        },\n",
    "        # RBF SVC\n",
    "        {\n",
    "            'C': [1e-3, 1e-2, 0.1, 1, 10],                                      # Regularization strength\n",
    "            'gamma': ['scale', 'auto', 1e-3, 1e-2, 1e-1],                       # Kernel coefficient for RBF\n",
    "            'kernel': ['rbf'],                                                  # RBF (nonlinear) kernel\n",
    "            'probability': [True],                                              # Probability estimates\n",
    "            'class_weight': [None, \"balanced\"],\n",
    "        }\n",
    "    ],\n",
    "    'DecisionTreeClassifier': {\n",
    "        'criterion': ['gini', 'entropy'],                                       # Split quality metric\n",
    "        'max_depth': [2, 3, 4, 5, 7],                                           # Controls tree depth (regularization)\n",
    "        'min_samples_split': [5, 10, 15],                                       # Minimum samples required to split a node\n",
    "        'min_samples_leaf': [2, 4, 6],                                          # Minimum samples per leaf node\n",
    "        'max_features': ['sqrt', 'log2', None],                                 # Number of features considered at each split\n",
    "        'class_weight': [None, \"balanced\"],\n",
    "        'random_state': [42],\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [100, 200, 400],                                        # Number of trees\n",
    "        'max_depth': [3, 5, 7, 10],                                             # Maximum depth of trees\n",
    "        'min_samples_split': [5, 10],                                           # Minimum samples to split an internal node\n",
    "        'min_samples_leaf': [2, 4],                                             # Minimum samples at a leaf node\n",
    "        'max_features': ['sqrt', 'log2'],                                       # Number of features considered at each split\n",
    "        'bootstrap': [True],                                                    # Use bootstrap samples\n",
    "        'n_jobs': [-1],                                                         # Use all available CPU cores for parallel processing\n",
    "        'class_weight': [None, \"balanced\", \"balanced_subsample\"],\n",
    "        'random_state': [42],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# === Utility function to tune a classifier's hyperparameters using grid search and cross-validation ===\n",
    "\n",
    "def get_tuned_model(classifier, X_train, y_train):\n",
    "    name = classifier.__class__.__name__                                 # Get class name as a string (e.g., 'LogisticRegression')\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)      # 5-fold stratified cross-validation\n",
    "    \n",
    "    # Special handling for SVC as its grid is a list (to support both linear & RBF kernels)\n",
    "    if name == 'SVC':\n",
    "        grid = GridSearchCV(\n",
    "            clone(classifier),            # Clone base estimator to avoid data leakage between folds\n",
    "            all_grid_params['SVC'],\n",
    "            scoring='roc_auc',            # Use ROC AUC for model selection (works for imbalanced data)\n",
    "            cv=cv,                        # Use stratified k-fold\n",
    "            n_jobs=-1,                    # Use all CPU cores\n",
    "            refit=True,\n",
    "        )\n",
    "        grid.fit(X_train, y_train)       # Fit grid search\n",
    "        return grid.best_estimator_      # Return the model with best hyperparameters\n",
    "\n",
    "    # For all other classifiers with defined grid parameters\n",
    "    elif name in all_grid_params and all_grid_params[name]:\n",
    "        grid = GridSearchCV(\n",
    "            clone(classifier),\n",
    "            all_grid_params[name],\n",
    "            scoring='roc_auc',\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "            refit=True,\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        return grid.best_estimator_\n",
    "\n",
    "    # If no hyperparameters to tune (e.g., GaussianNB), return the original classifier\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === BOOTSTRAP LASSO FEATURE SELECTION ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_lasso_fs(X, y, n_bootstrap=1000, freq_threshold=0.5, random_state=42):\n",
    "    \"\"\"\n",
    "    Selects stable features using bootstrapped Lasso logistic regression.\n",
    "    - X: feature matrix (numpy array)\n",
    "    - y: target labels\n",
    "    - n_bootstrap: number of bootstrap samples to draw\n",
    "    - freq_threshold: minimum frequency for a feature to be considered stable\n",
    "    - random_state: for reproducibility\n",
    "\n",
    "    Returns the indices of stable features.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    selected_counts = np.zeros(X.shape[1])  # To count selection frequency for each feature\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        # Resample data with replacement (bootstrapping), stratified by class\n",
    "        X_resampled, y_resampled = resample(X, y, stratify=y, random_state=random_state+i)\n",
    "\n",
    "        # L1-penalized logistic regression with cross-validation for feature selection\n",
    "        model = LogisticRegressionCV(\n",
    "            penalty='l1',\n",
    "            solver='liblinear',\n",
    "            cv=5,\n",
    "            scoring='roc_auc',\n",
    "            max_iter=10000,\n",
    "            tol=1e-3,       # Slightly relaxed tolerance\n",
    "            random_state=random_state+i\n",
    "        ).fit(X_resampled, y_resampled)\n",
    "        # Count features selected (non-zero coefficient means selected)\n",
    "        selected_counts += (model.coef_[0] != 0).astype(int)\n",
    "\n",
    "    # Calculate frequency of each feature being selected across bootstraps\n",
    "    selected_frequency = selected_counts / n_bootstrap\n",
    "    \n",
    "    # Select features whose selection frequency >= threshold\n",
    "    stable_features_idx = np.where(selected_frequency >= freq_threshold)[0]\n",
    "\n",
    "    print(f\"Stable features (freq >= {freq_threshold}): {stable_features_idx}\")\n",
    "    return stable_features_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === SA Feature Selection ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CORRECTED EVALUATE_FITNESS FOR SA \n",
    "# ==========================================\n",
    "\n",
    "def evaluate_fitness(solution, X, y, model, random_state=42):\n",
    "    \"\"\"\n",
    "    CORRECTED: Evaluates fitness using FRESH CV splits each time.\n",
    "    Same corrected approach as PSO/WOA/GWO - uses cross-validation on training data only.\n",
    "    \n",
    "    CRITICAL FIXES:\n",
    "    1. Uses CV on training data only (not train/test split)\n",
    "    2. Creates fresh StratifiedKFold for each evaluation\n",
    "    3. Handles edge cases properly\n",
    "    4. Consistent with PSO/WOA/GWO methodology\n",
    "    \n",
    "    Parameters:\n",
    "    - solution: binary vector (1: feature selected, 0: not selected)\n",
    "    - X: training feature matrix (numpy array)\n",
    "    - y: training target labels (numpy array) \n",
    "    - model: classifier to use\n",
    "    - random_state: for reproducible CV splits\n",
    "\n",
    "    Returns: Mean ROC AUC from cross-validation on selected features.\n",
    "    \"\"\"\n",
    "    selected_features = np.count_nonzero(solution)\n",
    "    \n",
    "    # Handle edge cases (same as PSO/WOA/GWO)\n",
    "    if selected_features == 0:\n",
    "        return 0.0\n",
    "    elif selected_features == 1:\n",
    "        return 0.5  # Single feature rarely gives good AUC\n",
    "    elif selected_features == len(solution):\n",
    "        return 0.6  # Penalize selecting all features\n",
    "    \n",
    "    # Select features\n",
    "    X_selected = X[:, solution == 1]\n",
    "    \n",
    "    try:\n",
    "        # CRITICAL FIX: Create FRESH CV splits each time (same as other algorithms)\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        \n",
    "        scores = cross_val_score(\n",
    "            clone(model), X_selected, y, \n",
    "            cv=cv, scoring='roc_auc', n_jobs=1\n",
    "        )\n",
    "        \n",
    "        # Check for invalid scores\n",
    "        if np.any(np.isnan(scores)) or len(scores) == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        return np.mean(scores)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: CV failed for {selected_features} features: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === SA Model for Feature Selection ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CORRECTED RUN_SA FUNCTION\n",
    "# ==========================================\n",
    "\n",
    "def run_sa(X_train, y_train, X_val, y_val, classifier, \n",
    "           n_iter=1000, initial_temp=100, cooling_rate=0.95, verbose=True):\n",
    "    \"\"\"\n",
    "    CORRECTED Simulated Annealing for feature selection.\n",
    "    \n",
    "    CRITICAL FIXES:\n",
    "    1. Uses corrected evaluate_fitness with CV on training data only\n",
    "    2. Proper random state management\n",
    "    3. Enhanced progress tracking and convergence monitoring\n",
    "    4. Consistent methodology with PSO/WOA/GWO\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train, X_val: Feature matrices (training and validation)\n",
    "    - y_train, y_val: Target labels (training and validation)\n",
    "    - classifier: classifier to use\n",
    "    - n_iter: number of iterations\n",
    "    - initial_temp: starting temperature\n",
    "    - cooling_rate: temperature reduction factor\n",
    "    - verbose: Print progress updates\n",
    "    \n",
    "    Returns: best_solution, train_auc_history, val_auc_history\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_auc_scores(X_train_sel, X_val_sel):\n",
    "        \"\"\"Compute AUC scores for selected features on train and validation sets.\"\"\"\n",
    "        temp_model = clone(classifier)\n",
    "        temp_model.fit(X_train_sel, y_train)\n",
    "        \n",
    "        # Get probabilities or decision scores\n",
    "        if hasattr(temp_model, 'predict_proba'):\n",
    "            y_train_proba = temp_model.predict_proba(X_train_sel)[:, 1]\n",
    "            y_val_proba = temp_model.predict_proba(X_val_sel)[:, 1]\n",
    "        else:\n",
    "            y_train_proba = temp_model.decision_function(X_train_sel)\n",
    "            y_val_proba = temp_model.decision_function(X_val_sel)\n",
    "        \n",
    "        train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "        val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "        return train_auc, val_auc\n",
    "    \n",
    "    n_features = X_train.shape[1]\n",
    "    \n",
    "    # Initialize solution with reasonable feature selection probability\n",
    "    current_solution = (np.random.rand(n_features) < 0.3).astype(int)\n",
    "    if np.sum(current_solution) == 0:\n",
    "        current_solution[np.random.randint(n_features)] = 1\n",
    "    \n",
    "    best_solution = current_solution.copy()\n",
    "    \n",
    "    # CORRECTED: Use CV-based fitness evaluation\n",
    "    current_score = evaluate_fitness(current_solution, X_train, y_train, classifier, random_state=42)\n",
    "    best_score = current_score\n",
    "    temperature = initial_temp\n",
    "\n",
    "    # Tracking variables\n",
    "    fitness_history = [current_score]\n",
    "    train_auc_history = []\n",
    "    val_auc_history = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Starting SA with {n_iter} iterations, initial temp: {initial_temp}\")\n",
    "        print(f\"Initial fitness: {current_score:.4f} with {np.sum(current_solution)} features\")\n",
    "\n",
    "    for iteration in range(n_iter):\n",
    "        # Generate neighbor solution by flipping one bit\n",
    "        neighbor = current_solution.copy()\n",
    "        idx = np.random.randint(n_features)\n",
    "        neighbor[idx] = 1 - neighbor[idx]\n",
    "        \n",
    "        # Ensure at least one feature is selected\n",
    "        if np.sum(neighbor) == 0:\n",
    "            neighbor[np.random.randint(n_features)] = 1\n",
    "\n",
    "        # CRITICAL: Use corrected fitness evaluation with unique random state\n",
    "        neighbor_score = evaluate_fitness(\n",
    "            neighbor, X_train, y_train, classifier, \n",
    "            random_state=42 + iteration\n",
    "        )\n",
    "\n",
    "        # Acceptance probability\n",
    "        if neighbor_score > current_score:\n",
    "            accept = True\n",
    "        else:\n",
    "            if temperature > 0:\n",
    "                delta = neighbor_score - current_score\n",
    "                accept = np.random.rand() < np.exp(delta / temperature)\n",
    "            else:\n",
    "                accept = False\n",
    "\n",
    "        if accept:\n",
    "            current_solution = neighbor\n",
    "            current_score = neighbor_score\n",
    "            if current_score > best_score:\n",
    "                best_score = current_score\n",
    "                best_solution = current_solution.copy()\n",
    "\n",
    "        fitness_history.append(current_score)\n",
    "        \n",
    "        # Compute train/val AUC for monitoring (separate from fitness)\n",
    "        if np.sum(best_solution) > 0:\n",
    "            X_train_sel = X_train[:, best_solution == 1]\n",
    "            X_val_sel = X_val[:, best_solution == 1]\n",
    "            \n",
    "            try:\n",
    "                # Apply scaling for monitoring AUC calculation\n",
    "                scaler = StandardScaler()\n",
    "                X_train_sel_scaled = scaler.fit_transform(X_train_sel)\n",
    "                X_val_sel_scaled = scaler.transform(X_val_sel)\n",
    "                \n",
    "                train_auc, val_auc = compute_auc_scores(X_train_sel_scaled, X_val_sel_scaled)\n",
    "                train_auc_history.append(train_auc)\n",
    "                val_auc_history.append(val_auc)\n",
    "                \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"Warning: Could not compute monitoring AUC at iteration {iteration+1}: {e}\")\n",
    "                train_auc_history.append(None)\n",
    "                val_auc_history.append(None)\n",
    "        else:\n",
    "            train_auc_history.append(None)\n",
    "            val_auc_history.append(None)\n",
    "\n",
    "        # Cool down temperature\n",
    "        temperature *= cooling_rate\n",
    "        \n",
    "        # Progress reporting\n",
    "        if verbose and (iteration + 1) % 200 == 0:\n",
    "            current_train_auc = train_auc_history[-1] if train_auc_history[-1] is not None else 0\n",
    "            current_val_auc = val_auc_history[-1] if val_auc_history[-1] is not None else 0\n",
    "            n_features_selected = int(np.sum(best_solution))\n",
    "            \n",
    "            print(f\"Iteration {iteration+1:4d}/{n_iter} - Best Fitness: {best_score:.4f}, \"\n",
    "                  f\"Train AUC: {current_train_auc:.4f}, Val AUC: {current_val_auc:.4f}, \"\n",
    "                  f\"Features: {n_features_selected:3d}, Temp: {temperature:.2f}\")\n",
    "\n",
    "    if verbose:\n",
    "        n_selected = int(np.sum(best_solution))\n",
    "        print(f\"SA completed! Best fitness (CV AUC): {best_score:.4f} with {n_selected} features\")\n",
    "\n",
    "    return best_solution, train_auc_history, val_auc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Evaluate model with classifier function ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_classifier(X_train, X_test, y_train, y_test, selected_features, feature_names, classifier):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a given classifier using only the features selected by a feature selection algorithm.\n",
    "    Prints Train/Test AUC and Accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train, X_test: Feature matrices (numpy arrays)\n",
    "        y_train, y_test: Labels\n",
    "        selected_features: Binary vector indicating which features to use\n",
    "        feature_names: List of feature names (not used here, but useful for further reporting)\n",
    "        classifier: Classifier instance (e.g., LogisticRegression)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select only the features chosen by the feature selection mask\n",
    "    X_train_sel = X_train[:, selected_features == 1]\n",
    "    X_test_sel = X_test[:, selected_features == 1]\n",
    "\n",
    "    # If no features were selected, print a warning and stop\n",
    "    if X_train_sel.shape[1] == 0:\n",
    "        print(\"\\n⚠️ No features selected. Cannot train classifier.\")\n",
    "        return\n",
    "\n",
    "    # Build pipeline: scale features then fit classifier\n",
    "    model = make_pipeline(StandardScaler(), classifier)\n",
    "    model.fit(X_train_sel, y_train)  # Train the model on selected features\n",
    "\n",
    "    # Get predicted probabilities or decision function for AUC\n",
    "    y_train_proba = model.predict_proba(X_train_sel)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_train_sel)\n",
    "    y_test_proba = model.predict_proba(X_test_sel)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_test_sel)\n",
    "\n",
    "    # Get predicted labels for accuracy\n",
    "    y_train_pred = model.predict(X_train_sel)\n",
    "    y_test_pred = model.predict(X_test_sel)\n",
    "\n",
    "    # Print evaluation metrics for train and test sets\n",
    "    print(f\"\\n✅ Results for {classifier.__class__.__name__}:\")\n",
    "    print(f\"Train AUC: {roc_auc_score(y_train, y_train_proba):.4f}\")\n",
    "    print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "    print(f\"Test AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Computes a bootstrapped confidence interval for ROC AUC of the final model ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_final_model_auc_ci(\n",
    "    y_true,\n",
    "    y_pred_proba,\n",
    "    n_bootstrap: int = 1000,\n",
    "    ci: float = 0.95,\n",
    "    random_state: int = 42,\n",
    "    min_valid: int = 200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Stratified bootstrap CI for ROC AUC on small/imbalanced test sets.\n",
    "    - Preserves class counts in each bootstrap sample (positives/negatives drawn separately).\n",
    "    - Avoids invalid replicates with a single class.\n",
    "    - Returns mean AUC and (lower, upper) percentile CI.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        True binary labels. If not exactly {0,1}, they will be remapped to {0,1} by ordering.\n",
    "    y_pred_proba : array-like\n",
    "        Predicted probabilities or decision scores (higher = more likely positive).\n",
    "    n_bootstrap : int, default=2000\n",
    "        Number of bootstrap replicates.\n",
    "    ci : float, default=0.95\n",
    "        Confidence level (e.g., 0.95 for 95% CI).\n",
    "    random_state : int, default=42\n",
    "        Seed for reproducibility.\n",
    "    min_valid : int, default=200\n",
    "        Minimum recommended number of valid bootstrap replicates for a stable CI.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean_auc : float\n",
    "    lower : float\n",
    "    upper : float\n",
    "    valid : int\n",
    "        Number of valid bootstrap replicates used.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    y_true = y_true.values if hasattr(y_true, \"values\") else np.asarray(y_true)\n",
    "    y_pred_proba = y_pred_proba.values if hasattr(y_pred_proba, \"values\") else np.asarray(y_pred_proba)\n",
    "\n",
    "    # Basic checks\n",
    "    if y_true.shape[0] != y_pred_proba.shape[0]:\n",
    "        raise ValueError(\"y_true and y_pred_proba must have the same number of samples.\")\n",
    "\n",
    "    uniq = np.unique(y_true)\n",
    "    if uniq.size < 2:\n",
    "        raise ValueError(\"AUC undefined: test set has a single class.\")\n",
    "    if uniq.size > 2:\n",
    "        # Remap to binary by ordering (largest label -> positive class)\n",
    "        # This allows labels like {-1, +1} or {0, 2}\n",
    "        pos_label = uniq.max()\n",
    "        y_true = (y_true == pos_label).astype(int)\n",
    "        uniq = np.array([0, 1])\n",
    "\n",
    "    # Class counts\n",
    "    n_pos = int((y_true == 1).sum())\n",
    "    n_neg = int((y_true == 0).sum())\n",
    "    if min(n_pos, n_neg) < 3:\n",
    "        print(f\"Warning: very few positives/negatives (pos={n_pos}, neg={n_neg}); CI will be unstable.\")\n",
    "\n",
    "    # Index pools by class\n",
    "    pos_idx = np.where(y_true == 1)[0]\n",
    "    neg_idx = np.where(y_true == 0)[0]\n",
    "\n",
    "    aucs = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Stratified resample: draw with replacement within each class\n",
    "        b_pos = rng.choice(pos_idx, size=n_pos, replace=True)\n",
    "        b_neg = rng.choice(neg_idx, size=n_neg, replace=True)\n",
    "        b_idx = np.concatenate([b_pos, b_neg])\n",
    "        rng.shuffle(b_idx)  # order doesn't matter for AUC, but good practice\n",
    "\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_true[b_idx], y_pred_proba[b_idx]))\n",
    "        except ValueError:\n",
    "            # Extremely unlikely with stratified sampling; keep guard anyway\n",
    "            continue\n",
    "\n",
    "    valid = len(aucs)\n",
    "    if valid == 0:\n",
    "        print(\"Error: No valid bootstrap samples generated.\")\n",
    "        return None, None, None, 0\n",
    "    if valid < min_valid:\n",
    "        print(f\"Warning: Only {valid} valid bootstrap samples (min recommended {min_valid}). CI may be unreliable.\")\n",
    "\n",
    "    # Percentile CI\n",
    "    lower = float(np.percentile(aucs, (1 - ci) / 2 * 100))\n",
    "    upper = float(np.percentile(aucs, (1 + ci) / 2 * 100))\n",
    "    mean_auc = float(np.mean(aucs))\n",
    "\n",
    "    print(f\"Bootstrapped {int(ci*100)}% CI for Final Model Test AUC: {mean_auc:.4f} [{lower:.4f}, {upper:.4f}] \"\n",
    "          f\"(valid reps = {valid})\")\n",
    "    return mean_auc, lower, upper, valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === `__main__` integration block with SA with Bootstrap LASSO (Hybrid Approach) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CORRECTED SA RADIOMICS FEATURE SELECTION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Step 1: Loading data and creating train/test split...\n",
      "Initial clinical data: 166 patients\n",
      "Final matched data: 163 patients\n",
      "Dataset: 163 samples, 103 features\n",
      "Class distribution: LRR=55 (33.7%), Non-LRR=108 (66.3%)\n",
      "Training/Validation: 130 samples\n",
      "Test (held-out): 33 samples\n",
      "\n",
      "Step 2: 5-Fold Cross-Validation with corrected SA feature selection...\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 1/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable features (freq >= 0.5): [  0   1   2   3   4   5   6   7   9  10  11  12  13  15  17  18  19  22\n",
      "  23  27  28  31  33  36  40  42  43  45  46  47  48  49  52  53  56  58\n",
      "  59  60  62  64  65  67  68  69  72  73  74  75  76  77  78  80  81  82\n",
      "  83  84  86  87  88  91  92  93  94  95  97  98  99 101 102]\n",
      "LASSO selected 69 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected SA...\n",
      "  LogisticRegression: Train AUC=0.6663, Val AUC=0.7986, Features=37\n",
      "\n",
      "Processing GaussianNB with corrected SA...\n",
      "  GaussianNB: Train AUC=0.6940, Val AUC=0.7778, Features=34\n",
      "\n",
      "Processing SVC with corrected SA...\n",
      "  SVC: Train AUC=0.3382, Val AUC=0.1736, Features=34\n",
      "\n",
      "Processing SVC with corrected SA...\n",
      "  SVC: Train AUC=0.3333, Val AUC=0.2292, Features=35\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected SA...\n",
      "  DecisionTreeClassifier: Train AUC=0.8139, Val AUC=0.6389, Features=30\n",
      "\n",
      "Processing RandomForestClassifier with corrected SA...\n",
      "  RandomForestClassifier: Train AUC=0.9257, Val AUC=0.6389, Features=38\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 2/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Stable features (freq >= 0.5): [  0   1   2   3   4   5   6   9  10  11  13  15  18  22  23  27  33  36\n",
      "  40  42  45  47  48  49  59  64  67  68  69  73  77  78  80  81  83  87\n",
      "  88  92  93  94  97  99 101 102]\n",
      "LASSO selected 44 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected SA...\n",
      "  LogisticRegression: Train AUC=0.6859, Val AUC=0.6863, Features=19\n",
      "\n",
      "Processing GaussianNB with corrected SA...\n",
      "  GaussianNB: Train AUC=0.6923, Val AUC=0.6993, Features=24\n",
      "\n",
      "Processing SVC with corrected SA...\n",
      "  SVC: Train AUC=0.6352, Val AUC=0.5817, Features=24\n",
      "\n",
      "Processing SVC with corrected SA...\n",
      "  SVC: Train AUC=0.6373, Val AUC=0.5686, Features=20\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected SA...\n",
      "  DecisionTreeClassifier: Train AUC=0.7611, Val AUC=0.6667, Features=22\n",
      "\n",
      "Processing RandomForestClassifier with corrected SA...\n",
      "  RandomForestClassifier: Train AUC=0.9395, Val AUC=0.7516, Features=23\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 3/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable features (freq >= 0.5): [  0   1   3   4   5   6  10  13  18  22  27  33  36  42  45  47  48  49\n",
      "  69  72  73  77  78  80  83  87  92  93  97  98  99 102]\n",
      "LASSO selected 32 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected SA...\n",
      "  LogisticRegression: Train AUC=0.7507, Val AUC=0.4706, Features=16\n",
      "\n",
      "Processing GaussianNB with corrected SA...\n",
      "  GaussianNB: Train AUC=0.7528, Val AUC=0.3987, Features=14\n",
      "\n",
      "Processing SVC with corrected SA...\n",
      "  SVC: Train AUC=0.2323, Val AUC=0.5752, Features=17\n",
      "\n",
      "Processing SVC with corrected SA...\n",
      "  SVC: Train AUC=0.2133, Val AUC=0.5817, Features=17\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected SA...\n",
      "  DecisionTreeClassifier: Train AUC=0.9774, Val AUC=0.4118, Features=15\n",
      "\n",
      "Processing RandomForestClassifier with corrected SA...\n",
      "  RandomForestClassifier: Train AUC=0.9222, Val AUC=0.3725, Features=11\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 4/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Stable features (freq >= 0.5): [  0   1   2   3   4   5   6   7  10  13  14  15  18  19  22  27  33  36\n",
      "  42  43  45  47  48  49  53  64  67  69  73  75  77  78  80  81  86  87\n",
      "  92  93  94  97  98  99 101 102]\n",
      "LASSO selected 44 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected SA...\n",
      "  LogisticRegression: Train AUC=0.6762, Val AUC=0.7908, Features=26\n",
      "\n",
      "Processing GaussianNB with corrected SA...\n",
      "  GaussianNB: Train AUC=0.7097, Val AUC=0.7516, Features=18\n",
      "\n",
      "Processing SVC with corrected SA...\n",
      "  SVC: Train AUC=0.3412, Val AUC=0.1895, Features=20\n",
      "\n",
      "Processing SVC with corrected SA...\n",
      "  SVC: Train AUC=0.3089, Val AUC=0.2745, Features=17\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected SA...\n",
      "  DecisionTreeClassifier: Train AUC=0.8238, Val AUC=0.4510, Features=22\n",
      "\n",
      "Processing RandomForestClassifier with corrected SA...\n",
      "  RandomForestClassifier: Train AUC=0.9354, Val AUC=0.6993, Features=24\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 5/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable features (freq >= 0.5): [  0   1   2   3   4   5   6   9  10  13  15  17  18  19  22  27  36  42\n",
      "  45  47  48  49  60  64  67  69  72  73  74  77  80  81  83  86  87  92\n",
      "  93  94  97  99 102]\n",
      "LASSO selected 41 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected SA...\n",
      "  LogisticRegression: Train AUC=0.7209, Val AUC=0.5882, Features=23\n",
      "\n",
      "Processing GaussianNB with corrected SA...\n",
      "  GaussianNB: Train AUC=0.7097, Val AUC=0.5686, Features=16\n",
      "\n",
      "Processing SVC with corrected SA...\n",
      "  SVC: Train AUC=0.2886, Val AUC=0.4379, Features=21\n",
      "\n",
      "Processing SVC with corrected SA...\n",
      "  SVC: Train AUC=0.2890, Val AUC=0.4837, Features=21\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected SA...\n",
      "  DecisionTreeClassifier: Train AUC=0.8443, Val AUC=0.3431, Features=20\n",
      "\n",
      "Processing RandomForestClassifier with corrected SA...\n",
      "  RandomForestClassifier: Train AUC=0.9362, Val AUC=0.5490, Features=20\n",
      "\n",
      "============================================================\n",
      "BUILDING CONSENSUS FEATURES (CORRECTED METHOD)\n",
      "============================================================\n",
      "LogisticRegression: 18 consensus features\n",
      "GaussianNB: 16 consensus features\n",
      "SVC: 42 consensus features\n",
      "DecisionTreeClassifier: 17 consensus features\n",
      "RandomForestClassifier: 18 consensus features\n",
      "\n",
      "Final SA consensus: 44 features\n",
      "Consensus features: ['original_glcm_Correlation', 'original_glrlm_RunEntropy', 'original_ngtdm_Strength', 'original_gldm_SmallDependenceLowGrayLevelEmphasis', 'original_ngtdm_Contrast', 'original_shape_Flatness', 'original_glcm_JointEnergy', 'original_shape_SurfaceArea', 'original_firstorder_10Percentile', 'original_shape_Maximum2DDiameterRow']...\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION ON HELD-OUT TEST SET\n",
      "============================================================\n",
      "Final training set: (130, 44)\n",
      "Final test set: (33, 44)\n",
      "\n",
      "Final evaluation: LogisticRegression\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6958 [0.5896, 0.7910] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6188 [0.3801, 0.8307] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: GaussianNB\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7130 [0.6165, 0.8016] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7193 [0.5164, 0.9091] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.2875 [0.1945, 0.3872] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3349 [0.1281, 0.5620] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.2875 [0.1945, 0.3872] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3349 [0.1281, 0.5620] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: DecisionTreeClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7267 [0.6490, 0.8002] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6438 [0.4648, 0.8017] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: RandomForestClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.9189 [0.8673, 0.9572] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6537 [0.4339, 0.8388] (valid reps = 1000)\n",
      "\n",
      "================================================================================\n",
      "SA PIPELINE COMPREHENSIVE PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "DATASET SUMMARY:\n",
      "- Total samples: 163 (Train/Val: 130, Test: 33)\n",
      "- Original features: 103\n",
      "- SA consensus features: 44\n",
      "- Class distribution: LRR=55 (33.7%)\n",
      "\n",
      "CROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\n",
      "--------------------------------------------------------------------------------\n",
      "Classifier                Train AUC       Val AUC         Train Acc       Val Acc        \n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression        0.700±0.031     0.667±0.125     0.677±0.028     0.623±0.075\n",
      "GaussianNB                0.712±0.022     0.639±0.140     0.700±0.014     0.669±0.052\n",
      "SVC                       0.362±0.143     0.410±0.165     0.620±0.093     0.619±0.095\n",
      "DecisionTreeClassifier    0.844±0.072     0.502±0.128     0.785±0.097     0.523±0.173\n",
      "RandomForestClassifier    0.932±0.007     0.602±0.133     0.813±0.026     0.631±0.093\n",
      "\n",
      "FINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Classifier                Train AUC [95% CI]        Test AUC [95% CI]         Test Acc  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "LogisticRegression        0.696 [0.590,0.791]   0.624 [0.380,0.831]   0.727\n",
      "GaussianNB                0.713 [0.617,0.802]   0.723 [0.516,0.909]   0.758\n",
      "SVC                       0.288 [0.194,0.387]   0.331 [0.128,0.562]   0.667\n",
      "DecisionTreeClassifier    0.727 [0.649,0.800]   0.645 [0.465,0.802]   0.606\n",
      "RandomForestClassifier    0.919 [0.867,0.957]   0.657 [0.434,0.839]   0.697\n",
      "\n",
      "Best SA Test Performance: GaussianNB\n",
      "Test AUC: 0.7231, Test Accuracy: 0.7576\n",
      "\n",
      "================================================================================\n",
      "CORRECTED SA PIPELINE COMPLETE - MATCHES PSO/WOA/GWO METHODOLOGY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CORRECTED SA MAIN PIPELINE (MATCHING PSO/WOA/GWO STRUCTURE)\n",
    "# ==========================================\n",
    "\n",
    "def corrected_sa_main_pipeline():\n",
    "    \"\"\"\n",
    "    SA main pipeline that matches the EXACT same structure as PSO/WOA/GWO pipelines:\n",
    "    1. 80/20 split\n",
    "    2. 5-Fold CV with LASSO+SA per fold \n",
    "    3. Feature name-based consensus\n",
    "    4. Final evaluation on held-out test set\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CORRECTED SA RADIOMICS FEATURE SELECTION PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ===============================================================\n",
    "    # 1) Load data and perform initial 80/20 split  \n",
    "    # ===============================================================\n",
    "    print(\"\\nStep 1: Loading data and creating train/test split...\")\n",
    "    \n",
    "    radiomics_data, clinical_data = load_data()\n",
    "    radiomics_cols = get_radiomics_columns(radiomics_data)\n",
    "    X_raw = radiomics_data[radiomics_cols].values\n",
    "    y = clinical_data[\"LocoRegeonalRecurrence\"].values\n",
    "    feature_names = radiomics_data[radiomics_cols].columns.tolist()\n",
    "\n",
    "    print(f\"Dataset: {len(X_raw)} samples, {X_raw.shape[1]} features\")\n",
    "    print(f\"Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%), \"\n",
    "          f\"Non-LRR={len(y)-np.sum(y)} ({100*(len(y)-np.sum(y))/len(y):.1f}%)\")\n",
    "\n",
    "    # Proper 80/20 split with stratification\n",
    "    X_temp, X_test_raw, y_temp, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Training/Validation: {len(X_temp)} samples\")\n",
    "    print(f\"Test (held-out): {len(X_test_raw)} samples\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 2) 5-Fold CV with corrected feature selection pipeline\n",
    "    # ===============================================================\n",
    "    print(f\"\\nStep 2: 5-Fold Cross-Validation with corrected SA feature selection...\")\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define classifiers\n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        GaussianNB(),\n",
    "        SVC(kernel='linear', probability=True),\n",
    "        SVC(kernel='rbf', probability=True),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    ]\n",
    "\n",
    "    # Store selected feature NAMES (not indices) for proper consensus\n",
    "    fold_selected_features = {}  # classifier -> [fold_features_sets]\n",
    "    classifier_fold_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        fold_selected_features[clf_name] = []\n",
    "        classifier_fold_results[clf_name] = {\n",
    "            'train_aucs': [], 'val_aucs': [], 'train_accs': [], 'val_accs': []\n",
    "        }\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold_id, (tr_idx, va_idx) in enumerate(skf.split(X_temp, y_temp), 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROCESSING FOLD {fold_id}/5\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        X_tr_raw, X_va_raw = X_temp[tr_idx], X_temp[va_idx]\n",
    "        y_tr, y_va = y_temp[tr_idx], y_temp[va_idx]\n",
    "\n",
    "        # STEP 1: Proper scaling (fit on train, transform both)\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_scaled = scaler.fit_transform(X_tr_raw)\n",
    "        X_va_scaled = scaler.transform(X_va_raw)\n",
    "\n",
    "        # STEP 2: Bootstrap LASSO feature selection (on training fold only)\n",
    "        print(f\"Applying Bootstrap LASSO feature selection...\")\n",
    "        stable_idx_fold = bootstrap_lasso_fs(\n",
    "            X_tr_scaled, y_tr, n_bootstrap=1000, freq_threshold=0.5\n",
    "        )\n",
    "        stable_idx_fold = np.asarray(stable_idx_fold)\n",
    "        \n",
    "        if len(stable_idx_fold) == 0:\n",
    "            print(f\"Warning: No stable features found in fold {fold_id}. Skipping fold.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"LASSO selected {len(stable_idx_fold)} features from {X_tr_scaled.shape[1]}\")\n",
    "\n",
    "        # Apply LASSO selection to get reduced feature matrices\n",
    "        X_tr_lasso = X_tr_scaled[:, stable_idx_fold]\n",
    "        X_va_lasso = X_va_scaled[:, stable_idx_fold]\n",
    "        \n",
    "        # Get feature names for LASSO-selected features\n",
    "        lasso_feature_names = [feature_names[i] for i in stable_idx_fold]\n",
    "\n",
    "        # STEP 3: SA feature selection per classifier (CORRECTED VERSION)\n",
    "        for clf in classifiers:\n",
    "            clf_name = clf.__class__.__name__\n",
    "            print(f\"\\nProcessing {clf_name} with corrected SA...\")\n",
    "            \n",
    "            try:\n",
    "                # Hyperparameter tuning on LASSO-selected features\n",
    "                tuned_clf = get_tuned_model(clf, X_tr_lasso, y_tr)\n",
    "\n",
    "                # CORRECTED SA: Uses fixed evaluate_fitness function\n",
    "                best_solution, train_auc_hist, val_auc_hist = run_sa(\n",
    "                    X_tr_lasso, y_tr, X_va_lasso, y_va, tuned_clf, \n",
    "                    n_iter=500, initial_temp=10, cooling_rate=0.95, verbose=False\n",
    "                )\n",
    "\n",
    "                # Get SA-selected feature names (not indices)\n",
    "                sa_selected_indices = np.where(best_solution == 1)[0]\n",
    "                sa_selected_feature_names = [lasso_feature_names[i] for i in sa_selected_indices]\n",
    "                \n",
    "                # Store selected feature names for this classifier and fold\n",
    "                fold_selected_features[clf_name].append(set(sa_selected_feature_names))\n",
    "\n",
    "                # Evaluate performance with selected features\n",
    "                if len(sa_selected_indices) > 0:\n",
    "                    X_tr_final = X_tr_lasso[:, best_solution == 1]\n",
    "                    X_va_final = X_va_lasso[:, best_solution == 1]\n",
    "                    \n",
    "                    # Train final model and evaluate\n",
    "                    final_model = make_pipeline(StandardScaler(), tuned_clf)\n",
    "                    final_model.fit(X_tr_final, y_tr)\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    if hasattr(final_model, 'predict_proba'):\n",
    "                        y_tr_proba = final_model.predict_proba(X_tr_final)[:, 1]\n",
    "                        y_va_proba = final_model.predict_proba(X_va_final)[:, 1]\n",
    "                    else:\n",
    "                        y_tr_proba = final_model.decision_function(X_tr_final)\n",
    "                        y_va_proba = final_model.decision_function(X_va_final)\n",
    "                    \n",
    "                    y_tr_pred = final_model.predict(X_tr_final)\n",
    "                    y_va_pred = final_model.predict(X_va_final)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    train_auc = roc_auc_score(y_tr, y_tr_proba)\n",
    "                    val_auc = roc_auc_score(y_va, y_va_proba)\n",
    "                    train_acc = accuracy_score(y_tr, y_tr_pred)\n",
    "                    val_acc = accuracy_score(y_va, y_va_pred)\n",
    "                    \n",
    "                    # Store results\n",
    "                    classifier_fold_results[clf_name]['train_aucs'].append(train_auc)\n",
    "                    classifier_fold_results[clf_name]['val_aucs'].append(val_auc)\n",
    "                    classifier_fold_results[clf_name]['train_accs'].append(train_acc)\n",
    "                    classifier_fold_results[clf_name]['val_accs'].append(val_acc)\n",
    "                    \n",
    "                    print(f\"  {clf_name}: Train AUC={train_auc:.4f}, Val AUC={val_auc:.4f}, \"\n",
    "                          f\"Features={len(sa_selected_indices)}\")\n",
    "                else:\n",
    "                    print(f\"  Warning: {clf_name} selected no features in fold {fold_id}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {clf_name}: {e}\")\n",
    "                fold_selected_features[clf_name].append(set())\n",
    "\n",
    "    # ===============================================================\n",
    "    # 3) CORRECTED consensus building using feature names (same as others)\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BUILDING CONSENSUS FEATURES (CORRECTED METHOD)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build consensus per classifier, then combine (same as PSO/WOA/GWO)\n",
    "    classifier_consensus_features = {}\n",
    "    \n",
    "    for clf_name in fold_selected_features:\n",
    "        if len(fold_selected_features[clf_name]) == 0:\n",
    "            classifier_consensus_features[clf_name] = set()\n",
    "            continue\n",
    "            \n",
    "        # Get all unique features selected by this classifier across folds\n",
    "        all_features_for_clf = set()\n",
    "        for fold_features in fold_selected_features[clf_name]:\n",
    "            all_features_for_clf.update(fold_features)\n",
    "        \n",
    "        # Count votes for each feature\n",
    "        feature_votes = {}\n",
    "        for feature in all_features_for_clf:\n",
    "            votes = sum(1 for fold_features in fold_selected_features[clf_name] \n",
    "                       if feature in fold_features)\n",
    "            feature_votes[feature] = votes\n",
    "        \n",
    "        # Select features with majority vote (>= 3 out of 5 folds)\n",
    "        consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                 if votes >= 3}\n",
    "        \n",
    "        # Fallback: if no features meet majority threshold, use >= 2 votes\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                     if votes >= 2}\n",
    "        \n",
    "        # Final fallback: use union if still empty\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = all_features_for_clf\n",
    "            \n",
    "        classifier_consensus_features[clf_name] = consensus_features_clf\n",
    "        print(f\"{clf_name}: {len(consensus_features_clf)} consensus features\")\n",
    "\n",
    "    # FINAL CONSENSUS: Union of all classifier consensus features\n",
    "    final_consensus_features = set()\n",
    "    for clf_features in classifier_consensus_features.values():\n",
    "        final_consensus_features.update(clf_features)\n",
    "    \n",
    "    # Convert back to indices for final evaluation\n",
    "    consensus_feature_names = list(final_consensus_features)\n",
    "    consensus_indices = [feature_names.index(fname) for fname in consensus_feature_names \n",
    "                        if fname in feature_names]\n",
    "    \n",
    "    print(f\"\\nFinal SA consensus: {len(consensus_indices)} features\")\n",
    "    print(f\"Consensus features: {consensus_feature_names[:10]}...\" if len(consensus_feature_names) > 10 \n",
    "          else f\"Consensus features: {consensus_feature_names}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 4) Final evaluation on held-out test set (same as others)\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL EVALUATION ON HELD-OUT TEST SET\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if len(consensus_indices) == 0:\n",
    "        print(\"ERROR: No consensus features found. Cannot proceed with final evaluation.\")\n",
    "        return\n",
    "    \n",
    "    # Apply final scaling and consensus feature selection\n",
    "    scaler_final = StandardScaler()\n",
    "    X_trval_scaled = scaler_final.fit_transform(X_temp)\n",
    "    X_test_scaled = scaler_final.transform(X_test_raw)\n",
    "    \n",
    "    # Select consensus features\n",
    "    X_trval_final = X_trval_scaled[:, consensus_indices]\n",
    "    X_test_final = X_test_scaled[:, consensus_indices]\n",
    "    \n",
    "    print(f\"Final training set: {X_trval_final.shape}\")\n",
    "    print(f\"Final test set: {X_test_final.shape}\")\n",
    "\n",
    "    # Final evaluation per classifier (same structure as others)\n",
    "    final_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        print(f\"\\nFinal evaluation: {clf_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Retune on full 80% with consensus features\n",
    "            tuned_clf_final = get_tuned_model(clf, X_trval_final, y_temp)\n",
    "            tuned_clf_final.fit(X_trval_final, y_temp)\n",
    "\n",
    "            # Training performance (80% data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_train_proba = tuned_clf_final.predict_proba(X_trval_final)[:, 1]\n",
    "            else:\n",
    "                y_train_proba = tuned_clf_final.decision_function(X_trval_final)\n",
    "            \n",
    "            y_train_pred = tuned_clf_final.predict(X_trval_final)\n",
    "            train_auc = roc_auc_score(y_temp, y_train_proba)\n",
    "            train_acc = accuracy_score(y_temp, y_train_pred)\n",
    "\n",
    "            # Test performance (20% held-out data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_test_proba = tuned_clf_final.predict_proba(X_test_final)[:, 1]\n",
    "            else:\n",
    "                y_test_proba = tuned_clf_final.decision_function(X_test_final)\n",
    "            \n",
    "            y_test_pred = tuned_clf_final.predict(X_test_final)\n",
    "            test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "            test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "            # Bootstrap confidence intervals\n",
    "            train_mean_auc, train_lower, train_upper, train_valid = bootstrap_final_model_auc_ci(\n",
    "                y_temp, y_train_proba, n_bootstrap=1000\n",
    "            )\n",
    "            \n",
    "            test_mean_auc, test_lower, test_upper, test_valid = bootstrap_final_model_auc_ci(\n",
    "                y_test, y_test_proba, n_bootstrap=1000\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            final_results[clf_name] = {\n",
    "                'train_auc': train_auc,\n",
    "                'train_acc': train_acc,\n",
    "                'test_auc': test_auc,\n",
    "                'test_acc': test_acc,\n",
    "                'train_ci_lower': train_lower,\n",
    "                'train_ci_upper': train_upper,\n",
    "                'test_ci_lower': test_lower,\n",
    "                'test_ci_upper': test_upper\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {clf_name}: {e}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 5) COMPREHENSIVE RESULTS SUMMARY (same as others)\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SA PIPELINE COMPREHENSIVE PERFORMANCE SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nDATASET SUMMARY:\")\n",
    "    print(f\"- Total samples: {len(X_raw)} (Train/Val: {len(X_temp)}, Test: {len(X_test_raw)})\")\n",
    "    print(f\"- Original features: {X_raw.shape[1]}\")\n",
    "    print(f\"- SA consensus features: {len(consensus_indices)}\")\n",
    "    print(f\"- Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%)\")\n",
    "\n",
    "    # Cross-validation performance summary\n",
    "    print(f\"\\nCROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC':<15} {'Val AUC':<15} {'Train Acc':<15} {'Val Acc':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for clf_name, results in classifier_fold_results.items():\n",
    "        if results['train_aucs']:\n",
    "            train_auc_mean = np.mean(results['train_aucs'])\n",
    "            train_auc_std = np.std(results['train_aucs'])\n",
    "            val_auc_mean = np.mean(results['val_aucs'])\n",
    "            val_auc_std = np.std(results['val_aucs'])\n",
    "            train_acc_mean = np.mean(results['train_accs'])\n",
    "            train_acc_std = np.std(results['train_accs'])\n",
    "            val_acc_mean = np.mean(results['val_accs'])\n",
    "            val_acc_std = np.std(results['val_accs'])\n",
    "            \n",
    "            print(f\"{clf_name:<25} {train_auc_mean:.3f}±{train_auc_std:.3f}     \"\n",
    "                  f\"{val_auc_mean:.3f}±{val_auc_std:.3f}     \"\n",
    "                  f\"{train_acc_mean:.3f}±{train_acc_std:.3f}     \"\n",
    "                  f\"{val_acc_mean:.3f}±{val_acc_std:.3f}\")\n",
    "\n",
    "    # Final test performance\n",
    "    print(f\"\\nFINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC [95% CI]':<25} {'Test AUC [95% CI]':<25} {'Test Acc':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for clf_name, results in final_results.items():\n",
    "        train_auc = results['train_auc']\n",
    "        train_lower = results['train_ci_lower']\n",
    "        train_upper = results['train_ci_upper']\n",
    "        test_auc = results['test_auc']\n",
    "        test_lower = results['test_ci_lower']\n",
    "        test_upper = results['test_ci_upper']\n",
    "        test_acc = results['test_acc']\n",
    "\n",
    "        print(f\"{clf_name:<25} {train_auc:.3f} [{train_lower:.3f},{train_upper:.3f}]   \"\n",
    "              f\"{test_auc:.3f} [{test_lower:.3f},{test_upper:.3f}]   {test_acc:.3f}\")\n",
    "\n",
    "    # Best performer\n",
    "    if final_results:\n",
    "        best_clf = max(final_results.keys(), key=lambda x: final_results[x]['test_auc'])\n",
    "        best_test_auc = final_results[best_clf]['test_auc']\n",
    "        best_test_acc = final_results[best_clf]['test_acc']\n",
    "        \n",
    "        print(f\"\\nBest SA Test Performance: {best_clf}\")\n",
    "        print(f\"Test AUC: {best_test_auc:.4f}, Test Accuracy: {best_test_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"CORRECTED SA PIPELINE COMPLETE - MATCHES PSO/WOA/GWO METHODOLOGY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return final_results, consensus_feature_names, classifier_fold_results\n",
    "\n",
    "\n",
    "# Run the corrected SA pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    sa_final_results, sa_consensus_features, sa_cv_results = corrected_sa_main_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === `__main__` integration block with only SA ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SA-ONLY RADIOMICS FEATURE SELECTION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Step 1: Loading data and creating train/test split...\n",
      "Initial clinical data: 166 patients\n",
      "Final matched data: 163 patients\n",
      "Dataset: 163 samples, 103 features\n",
      "Class distribution: LRR=55 (33.7%), Non-LRR=108 (66.3%)\n",
      "Training/Validation: 130 samples\n",
      "Test (held-out): 33 samples\n",
      "\n",
      "Step 2: 5-Fold Cross-Validation with SA-only feature selection...\n",
      "Note: SA will work on all original features (no LASSO pre-filtering)\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 1/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  LogisticRegression: Train AUC=0.6679, Val AUC=0.7778, Features selected=49\n",
      "\n",
      "Processing GaussianNB with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  GaussianNB: Train AUC=0.6932, Val AUC=0.7153, Features selected=46\n",
      "\n",
      "Processing SVC with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  SVC: Train AUC=0.3391, Val AUC=0.1875, Features selected=47\n",
      "\n",
      "Processing SVC with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  SVC: Train AUC=0.3325, Val AUC=0.2222, Features selected=36\n",
      "\n",
      "Processing DecisionTreeClassifier with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.7988, Val AUC=0.5243, Features selected=53\n",
      "\n",
      "Processing RandomForestClassifier with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9395, Val AUC=0.6944, Features selected=51\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 2/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  LogisticRegression: Train AUC=0.6882, Val AUC=0.6797, Features selected=52\n",
      "\n",
      "Processing GaussianNB with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  GaussianNB: Train AUC=0.7209, Val AUC=0.6536, Features selected=30\n",
      "\n",
      "Processing SVC with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  SVC: Train AUC=0.3077, Val AUC=0.3007, Features selected=46\n",
      "\n",
      "Processing SVC with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  SVC: Train AUC=0.2998, Val AUC=0.3333, Features selected=52\n",
      "\n",
      "Processing DecisionTreeClassifier with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.7961, Val AUC=0.5359, Features selected=52\n",
      "\n",
      "Processing RandomForestClassifier with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9122, Val AUC=0.6536, Features selected=38\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 3/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  LogisticRegression: Train AUC=0.7540, Val AUC=0.3987, Features selected=57\n",
      "\n",
      "Processing GaussianNB with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  GaussianNB: Train AUC=0.7741, Val AUC=0.4444, Features selected=58\n",
      "\n",
      "Processing SVC with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  SVC: Train AUC=0.2472, Val AUC=0.6013, Features selected=53\n",
      "\n",
      "Processing SVC with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  SVC: Train AUC=0.7445, Val AUC=0.4379, Features selected=52\n",
      "\n",
      "Processing DecisionTreeClassifier with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.9017, Val AUC=0.5294, Features selected=62\n",
      "\n",
      "Processing RandomForestClassifier with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9222, Val AUC=0.3529, Features selected=48\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 4/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  LogisticRegression: Train AUC=0.6853, Val AUC=0.7778, Features selected=42\n",
      "\n",
      "Processing GaussianNB with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  GaussianNB: Train AUC=0.6501, Val AUC=0.6765, Features selected=53\n",
      "\n",
      "Processing SVC with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  SVC: Train AUC=0.3217, Val AUC=0.2549, Features selected=40\n",
      "\n",
      "Processing SVC with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  SVC: Train AUC=0.3371, Val AUC=0.2484, Features selected=50\n",
      "\n",
      "Processing DecisionTreeClassifier with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.9072, Val AUC=0.5588, Features selected=50\n",
      "\n",
      "Processing RandomForestClassifier with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9350, Val AUC=0.6797, Features selected=48\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 5/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  LogisticRegression: Train AUC=0.7126, Val AUC=0.5490, Features selected=49\n",
      "\n",
      "Processing GaussianNB with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  GaussianNB: Train AUC=0.7077, Val AUC=0.5621, Features selected=53\n",
      "\n",
      "Processing SVC with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  SVC: Train AUC=0.2923, Val AUC=0.4444, Features selected=52\n",
      "\n",
      "Processing SVC with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  SVC: Train AUC=0.7118, Val AUC=0.5621, Features selected=59\n",
      "\n",
      "Processing DecisionTreeClassifier with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.8433, Val AUC=0.4183, Features selected=43\n",
      "\n",
      "Processing RandomForestClassifier with SA on full feature set...\n",
      "  Running SA on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9064, Val AUC=0.5098, Features selected=56\n",
      "\n",
      "============================================================\n",
      "BUILDING CONSENSUS FEATURES FROM SA SELECTIONS\n",
      "============================================================\n",
      "LogisticRegression: 49 consensus features\n",
      "GaussianNB: 42 consensus features\n",
      "SVC: 96 consensus features\n",
      "DecisionTreeClassifier: 58 consensus features\n",
      "RandomForestClassifier: 44 consensus features\n",
      "\n",
      "Final SA consensus: 102 features\n",
      "Consensus features: ['original_glcm_Correlation', 'original_gldm_DependenceEntropy', 'original_gldm_SmallDependenceEmphasis', 'original_glrlm_RunEntropy', 'original_ngtdm_Strength', 'original_glcm_Id', 'original_shape_SurfaceVolumeRatio', 'original_glrlm_RunLengthNonUniformity', 'original_glrlm_ShortRunEmphasis', 'original_gldm_GrayLevelNonUniformity']...\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION ON HELD-OUT TEST SET\n",
      "============================================================\n",
      "Final training set: (130, 102)\n",
      "Final test set: (33, 102)\n",
      "\n",
      "Final evaluation: LogisticRegression\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6958 [0.5896, 0.7910] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6188 [0.3801, 0.8307] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: GaussianNB\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7203 [0.6263, 0.8063] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6825 [0.4793, 0.8719] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.2842 [0.1895, 0.3840] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3596 [0.1405, 0.5827] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.2842 [0.1895, 0.3840] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3596 [0.1405, 0.5827] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: DecisionTreeClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.8076 [0.7299, 0.8677] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6284 [0.4337, 0.8017] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: RandomForestClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.8998 [0.8448, 0.9456] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6501 [0.4131, 0.8430] (valid reps = 1000)\n",
      "\n",
      "================================================================================\n",
      "SA-ONLY PIPELINE PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "DATASET SUMMARY:\n",
      "- Total samples: 163 (Train/Val: 130, Test: 33)\n",
      "- Original features: 103\n",
      "- SA consensus features: 102\n",
      "- Feature reduction: 103 → 102 (99.0%)\n",
      "- Class distribution: LRR=55 (33.7%)\n",
      "\n",
      "CROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\n",
      "--------------------------------------------------------------------------------\n",
      "Classifier                Train AUC       Val AUC         Train Acc       Val Acc        \n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression        0.702±0.030     0.637±0.146     0.690±0.017     0.623±0.104\n",
      "GaussianNB                0.709±0.040     0.610±0.097     0.665±0.106     0.577±0.060\n",
      "SVC                       0.393±0.170     0.359±0.137     0.599±0.137     0.542±0.140\n",
      "DecisionTreeClassifier    0.849±0.048     0.513±0.049     0.792±0.030     0.546±0.029\n",
      "RandomForestClassifier    0.923±0.013     0.578±0.130     0.823±0.034     0.631±0.079\n",
      "\n",
      "FINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Classifier                Train AUC [95% CI]        Test AUC [95% CI]         Test Acc  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "LogisticRegression        0.696 [0.590,0.791]   0.624 [0.380,0.831]   0.727\n",
      "GaussianNB                0.721 [0.626,0.806]   0.686 [0.479,0.872]   0.697\n",
      "SVC                       0.285 [0.189,0.384]   0.355 [0.140,0.583]   0.667\n",
      "DecisionTreeClassifier    0.807 [0.730,0.868]   0.628 [0.434,0.802]   0.606\n",
      "RandomForestClassifier    0.899 [0.845,0.946]   0.653 [0.413,0.843]   0.697\n",
      "\n",
      "Best SA-Only Performance: GaussianNB\n",
      "Test AUC: 0.6860, Test Accuracy: 0.6970\n",
      "Average features per classifier: 57.8\n",
      "\n",
      "================================================================================\n",
      "SA-ONLY PIPELINE COMPLETE\n",
      "Compare these results with LASSO+SA to evaluate the impact of pre-filtering\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def sa_only_main_pipeline():\n",
    "    \"\"\"\n",
    "    SA-ONLY feature selection pipeline (without LASSO pre-filtering).\n",
    "    This version applies SA directly to all original features for each classifier.\n",
    "    \n",
    "    Pipeline: Raw Data → 80/20 Split → 5-Fold CV → SA → Consensus → Final Test\n",
    "    \n",
    "    Uses the same corrected SA implementation to ensure methodological soundness.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"SA-ONLY RADIOMICS FEATURE SELECTION PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ===============================================================\n",
    "    # 1) Load data and perform initial 80/20 split\n",
    "    # ===============================================================\n",
    "    print(\"\\nStep 1: Loading data and creating train/test split...\")\n",
    "    \n",
    "    radiomics_data, clinical_data = load_data()\n",
    "    radiomics_cols = get_radiomics_columns(radiomics_data)\n",
    "    X_raw = radiomics_data[radiomics_cols].values\n",
    "    y = clinical_data[\"LocoRegeonalRecurrence\"].values\n",
    "    feature_names = radiomics_data[radiomics_cols].columns.tolist()\n",
    "\n",
    "    print(f\"Dataset: {len(X_raw)} samples, {X_raw.shape[1]} features\")\n",
    "    print(f\"Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%), \"\n",
    "          f\"Non-LRR={len(y)-np.sum(y)} ({100*(len(y)-np.sum(y))/len(y):.1f}%)\")\n",
    "\n",
    "    # Proper 80/20 split with stratification\n",
    "    X_temp, X_test_raw, y_temp, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Training/Validation: {len(X_temp)} samples\")\n",
    "    print(f\"Test (held-out): {len(X_test_raw)} samples\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 2) 5-Fold CV with SA-only feature selection\n",
    "    # ===============================================================\n",
    "    print(f\"\\nStep 2: 5-Fold Cross-Validation with SA-only feature selection...\")\n",
    "    print(\"Note: SA will work on all original features (no LASSO pre-filtering)\")\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define classifiers\n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        GaussianNB(),\n",
    "        SVC(kernel='linear', probability=True),\n",
    "        SVC(kernel='rbf', probability=True),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    ]\n",
    "\n",
    "    # Store selected feature NAMES for proper consensus building\n",
    "    fold_selected_features = {}  # classifier -> [fold_features_sets]\n",
    "    classifier_fold_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        fold_selected_features[clf_name] = []\n",
    "        classifier_fold_results[clf_name] = {\n",
    "            'train_aucs': [], 'val_aucs': [], 'train_accs': [], 'val_accs': []\n",
    "        }\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold_id, (tr_idx, va_idx) in enumerate(skf.split(X_temp, y_temp), 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROCESSING FOLD {fold_id}/5\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        X_tr_raw, X_va_raw = X_temp[tr_idx], X_temp[va_idx]\n",
    "        y_tr, y_va = y_temp[tr_idx], y_temp[va_idx]\n",
    "\n",
    "        # STEP 1: Proper scaling (fit on train, transform both)\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_scaled = scaler.fit_transform(X_tr_raw)\n",
    "        X_va_scaled = scaler.transform(X_va_raw)\n",
    "        \n",
    "        print(f\"Working with ALL {X_tr_scaled.shape[1]} original features\")\n",
    "\n",
    "        # STEP 2: SA feature selection per classifier (directly on all features)\n",
    "        for clf in classifiers:\n",
    "            clf_name = clf.__class__.__name__\n",
    "            print(f\"\\nProcessing {clf_name} with SA on full feature set...\")\n",
    "            \n",
    "            try:\n",
    "                # Hyperparameter tuning on full scaled feature set\n",
    "                tuned_clf = get_tuned_model(clf, X_tr_scaled, y_tr)\n",
    "\n",
    "                # SA feature selection on ALL features (no LASSO pre-filtering)\n",
    "                print(f\"  Running SA on {X_tr_scaled.shape[1]} features...\")\n",
    "                best_solution, train_auc_hist, val_auc_hist = run_sa(\n",
    "                    X_tr_scaled, y_tr, X_va_scaled, y_va, tuned_clf, \n",
    "                    n_iter=800,      # More iterations for larger search space\n",
    "                    initial_temp=50, # Higher temperature for more exploration\n",
    "                    cooling_rate=0.98, # Slower cooling for thorough search\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "                # Get SA-selected feature names\n",
    "                sa_selected_indices = np.where(best_solution == 1)[0]\n",
    "                sa_selected_feature_names = [feature_names[i] for i in sa_selected_indices]\n",
    "                \n",
    "                # Store selected feature names for this classifier and fold\n",
    "                fold_selected_features[clf_name].append(set(sa_selected_feature_names))\n",
    "\n",
    "                # Evaluate performance with SA-selected features\n",
    "                if len(sa_selected_indices) > 0:\n",
    "                    X_tr_sa = X_tr_scaled[:, best_solution == 1]\n",
    "                    X_va_sa = X_va_scaled[:, best_solution == 1]\n",
    "                    \n",
    "                    # Train final model and evaluate\n",
    "                    final_model = make_pipeline(StandardScaler(), tuned_clf)\n",
    "                    final_model.fit(X_tr_sa, y_tr)\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    if hasattr(final_model, 'predict_proba'):\n",
    "                        y_tr_proba = final_model.predict_proba(X_tr_sa)[:, 1]\n",
    "                        y_va_proba = final_model.predict_proba(X_va_sa)[:, 1]\n",
    "                    else:\n",
    "                        y_tr_proba = final_model.decision_function(X_tr_sa)\n",
    "                        y_va_proba = final_model.decision_function(X_va_sa)\n",
    "                    \n",
    "                    y_tr_pred = final_model.predict(X_tr_sa)\n",
    "                    y_va_pred = final_model.predict(X_va_sa)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    train_auc = roc_auc_score(y_tr, y_tr_proba)\n",
    "                    val_auc = roc_auc_score(y_va, y_va_proba)\n",
    "                    train_acc = accuracy_score(y_tr, y_tr_pred)\n",
    "                    val_acc = accuracy_score(y_va, y_va_pred)\n",
    "                    \n",
    "                    # Store results\n",
    "                    classifier_fold_results[clf_name]['train_aucs'].append(train_auc)\n",
    "                    classifier_fold_results[clf_name]['val_aucs'].append(val_auc)\n",
    "                    classifier_fold_results[clf_name]['train_accs'].append(train_acc)\n",
    "                    classifier_fold_results[clf_name]['val_accs'].append(val_acc)\n",
    "                    \n",
    "                    print(f\"  {clf_name}: Train AUC={train_auc:.4f}, Val AUC={val_auc:.4f}, \"\n",
    "                          f\"Features selected={len(sa_selected_indices)}\")\n",
    "                else:\n",
    "                    print(f\"  Warning: {clf_name} selected no features in fold {fold_id}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {clf_name}: {e}\")\n",
    "                fold_selected_features[clf_name].append(set())\n",
    "\n",
    "    # ===============================================================\n",
    "    # 3) Build consensus features using the same method\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BUILDING CONSENSUS FEATURES FROM SA SELECTIONS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build consensus per classifier, then combine (same logic as other algorithms)\n",
    "    classifier_consensus_features = {}\n",
    "    \n",
    "    for clf_name in fold_selected_features:\n",
    "        if len(fold_selected_features[clf_name]) == 0:\n",
    "            classifier_consensus_features[clf_name] = set()\n",
    "            continue\n",
    "            \n",
    "        # Get all unique features selected by this classifier across folds\n",
    "        all_features_for_clf = set()\n",
    "        for fold_features in fold_selected_features[clf_name]:\n",
    "            all_features_for_clf.update(fold_features)\n",
    "        \n",
    "        # Count votes for each feature\n",
    "        feature_votes = {}\n",
    "        for feature in all_features_for_clf:\n",
    "            votes = sum(1 for fold_features in fold_selected_features[clf_name] \n",
    "                       if feature in fold_features)\n",
    "            feature_votes[feature] = votes\n",
    "        \n",
    "        # Select features with majority vote (>= 3 out of 5 folds)\n",
    "        consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                 if votes >= 3}\n",
    "        \n",
    "        # Fallback: if no features meet majority threshold, use >= 2 votes\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                     if votes >= 2}\n",
    "        \n",
    "        # Final fallback: use union if still empty\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = all_features_for_clf\n",
    "            \n",
    "        classifier_consensus_features[clf_name] = consensus_features_clf\n",
    "        print(f\"{clf_name}: {len(consensus_features_clf)} consensus features\")\n",
    "\n",
    "    # FINAL CONSENSUS: Union of all classifier consensus features\n",
    "    final_consensus_features = set()\n",
    "    for clf_features in classifier_consensus_features.values():\n",
    "        final_consensus_features.update(clf_features)\n",
    "    \n",
    "    # Convert back to indices for final evaluation\n",
    "    consensus_feature_names = list(final_consensus_features)\n",
    "    consensus_indices = [feature_names.index(fname) for fname in consensus_feature_names \n",
    "                        if fname in feature_names]\n",
    "    \n",
    "    print(f\"\\nFinal SA consensus: {len(consensus_indices)} features\")\n",
    "    print(f\"Consensus features: {consensus_feature_names[:10]}...\" if len(consensus_feature_names) > 10 \n",
    "          else f\"Consensus features: {consensus_feature_names}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 4) Final evaluation on held-out test set\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL EVALUATION ON HELD-OUT TEST SET\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if len(consensus_indices) == 0:\n",
    "        print(\"ERROR: No consensus features found. Cannot proceed with final evaluation.\")\n",
    "        return\n",
    "    \n",
    "    # Apply final scaling and consensus feature selection\n",
    "    scaler_final = StandardScaler()\n",
    "    X_trval_scaled = scaler_final.fit_transform(X_temp)\n",
    "    X_test_scaled = scaler_final.transform(X_test_raw)\n",
    "    \n",
    "    # Select SA consensus features\n",
    "    X_trval_final = X_trval_scaled[:, consensus_indices]\n",
    "    X_test_final = X_test_scaled[:, consensus_indices]\n",
    "    \n",
    "    print(f\"Final training set: {X_trval_final.shape}\")\n",
    "    print(f\"Final test set: {X_test_final.shape}\")\n",
    "\n",
    "    # Final evaluation per classifier\n",
    "    final_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        print(f\"\\nFinal evaluation: {clf_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Retune on full 80% with SA consensus features\n",
    "            tuned_clf_final = get_tuned_model(clf, X_trval_final, y_temp)\n",
    "            tuned_clf_final.fit(X_trval_final, y_temp)\n",
    "\n",
    "            # Training performance (80% data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_train_proba = tuned_clf_final.predict_proba(X_trval_final)[:, 1]\n",
    "            else:\n",
    "                y_train_proba = tuned_clf_final.decision_function(X_trval_final)\n",
    "            \n",
    "            y_train_pred = tuned_clf_final.predict(X_trval_final)\n",
    "            train_auc = roc_auc_score(y_temp, y_train_proba)\n",
    "            train_acc = accuracy_score(y_temp, y_train_pred)\n",
    "\n",
    "            # Test performance (20% held-out data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_test_proba = tuned_clf_final.predict_proba(X_test_final)[:, 1]\n",
    "            else:\n",
    "                y_test_proba = tuned_clf_final.decision_function(X_test_final)\n",
    "            \n",
    "            y_test_pred = tuned_clf_final.predict(X_test_final)\n",
    "            test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "            test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "            # Bootstrap confidence intervals\n",
    "            train_mean_auc, train_lower, train_upper, train_valid = bootstrap_final_model_auc_ci(\n",
    "                y_temp, y_train_proba, n_bootstrap=1000\n",
    "            )\n",
    "            \n",
    "            test_mean_auc, test_lower, test_upper, test_valid = bootstrap_final_model_auc_ci(\n",
    "                y_test, y_test_proba, n_bootstrap=1000\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            final_results[clf_name] = {\n",
    "                'train_auc': train_auc,\n",
    "                'train_acc': train_acc,\n",
    "                'test_auc': test_auc,\n",
    "                'test_acc': test_acc,\n",
    "                'train_ci_lower': train_lower,\n",
    "                'train_ci_upper': train_upper,\n",
    "                'test_ci_lower': test_lower,\n",
    "                'test_ci_upper': test_upper\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {clf_name}: {e}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 5) COMPREHENSIVE RESULTS SUMMARY\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SA-ONLY PIPELINE PERFORMANCE SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nDATASET SUMMARY:\")\n",
    "    print(f\"- Total samples: {len(X_raw)} (Train/Val: {len(X_temp)}, Test: {len(X_test_raw)})\")\n",
    "    print(f\"- Original features: {X_raw.shape[1]}\")\n",
    "    print(f\"- SA consensus features: {len(consensus_indices)}\")\n",
    "    print(f\"- Feature reduction: {X_raw.shape[1]} → {len(consensus_indices)} \"\n",
    "          f\"({100*len(consensus_indices)/X_raw.shape[1]:.1f}%)\")\n",
    "    print(f\"- Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%)\")\n",
    "\n",
    "    # Cross-validation performance summary\n",
    "    print(f\"\\nCROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC':<15} {'Val AUC':<15} {'Train Acc':<15} {'Val Acc':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for clf_name, results in classifier_fold_results.items():\n",
    "        if results['train_aucs']:\n",
    "            train_auc_mean = np.mean(results['train_aucs'])\n",
    "            train_auc_std = np.std(results['train_aucs'])\n",
    "            val_auc_mean = np.mean(results['val_aucs'])\n",
    "            val_auc_std = np.std(results['val_aucs'])\n",
    "            train_acc_mean = np.mean(results['train_accs'])\n",
    "            train_acc_std = np.std(results['train_accs'])\n",
    "            val_acc_mean = np.mean(results['val_accs'])\n",
    "            val_acc_std = np.std(results['val_accs'])\n",
    "            \n",
    "            print(f\"{clf_name:<25} {train_auc_mean:.3f}±{train_auc_std:.3f}     \"\n",
    "                  f\"{val_auc_mean:.3f}±{val_auc_std:.3f}     \"\n",
    "                  f\"{train_acc_mean:.3f}±{train_acc_std:.3f}     \"\n",
    "                  f\"{val_acc_mean:.3f}±{val_acc_std:.3f}\")\n",
    "\n",
    "    # Final test performance\n",
    "    print(f\"\\nFINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC [95% CI]':<25} {'Test AUC [95% CI]':<25} {'Test Acc':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for clf_name, results in final_results.items():\n",
    "        train_auc = results['train_auc']\n",
    "        train_lower = results['train_ci_lower']\n",
    "        train_upper = results['train_ci_upper']\n",
    "        test_auc = results['test_auc']\n",
    "        test_lower = results['test_ci_lower']\n",
    "        test_upper = results['test_ci_upper']\n",
    "        test_acc = results['test_acc']\n",
    "\n",
    "        print(f\"{clf_name:<25} {train_auc:.3f} [{train_lower:.3f},{train_upper:.3f}]   \"\n",
    "              f\"{test_auc:.3f} [{test_lower:.3f},{test_upper:.3f}]   {test_acc:.3f}\")\n",
    "\n",
    "    # Best performer and comparison insights\n",
    "    if final_results:\n",
    "        best_clf = max(final_results.keys(), key=lambda x: final_results[x]['test_auc'])\n",
    "        best_test_auc = final_results[best_clf]['test_auc']\n",
    "        best_test_acc = final_results[best_clf]['test_acc']\n",
    "        \n",
    "        print(f\"\\nBest SA-Only Performance: {best_clf}\")\n",
    "        print(f\"Test AUC: {best_test_auc:.4f}, Test Accuracy: {best_test_acc:.4f}\")\n",
    "        \n",
    "        # Calculate average feature reduction\n",
    "        avg_features_per_classifier = np.mean([len(features) for features in classifier_consensus_features.values() if features])\n",
    "        print(f\"Average features per classifier: {avg_features_per_classifier:.1f}\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SA-ONLY PIPELINE COMPLETE\")\n",
    "    print(\"Compare these results with LASSO+SA to evaluate the impact of pre-filtering\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return final_results, consensus_feature_names, classifier_fold_results\n",
    "\n",
    "\n",
    "# Run the SA-only pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    sa_results, sa_consensus_features, sa_cv_results = sa_only_main_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
