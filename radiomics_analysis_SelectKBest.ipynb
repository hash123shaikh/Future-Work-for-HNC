{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === **SelectKBest for Feature Selection to optimize feature subsets for various ML classifiers** ===\n",
    "\n",
    "-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Stable Feature Pre-selection:**\n",
    "\n",
    "* Performed initial feature selection using **bootstrapped LASSO logistic regression** (`penalty='l1'`, `solver='liblinear'`, `cv=5`, `max_iter=5000`), repeated for **100 bootstrap samples** (`n_bootstrap=100`). Features were retained if selected in **≥70%** of bootstraps (`freq_threshold=0.7`), ensuring stability against sampling variance.\n",
    "\n",
    "\n",
    "**2. Metaheuristic Feature Selection:**\n",
    "\n",
    "* Applies **Particle Swarm Optimization (PSO)** for further feature selection from the stable set, using a population of **20 particles** (`n_particles=20`) and **50 iterations** (`max_iter=50`). Each particle represented a binary feature mask, and the swarm was optimized to maximize mean ROC AUC over 5-fold stratified cross-validation (`StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`).\n",
    "\n",
    "\n",
    "**3. Comprehensive Classifier Comparison:**\n",
    "\n",
    "* Evaluated a broad suite of classifiers:\n",
    "\n",
    "  * **Logistic Regression** (`max_iter=1000`), with grid search over `C=[0.001, 0.01, 0.1, 1, 10]` and `penalty=['l1', 'l2']`\n",
    "\n",
    "  * **Gaussian Naive Bayes** (default parameters)\n",
    "\n",
    "  * **Support Vector Machines** (linear and RBF kernels, `C=[0.01, 0.1, 1, 10]`, `gamma=['scale', 'auto']`)\n",
    "\n",
    "  * **Decision Tree** (`max_depth=[3, 5, 7]`, `min_samples_split=[5, 10]`, `min_samples_leaf=[2, 4]`)\n",
    "\n",
    "  * **Random Forest** (`n_estimators=[100, 200]`, `max_depth=[5, 10]`, `min_samples_split=[5, 10]`, `min_samples_leaf=[2, 4]`)\n",
    "\n",
    "  * **VotingClassifier** ensemble combining top-tuned base models with soft voting.\n",
    "\n",
    "* Hyperparameters were tuned for each classifier using **GridSearchCV** and 5-fold stratified cross-validation, optimizing for ROC AUC.\n",
    "\n",
    "\n",
    "**4. Class Imbalance and Data Integrity Handling:**\n",
    "\n",
    "* Maintained **class distribution balance** in all data splits using stratified sampling, both in train/test partitioning (`test_size=0.2`) and during cross-validation.\n",
    "\n",
    "* For bootstrapping and CI estimation, ensured that each resample included both classes—skipping samples otherwise to avoid invalid AUC calculations.\n",
    "\n",
    "\n",
    "**5. Feature Scaling and Pipeline Safety:**\n",
    "\n",
    "* Applied **feature standardization** (`StandardScaler()`) within all pipelines, fitting scalers only on training data to prevent information leakage.\n",
    "\n",
    "* Model pipelines (`make_pipeline(StandardScaler(), classifier)`) ensured consistent preprocessing during evaluation and prediction.\n",
    "\n",
    "\n",
    "**6. Model Evaluation & Uncertainty Quantification:**\n",
    "\n",
    "* Reported **ROC AUC and accuracy** for both training and testing sets at each PSO iteration.\n",
    "\n",
    "* Computed **bootstrapped confidence intervals** for test AUC (`n_bootstrap=1000`, `ci=0.95`), resampling test predictions to quantify model uncertainty and generalization performance.\n",
    "\n",
    "\n",
    "**7. Visualization and Monitoring:**\n",
    "\n",
    "* Plotted **train/test AUC trends** across PSO iterations for convergence analysis.\n",
    "\n",
    "* Displayed final **ROC curves** for both training and testing sets, including mean AUC and 95% confidence intervals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === IMPORTS ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                                            # Core numerical computation library for arrays and matrix operations\n",
    "import pandas as pd                                                                           # Library for data manipulation and analysis (tabular data, DataFrames)\n",
    "from sklearn.base import clone                                                                # For cloning estimators (useful when building pipelines or doing cross-validation)\n",
    "import matplotlib.pyplot as plt                                                               # For plotting graphs (e.g., ROC curves, feature importances, etc.)\n",
    "from scipy.stats import bootstrap                                                             # For statistical bootstrap resampling (scipy's bootstrap is for CI, sklearn's resample for random sampling)\n",
    "from sklearn.utils import resample                                                            # Utility to randomly resample datasets (e.g., for bootstrapping in ML)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold        # For splitting data, cross-validation, and stratified folds (for imbalanced classes)\n",
    "from sklearn.preprocessing import StandardScaler                                              # For scaling features to zero mean/unit variance (important for many ML algorithms)\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score                          # For evaluating model performance: ROC AUC, ROC curve points, accuracy\n",
    "\n",
    "# === CLASSIFIERS ===\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB                                                    # Naive Bayes classifier for classification tasks\n",
    "from sklearn.svm import SVC                                                                   # Support Vector Classifier (linear & nonlinear SVMs)\n",
    "from sklearn.tree import DecisionTreeClassifier                                               # Decision Tree classifier (nonlinear, interpretable ML model)\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier                         # Random Forest classifier (ensemble of Decision Trees)\n",
    "from sklearn.pipeline import make_pipeline, Pipeline                                          # For creating machine learning pipelines (combining preprocessing + models)\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV                     # Logistic Regression (standard and cross-validated, for classification)\n",
    "\n",
    "# === GRID SEARCH HYPERPARAMETER TUNING ===\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV                                              # For exhaustive grid search over hyperparameters with cross-validation\n",
    "from sklearn.feature_selection import SelectKBest, f_classif                                   # For univariate feature selection (SelectKBest with ANOVA F-value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === LOAD AND PREPROCESS DATA ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Load radiomics and clinical CSV files into DataFrames\n",
    "    radiomics = pd.read_csv(\"./HNC-Prospective-Radiomics-305.csv\")\n",
    "    clinical = pd.read_csv(\"./proceed_radiomics_128.csv\")\n",
    "\n",
    "    print(f\"Initial clinical data: {len(clinical)} patients\")\n",
    "    # print(f\"Unique locations in clinical data: {clinical['Location'].value_counts()}\")\n",
    "\n",
    "    # Filter clinical data to only include specific tumor locations\n",
    "    # clinical = clinical[clinical[\"Location\"].isin(['Larynx', 'Tonsil', 'Hypopharynx', 'Oropharynx', 'BOT', 'Other'])]\n",
    "    # print(f\"After location filtering: {len(clinical)} patients\")\n",
    "\n",
    "    # Standardize 'research_subject_uid' in radiomics by keeping only the part before \"_\"\n",
    "    radiomics[\"research_subject_uid\"] = radiomics[\"research_subject_uid\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "    # Remove any leading/trailing spaces from 'Project ID' in clinical data\n",
    "    clinical[\"Project ID\"] = clinical[\"Project ID\"].str.strip()\n",
    "\n",
    "    # Filter radiomics to only keep rows with research_subject_uid present in clinical Project IDs\n",
    "    radiomics_filtered = radiomics[radiomics[\"research_subject_uid\"].isin(clinical[\"Project ID\"])]\n",
    "    \n",
    "    # Filter clinical to only keep rows with Project ID present in radiomics research_subject_uid\n",
    "    clinical_filtered = clinical[clinical[\"Project ID\"].isin(radiomics[\"research_subject_uid\"])]\n",
    "\n",
    "    print(f\"Final matched data: {len(clinical_filtered)} patients\")\n",
    "\n",
    "    # Sort both DataFrames by their ID columns and reset their indices\n",
    "    radiomics_filtered = radiomics_filtered.sort_values(by=\"research_subject_uid\").reset_index(drop=True)\n",
    "    clinical_filtered = clinical_filtered.sort_values(by=\"Project ID\").reset_index(drop=True)\n",
    "\n",
    "    # Return the filtered and aligned DataFrames for further processing\n",
    "    return radiomics_filtered, clinical_filtered\n",
    "\n",
    "\n",
    "def get_radiomics_columns(data):\n",
    "    \"\"\"\n",
    "    Returns the columns from 'original_shape_Elongation' to 'original_ngtdm_Strength'.\n",
    "    These typically represent the set of radiomics features you want to extract.\n",
    "    \"\"\"\n",
    "    start_column = \"original_shape_Elongation\"\n",
    "    end_column = \"original_ngtdm_Strength\"\n",
    "    start_idx = data.columns.get_loc(start_column)\n",
    "    end_idx = data.columns.get_loc(end_column) + 1  # +1 to include the end column itself\n",
    "    return data.columns[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Define hyperparameter grids for each classifier ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These grids help tune the model to avoid overfitting by optimizing regularization and other key parameters.\n",
    "all_grid_params = {\n",
    "    'LogisticRegression': {\n",
    "        'C': [1e-4, 3e-4, 1e-3, 3e-3, 1e-2, 3e-2, 0.1, 0.3, 1, 3, 10],          # Regularization strength (lower = stronger regularization)\n",
    "        'penalty': ['l1', 'l2'],                                                # Type of regularization: L1 (Lasso), L2 (Ridge)\n",
    "        'solver': ['liblinear'],                                                # Solver that supports both l1 and l2\n",
    "        'class_weight': [None, \"balanced\"],\n",
    "        'max_iter': [1000],\n",
    "    },\n",
    "    'GaussianNB': {},                                                           # No tunable hyperparameters for basic Naive Bayes\n",
    "    'SVC': [\n",
    "        # Linear SVC\n",
    "        {\n",
    "            'C': [1e-3, 1e-2, 0.1, 1, 10],                                      # Regularization strength\n",
    "            'kernel': ['linear'],                                               # Linear kernel\n",
    "            'probability': [True],                                              # Needed for probability predictions (e.g., ROC AUC)\n",
    "            'class_weight': [None, \"balanced\"],\n",
    "        },\n",
    "        # RBF SVC\n",
    "        {\n",
    "            'C': [1e-3, 1e-2, 0.1, 1, 10],                                      # Regularization strength\n",
    "            'gamma': ['scale', 'auto', 1e-3, 1e-2, 1e-1],                       # Kernel coefficient for RBF\n",
    "            'kernel': ['rbf'],                                                  # RBF (nonlinear) kernel\n",
    "            'probability': [True],                                              # Probability estimates\n",
    "            'class_weight': [None, \"balanced\"],\n",
    "        }\n",
    "    ],\n",
    "    'DecisionTreeClassifier': {\n",
    "        'criterion': ['gini', 'entropy'],                                       # Split quality metric\n",
    "        'max_depth': [2, 3, 4, 5, 7],                                           # Controls tree depth (regularization)\n",
    "        'min_samples_split': [5, 10, 15],                                       # Minimum samples required to split a node\n",
    "        'min_samples_leaf': [2, 4, 6],                                          # Minimum samples per leaf node\n",
    "        'max_features': ['sqrt', 'log2', None],                                 # Number of features considered at each split\n",
    "        'class_weight': [None, \"balanced\"],\n",
    "        'random_state': [42],\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [100, 200, 400],                                        # Number of trees\n",
    "        'max_depth': [3, 5, 7, 10],                                             # Maximum depth of trees\n",
    "        'min_samples_split': [5, 10],                                           # Minimum samples to split an internal node\n",
    "        'min_samples_leaf': [2, 4],                                             # Minimum samples at a leaf node\n",
    "        'max_features': ['sqrt', 'log2'],                                       # Number of features considered at each split\n",
    "        'bootstrap': [True],                                                    # Use bootstrap samples\n",
    "        'n_jobs': [-1],                                                         # Use all available CPU cores for parallel processing\n",
    "        'class_weight': [None, \"balanced\", \"balanced_subsample\"],\n",
    "        'random_state': [42],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# === Utility function to tune a classifier's hyperparameters using grid search and cross-validation ===\n",
    "\n",
    "def get_tuned_model(classifier, X_train, y_train):\n",
    "    name = classifier.__class__.__name__                                 # Get class name as a string (e.g., 'LogisticRegression')\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)      # 5-fold stratified cross-validation\n",
    "    \n",
    "    # Special handling for SVC as its grid is a list (to support both linear & RBF kernels)\n",
    "    if name == 'SVC':\n",
    "        grid = GridSearchCV(\n",
    "            clone(classifier),            # Clone base estimator to avoid data leakage between folds\n",
    "            all_grid_params['SVC'],\n",
    "            scoring='roc_auc',            # Use ROC AUC for model selection (works for imbalanced data)\n",
    "            cv=cv,                        # Use stratified k-fold\n",
    "            n_jobs=-1,                    # Use all CPU cores\n",
    "            refit=True,\n",
    "        )\n",
    "        grid.fit(X_train, y_train)       # Fit grid search\n",
    "        return grid.best_estimator_      # Return the model with best hyperparameters\n",
    "\n",
    "    # For all other classifiers with defined grid parameters\n",
    "    elif name in all_grid_params and all_grid_params[name]:\n",
    "        grid = GridSearchCV(\n",
    "            clone(classifier),\n",
    "            all_grid_params[name],\n",
    "            scoring='roc_auc',\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "            refit=True,\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        return grid.best_estimator_\n",
    "\n",
    "    # If no hyperparameters to tune (e.g., GaussianNB), return the original classifier\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === BOOTSTRAP SelectKBest FEATURE SELECTION ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectkbest_feature_selection(X, y, k_values=None, cv=5, scoring='roc_auc', random_state=42):\n",
    "    \"\"\"\n",
    "    Selects optimal k features using SelectKBest with f_classif scoring and cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: feature matrix (numpy array)\n",
    "    - y: target labels\n",
    "    - k_values: list of k values to test (if None, uses default range)\n",
    "    - cv: number of cross-validation folds\n",
    "    - scoring: scoring metric for model selection\n",
    "    - random_state: for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - best_k: optimal number of features\n",
    "    - selected_features_idx: indices of selected features\n",
    "    - cv_scores: cross-validation scores for each k\n",
    "    \"\"\"\n",
    "    \n",
    "    if k_values is None:\n",
    "        # Default k values to test (adjust based on your feature count)\n",
    "        max_features = min(X.shape[1], 50)  # Don't test more than 50 or total features\n",
    "        k_values = [5, 10, 15, 20, 25, 30, 40, 50]\n",
    "        k_values = [k for k in k_values if k <= max_features]\n",
    "    \n",
    "    print(f\"Testing k values: {k_values}\")\n",
    "    \n",
    "    best_score = 0\n",
    "    best_k = k_values[0]\n",
    "    cv_scores = {}\n",
    "    \n",
    "    # Test each k value using cross-validation\n",
    "    for k in k_values:\n",
    "        print(f\"\\nTesting k={k}...\")\n",
    "        \n",
    "        # SelectKBest with f_classif (ANOVA F-test)\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "        X_selected = selector.fit_transform(X, y)\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LogisticRegression(max_iter=1000, random_state=random_state))\n",
    "        ])\n",
    "        \n",
    "        # Cross-validation scores\n",
    "        scores = cross_val_score(pipeline, X_selected, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "        mean_score = scores.mean()\n",
    "        std_score = scores.std()\n",
    "        \n",
    "        cv_scores[k] = {'mean': mean_score, 'std': std_score, 'scores': scores}\n",
    "        \n",
    "        print(f\"  CV Score: {mean_score:.4f} (±{std_score:.4f})\")\n",
    "        \n",
    "        # Update best k if this is better\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_k = k\n",
    "    \n",
    "    print(f\"\\nBest k: {best_k} with CV score: {best_score:.4f}\")\n",
    "    \n",
    "    # Fit final selector with best k on full training data\n",
    "    final_selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "    final_selector.fit(X, y)\n",
    "    selected_features_idx = final_selector.get_support(indices=True)\n",
    "    \n",
    "    print(f\"Selected {len(selected_features_idx)} features: {selected_features_idx}\")\n",
    "    \n",
    "    return best_k, selected_features_idx, cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Evaluate model with classifier function ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_classifier(X_train, X_test, y_train, y_test, selected_features, feature_names, classifier):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a given classifier using only the features selected by a feature selection algorithm.\n",
    "    Prints Train/Test AUC and Accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train, X_test: Feature matrices (numpy arrays)\n",
    "        y_train, y_test: Labels\n",
    "        selected_features: Binary vector indicating which features to use\n",
    "        feature_names: List of feature names (not used here, but useful for further reporting)\n",
    "        classifier: Classifier instance (e.g., LogisticRegression)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select only the features chosen by the feature selection mask\n",
    "    X_train_sel = X_train[:, selected_features == 1]\n",
    "    X_test_sel = X_test[:, selected_features == 1]\n",
    "\n",
    "    # If no features were selected, print a warning and stop\n",
    "    if X_train_sel.shape[1] == 0:\n",
    "        print(\"\\n⚠️ No features selected. Cannot train classifier.\")\n",
    "        return\n",
    "\n",
    "    # Build pipeline: scale features then fit classifier\n",
    "    model = make_pipeline(StandardScaler(), classifier)\n",
    "    model.fit(X_train_sel, y_train)  # Train the model on selected features\n",
    "\n",
    "    # Get predicted probabilities or decision function for AUC\n",
    "    y_train_proba = model.predict_proba(X_train_sel)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_train_sel)\n",
    "    y_test_proba = model.predict_proba(X_test_sel)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_test_sel)\n",
    "\n",
    "    # Get predicted labels for accuracy\n",
    "    y_train_pred = model.predict(X_train_sel)\n",
    "    y_test_pred = model.predict(X_test_sel)\n",
    "\n",
    "    # Print evaluation metrics for train and test sets\n",
    "    print(f\"\\n✅ Results for {classifier.__class__.__name__}:\")\n",
    "    print(f\"Train AUC: {roc_auc_score(y_train, y_train_proba):.4f}\")\n",
    "    print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "    print(f\"Test AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Computes a bootstrapped confidence interval for ROC AUC of the final model ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_final_model_auc_ci(\n",
    "    y_true,\n",
    "    y_pred_proba,\n",
    "    n_bootstrap: int = 1000,\n",
    "    ci: float = 0.95,\n",
    "    random_state: int = 42,\n",
    "    min_valid: int = 200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Stratified bootstrap CI for ROC AUC on small/imbalanced test sets.\n",
    "    - Preserves class counts in each bootstrap sample (positives/negatives drawn separately).\n",
    "    - Avoids invalid replicates with a single class.\n",
    "    - Returns mean AUC and (lower, upper) percentile CI.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        True binary labels. If not exactly {0,1}, they will be remapped to {0,1} by ordering.\n",
    "    y_pred_proba : array-like\n",
    "        Predicted probabilities or decision scores (higher = more likely positive).\n",
    "    n_bootstrap : int, default=2000\n",
    "        Number of bootstrap replicates.\n",
    "    ci : float, default=0.95\n",
    "        Confidence level (e.g., 0.95 for 95% CI).\n",
    "    random_state : int, default=42\n",
    "        Seed for reproducibility.\n",
    "    min_valid : int, default=200\n",
    "        Minimum recommended number of valid bootstrap replicates for a stable CI.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean_auc : float\n",
    "    lower : float\n",
    "    upper : float\n",
    "    valid : int\n",
    "        Number of valid bootstrap replicates used.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    y_true = y_true.values if hasattr(y_true, \"values\") else np.asarray(y_true)\n",
    "    y_pred_proba = y_pred_proba.values if hasattr(y_pred_proba, \"values\") else np.asarray(y_pred_proba)\n",
    "\n",
    "    # Basic checks\n",
    "    if y_true.shape[0] != y_pred_proba.shape[0]:\n",
    "        raise ValueError(\"y_true and y_pred_proba must have the same number of samples.\")\n",
    "\n",
    "    uniq = np.unique(y_true)\n",
    "    if uniq.size < 2:\n",
    "        raise ValueError(\"AUC undefined: test set has a single class.\")\n",
    "    if uniq.size > 2:\n",
    "        # Remap to binary by ordering (largest label -> positive class)\n",
    "        # This allows labels like {-1, +1} or {0, 2}\n",
    "        pos_label = uniq.max()\n",
    "        y_true = (y_true == pos_label).astype(int)\n",
    "        uniq = np.array([0, 1])\n",
    "\n",
    "    # Class counts\n",
    "    n_pos = int((y_true == 1).sum())\n",
    "    n_neg = int((y_true == 0).sum())\n",
    "    if min(n_pos, n_neg) < 3:\n",
    "        print(f\"Warning: very few positives/negatives (pos={n_pos}, neg={n_neg}); CI will be unstable.\")\n",
    "\n",
    "    # Index pools by class\n",
    "    pos_idx = np.where(y_true == 1)[0]\n",
    "    neg_idx = np.where(y_true == 0)[0]\n",
    "\n",
    "    aucs = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Stratified resample: draw with replacement within each class\n",
    "        b_pos = rng.choice(pos_idx, size=n_pos, replace=True)\n",
    "        b_neg = rng.choice(neg_idx, size=n_neg, replace=True)\n",
    "        b_idx = np.concatenate([b_pos, b_neg])\n",
    "        rng.shuffle(b_idx)  # order doesn't matter for AUC, but good practice\n",
    "\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_true[b_idx], y_pred_proba[b_idx]))\n",
    "        except ValueError:\n",
    "            # Extremely unlikely with stratified sampling; keep guard anyway\n",
    "            continue\n",
    "\n",
    "    valid = len(aucs)\n",
    "    if valid == 0:\n",
    "        print(\"Error: No valid bootstrap samples generated.\")\n",
    "        return None, None, None, 0\n",
    "    if valid < min_valid:\n",
    "        print(f\"Warning: Only {valid} valid bootstrap samples (min recommended {min_valid}). CI may be unreliable.\")\n",
    "\n",
    "    # Percentile CI\n",
    "    lower = float(np.percentile(aucs, (1 - ci) / 2 * 100))\n",
    "    upper = float(np.percentile(aucs, (1 + ci) / 2 * 100))\n",
    "    mean_auc = float(np.mean(aucs))\n",
    "\n",
    "    print(f\"Bootstrapped {int(ci*100)}% CI for Final Model Test AUC: {mean_auc:.4f} [{lower:.4f}, {upper:.4f}] \"\n",
    "          f\"(valid reps = {valid})\")\n",
    "    return mean_auc, lower, upper, valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === `__main__` integration block with Bootstrap SelectKBest ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial clinical data: 128 patients\n",
      "Final matched data: 128 patients\n",
      "DATASET INFORMATION:\n",
      "Total samples: 128\n",
      "Total features: 103\n",
      "Class distribution: LRR=47, Non-LRR=81\n",
      "LRR percentage: 36.7%\n",
      "\n",
      "DATA SPLIT:\n",
      "Train/val samples: 102\n",
      "Test samples: 26\n",
      "Train/val class dist: LRR=37, Non-LRR=65\n",
      "Test class dist: LRR=10, Non-LRR=16\n",
      "\n",
      "============================================================\n",
      "SELECTKBEST FEATURE SELECTION WITH 5-FOLD CROSS-VALIDATION\n",
      "============================================================\n",
      "\n",
      "FOLD 1/5\n",
      "----------------------------------------\n",
      "Running SelectKBest feature selection...\n",
      "Testing k values: [5, 10, 15, 20, 25, 30, 40, 50]\n",
      "\n",
      "Testing k=5...\n",
      "  CV Score: 0.6350 (±0.0503)\n",
      "\n",
      "Testing k=10...\n",
      "  CV Score: 0.6411 (±0.0376)\n",
      "\n",
      "Testing k=15...\n",
      "  CV Score: 0.6730 (±0.0274)\n",
      "\n",
      "Testing k=20...\n",
      "  CV Score: 0.5781 (±0.0684)\n",
      "\n",
      "Testing k=25...\n",
      "  CV Score: 0.5818 (±0.0852)\n",
      "\n",
      "Testing k=30...\n",
      "  CV Score: 0.5710 (±0.0436)\n",
      "\n",
      "Testing k=40...\n",
      "  CV Score: 0.5604 (±0.0727)\n",
      "\n",
      "Testing k=50...\n",
      "  CV Score: 0.5450 (±0.0601)\n",
      "\n",
      "Best k: 15 with CV score: 0.6730\n",
      "Selected 15 features: [  2   5   6   7   8   9  11  15  52  61  68  73  85  88 101]\n",
      "Selected 15 features out of 103 (k=15)\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "  Train AUC: 0.7493, Val AUC: 0.5288\n",
      "  Train Acc: 0.7407, Val Acc: 0.6190\n",
      "\n",
      "Evaluating GaussianNB...\n",
      "  Train AUC: 0.7248, Val AUC: 0.6971\n",
      "  Train Acc: 0.6790, Val Acc: 0.7619\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.6873, Val AUC: 0.8173\n",
      "  Train Acc: 0.6420, Val Acc: 0.6190\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.6877, Val AUC: 0.8173\n",
      "  Train Acc: 0.6420, Val Acc: 0.6190\n",
      "\n",
      "Evaluating DecisionTreeClassifier...\n",
      "  Train AUC: 0.8982, Val AUC: 0.6923\n",
      "  Train Acc: 0.8395, Val Acc: 0.5714\n",
      "\n",
      "Evaluating RandomForestClassifier...\n",
      "  Train AUC: 0.9304, Val AUC: 0.7500\n",
      "  Train Acc: 0.8025, Val Acc: 0.7143\n",
      "\n",
      "FOLD 2/5\n",
      "----------------------------------------\n",
      "Running SelectKBest feature selection...\n",
      "Testing k values: [5, 10, 15, 20, 25, 30, 40, 50]\n",
      "\n",
      "Testing k=5...\n",
      "  CV Score: 0.6669 (±0.0711)\n",
      "\n",
      "Testing k=10...\n",
      "  CV Score: 0.6316 (±0.0957)\n",
      "\n",
      "Testing k=15...\n",
      "  CV Score: 0.6300 (±0.1138)\n",
      "\n",
      "Testing k=20...\n",
      "  CV Score: 0.6257 (±0.1036)\n",
      "\n",
      "Testing k=25...\n",
      "  CV Score: 0.5959 (±0.1034)\n",
      "\n",
      "Testing k=30...\n",
      "  CV Score: 0.5767 (±0.0509)\n",
      "\n",
      "Testing k=40...\n",
      "  CV Score: 0.5863 (±0.0306)\n",
      "\n",
      "Testing k=50...\n",
      "  CV Score: 0.5709 (±0.0377)\n",
      "\n",
      "Best k: 5 with CV score: 0.6669\n",
      "Selected 5 features: [ 8 11 15 61 73]\n",
      "Selected 5 features out of 103 (k=5)\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "  Train AUC: 0.6850, Val AUC: 0.6442\n",
      "  Train Acc: 0.7407, Val Acc: 0.7143\n",
      "\n",
      "Evaluating GaussianNB...\n",
      "  Train AUC: 0.7095, Val AUC: 0.5962\n",
      "  Train Acc: 0.7284, Val Acc: 0.6667\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.7175, Val AUC: 0.6250\n",
      "  Train Acc: 0.6420, Val Acc: 0.6190\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.7175, Val AUC: 0.6250\n",
      "  Train Acc: 0.6420, Val Acc: 0.6190\n",
      "\n",
      "Evaluating DecisionTreeClassifier...\n",
      "  Train AUC: 0.8445, Val AUC: 0.5962\n",
      "  Train Acc: 0.7531, Val Acc: 0.6667\n",
      "\n",
      "Evaluating RandomForestClassifier...\n",
      "  Train AUC: 0.8561, Val AUC: 0.6058\n",
      "  Train Acc: 0.7654, Val Acc: 0.7143\n",
      "\n",
      "FOLD 3/5\n",
      "----------------------------------------\n",
      "Running SelectKBest feature selection...\n",
      "Testing k values: [5, 10, 15, 20, 25, 30, 40, 50]\n",
      "\n",
      "Testing k=5...\n",
      "  CV Score: 0.6748 (±0.0579)\n",
      "\n",
      "Testing k=10...\n",
      "  CV Score: 0.6465 (±0.0662)\n",
      "\n",
      "Testing k=15...\n",
      "  CV Score: 0.6072 (±0.0303)\n",
      "\n",
      "Testing k=20...\n",
      "  CV Score: 0.6076 (±0.0289)\n",
      "\n",
      "Testing k=25...\n",
      "  CV Score: 0.5871 (±0.0552)\n",
      "\n",
      "Testing k=30...\n",
      "  CV Score: 0.5763 (±0.0615)\n",
      "\n",
      "Testing k=40...\n",
      "  CV Score: 0.6034 (±0.1016)\n",
      "\n",
      "Testing k=50...\n",
      "  CV Score: 0.5191 (±0.0225)\n",
      "\n",
      "Best k: 5 with CV score: 0.6748\n",
      "Selected 5 features: [ 8 11 15 61 85]\n",
      "Selected 5 features out of 103 (k=5)\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "  Train AUC: 0.6801, Val AUC: 0.5714\n",
      "  Train Acc: 0.7073, Val Acc: 0.6500\n",
      "\n",
      "Evaluating GaussianNB...\n",
      "  Train AUC: 0.7045, Val AUC: 0.6923\n",
      "  Train Acc: 0.7195, Val Acc: 0.6500\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.7013, Val AUC: 0.6923\n",
      "  Train Acc: 0.6341, Val Acc: 0.6500\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.7013, Val AUC: 0.6923\n",
      "  Train Acc: 0.6341, Val Acc: 0.6500\n",
      "\n",
      "Evaluating DecisionTreeClassifier...\n",
      "  Train AUC: 0.8817, Val AUC: 0.5055\n",
      "  Train Acc: 0.7439, Val Acc: 0.6500\n",
      "\n",
      "Evaluating RandomForestClassifier...\n",
      "  Train AUC: 0.9846, Val AUC: 0.6154\n",
      "  Train Acc: 0.9390, Val Acc: 0.6500\n",
      "\n",
      "FOLD 4/5\n",
      "----------------------------------------\n",
      "Running SelectKBest feature selection...\n",
      "Testing k values: [5, 10, 15, 20, 25, 30, 40, 50]\n",
      "\n",
      "Testing k=5...\n",
      "  CV Score: 0.6324 (±0.0661)\n",
      "\n",
      "Testing k=10...\n",
      "  CV Score: 0.6132 (±0.0757)\n",
      "\n",
      "Testing k=15...\n",
      "  CV Score: 0.5314 (±0.0293)\n",
      "\n",
      "Testing k=20...\n",
      "  CV Score: 0.5259 (±0.0380)\n",
      "\n",
      "Testing k=25...\n",
      "  CV Score: 0.4984 (±0.0179)\n",
      "\n",
      "Testing k=30...\n",
      "  CV Score: 0.4961 (±0.0100)\n",
      "\n",
      "Testing k=40...\n",
      "  CV Score: 0.5150 (±0.0405)\n",
      "\n",
      "Testing k=50...\n",
      "  CV Score: 0.4899 (±0.0472)\n",
      "\n",
      "Best k: 5 with CV score: 0.6324\n",
      "Selected 5 features: [11 15 61 73 85]\n",
      "Selected 5 features out of 103 (k=5)\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "  Train AUC: 0.6609, Val AUC: 0.6703\n",
      "  Train Acc: 0.6829, Val Acc: 0.7500\n",
      "\n",
      "Evaluating GaussianNB...\n",
      "  Train AUC: 0.7218, Val AUC: 0.6593\n",
      "  Train Acc: 0.7073, Val Acc: 0.7500\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.7138, Val AUC: 0.6593\n",
      "  Train Acc: 0.6341, Val Acc: 0.6500\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.7135, Val AUC: 0.6593\n",
      "  Train Acc: 0.6341, Val Acc: 0.6500\n",
      "\n",
      "Evaluating DecisionTreeClassifier...\n",
      "  Train AUC: 0.8458, Val AUC: 0.4121\n",
      "  Train Acc: 0.8049, Val Acc: 0.5000\n",
      "\n",
      "Evaluating RandomForestClassifier...\n",
      "  Train AUC: 0.8827, Val AUC: 0.7033\n",
      "  Train Acc: 0.7927, Val Acc: 0.7000\n",
      "\n",
      "FOLD 5/5\n",
      "----------------------------------------\n",
      "Running SelectKBest feature selection...\n",
      "Testing k values: [5, 10, 15, 20, 25, 30, 40, 50]\n",
      "\n",
      "Testing k=5...\n",
      "  CV Score: 0.6724 (±0.0644)\n",
      "\n",
      "Testing k=10...\n",
      "  CV Score: 0.6656 (±0.0438)\n",
      "\n",
      "Testing k=15...\n",
      "  CV Score: 0.6103 (±0.0438)\n",
      "\n",
      "Testing k=20...\n",
      "  CV Score: 0.5298 (±0.0483)\n",
      "\n",
      "Testing k=25...\n",
      "  CV Score: 0.5236 (±0.0545)\n",
      "\n",
      "Testing k=30...\n",
      "  CV Score: 0.6561 (±0.0970)\n",
      "\n",
      "Testing k=40...\n",
      "  CV Score: 0.6149 (±0.0899)\n",
      "\n",
      "Testing k=50...\n",
      "  CV Score: 0.6012 (±0.0865)\n",
      "\n",
      "Best k: 5 with CV score: 0.6724\n",
      "Selected 5 features: [ 8 11 15 61 85]\n",
      "Selected 5 features out of 103 (k=5)\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "  Train AUC: 0.6840, Val AUC: 0.6044\n",
      "  Train Acc: 0.7317, Val Acc: 0.5500\n",
      "\n",
      "Evaluating GaussianNB...\n",
      "  Train AUC: 0.7192, Val AUC: 0.6484\n",
      "  Train Acc: 0.7195, Val Acc: 0.7000\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.7135, Val AUC: 0.6703\n",
      "  Train Acc: 0.6341, Val Acc: 0.6500\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.7135, Val AUC: 0.6648\n",
      "  Train Acc: 0.6341, Val Acc: 0.6500\n",
      "\n",
      "Evaluating DecisionTreeClassifier...\n",
      "  Train AUC: 0.9016, Val AUC: 0.5879\n",
      "  Train Acc: 0.8415, Val Acc: 0.6500\n",
      "\n",
      "Evaluating RandomForestClassifier...\n",
      "  Train AUC: 0.9596, Val AUC: 0.4286\n",
      "  Train Acc: 0.8902, Val Acc: 0.5500\n",
      "\n",
      "============================================================\n",
      "BUILDING CONSENSUS FEATURES FROM SELECTKBEST\n",
      "============================================================\n",
      "Best k values per fold: [15, 5, 5, 5, 5]\n",
      "Average best k: 7.0 ± 4.0\n",
      "k range: 5 - 15\n",
      "Consensus features: 6 selected\n",
      "Features selected in ≥3 folds: 6\n",
      "\n",
      "Feature Stability Analysis:\n",
      "  3 features selected in 5/5 folds\n",
      "  2 features selected in 4/5 folds\n",
      "  1 features selected in 3/5 folds\n",
      "  9 features selected in 1/5 folds\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION ON TEST SET\n",
      "============================================================\n",
      "Using 6 consensus features for final evaluation\n",
      "\n",
      "Final evaluation: LogisticRegression\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.5922 [0.3750, 0.8063] (valid reps = 1000)\n",
      "  Test AUC: 0.5938 [95% CI: 0.3750, 0.8063]\n",
      "  Test Accuracy: 0.5769\n",
      "\n",
      "Final evaluation: GaussianNB\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.5471 [0.3062, 0.7906] (valid reps = 1000)\n",
      "  Test AUC: 0.5437 [95% CI: 0.3062, 0.7906]\n",
      "  Test Accuracy: 0.6923\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.5796 [0.3188, 0.8312] (valid reps = 1000)\n",
      "  Test AUC: 0.5750 [95% CI: 0.3188, 0.8312]\n",
      "  Test Accuracy: 0.6154\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.5796 [0.3188, 0.8312] (valid reps = 1000)\n",
      "  Test AUC: 0.5750 [95% CI: 0.3188, 0.8312]\n",
      "  Test Accuracy: 0.6154\n",
      "\n",
      "Final evaluation: DecisionTreeClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7315 [0.5249, 0.9094] (valid reps = 1000)\n",
      "  Test AUC: 0.7281 [95% CI: 0.5249, 0.9094]\n",
      "  Test Accuracy: 0.6923\n",
      "\n",
      "Final evaluation: RandomForestClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6659 [0.4437, 0.8719] (valid reps = 1000)\n",
      "  Test AUC: 0.6625 [95% CI: 0.4437, 0.8719]\n",
      "  Test Accuracy: 0.6154\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE SELECTKBEST FEATURE SELECTION RESULTS\n",
      "================================================================================\n",
      "\n",
      "DATASET SUMMARY:\n",
      "- Total samples: 128 (Train: 102, Test: 26)\n",
      "- Original features: 103\n",
      "- Consensus features: 6\n",
      "- Class distribution: LRR=47 (36.7%), Non-LRR=81 (63.3%)\n",
      "\n",
      "SELECTKBEST PARAMETER SUMMARY:\n",
      "- k values tested per fold: varies (auto-determined)\n",
      "- Best k per fold: [15, 5, 5, 5, 5]\n",
      "- Average optimal k: 7.0 ± 4.0\n",
      "- k stability: 2 unique values across 5 folds\n",
      "\n",
      "CROSS-VALIDATION PERFORMANCE (Mean ± Std):\n",
      "--------------------------------------------------------------------------------\n",
      "Classifier           Train AUC       Val AUC         Train Acc       Val Acc         Avg Features\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression   0.692±0.030     0.604±0.050     0.721±0.022     0.657±0.071     7.0\n",
      "GaussianNB           0.716±0.008     0.659±0.036     0.711±0.017     0.706±0.044     7.0\n",
      "SVC                  0.707±0.011     0.692±0.066     0.637±0.004     0.638±0.015     7.0\n",
      "DecisionTreeClassifier 0.874±0.025     0.559±0.094     0.797±0.041     0.608±0.063     7.0\n",
      "RandomForestClassifier 0.923±0.048     0.621±0.110     0.838±0.066     0.666±0.062     7.0\n",
      "\n",
      "FINAL TEST PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\n",
      "----------------------------------------------------------------------\n",
      "Classifier           Test AUC [95% CI]         Test Accuracy  \n",
      "----------------------------------------------------------------------\n",
      "LogisticRegression   0.594 [0.375,0.806]     0.577\n",
      "GaussianNB           0.544 [0.306,0.791]     0.692\n",
      "SVC                  0.575 [0.319,0.831]     0.615\n",
      "DecisionTreeClassifier 0.728 [0.525,0.909]     0.692\n",
      "RandomForestClassifier 0.663 [0.444,0.872]     0.615\n",
      "\n",
      "BEST TEST PERFORMANCE: DecisionTreeClassifier\n",
      "Test AUC: 0.7281 [95% CI: 0.5249, 0.9094]\n",
      "Test Accuracy: 0.6923\n",
      "\n",
      "FEATURE SELECTION EFFECTIVENESS:\n",
      "- Dimensionality reduction: 103 → 6 features (5.8% retained)\n",
      "- Feature stability: 6/15 features appeared in ≥3/5 folds\n",
      "\n",
      "================================================================================\n",
      "SELECTKBEST FEATURE SELECTION PIPELINE COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ---- Load data and extract radiomics features/labels ----\n",
    "    radiomics_data, clinical_data = load_data()\n",
    "    radiomics_cols = get_radiomics_columns(radiomics_data)\n",
    "    X_raw = radiomics_data[radiomics_cols].values\n",
    "    y = clinical_data[\"LocoRegeonalRecurrence\"].values\n",
    "\n",
    "    # Print dataset information\n",
    "    print(\"DATASET INFORMATION:\")\n",
    "    print(f\"Total samples: {len(X_raw)}\")\n",
    "    print(f\"Total features: {X_raw.shape[1]}\")\n",
    "    print(f\"Class distribution: LRR={np.sum(y)}, Non-LRR={len(y)-np.sum(y)}\")\n",
    "    print(f\"LRR percentage: {100*np.sum(y)/len(y):.1f}%\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 1) Hold-out TEST set (20%), keep untouched till the very end\n",
    "    # ===============================================================\n",
    "    X_temp, X_test_raw, y_temp, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"\\nDATA SPLIT:\")\n",
    "    print(f\"Train/val samples: {len(X_temp)}\")\n",
    "    print(f\"Test samples: {len(X_test_raw)}\")\n",
    "    print(f\"Train/val class dist: LRR={np.sum(y_temp)}, Non-LRR={len(y_temp)-np.sum(y_temp)}\")\n",
    "    print(f\"Test class dist: LRR={np.sum(y_test)}, Non-LRR={len(y_test)-np.sum(y_test)}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 2) SELECTKBEST Feature Selection with Cross-Validation\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SELECTKBEST FEATURE SELECTION WITH 5-FOLD CROSS-VALIDATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Define classifiers for evaluation\n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        GaussianNB(),\n",
    "        SVC(kernel='linear', probability=True),\n",
    "        SVC(kernel='rbf', probability=True),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    ]\n",
    "\n",
    "    # 5-fold stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Storage for cross-validation results\n",
    "    cv_results = {}\n",
    "    for clf in classifiers:\n",
    "        cv_results[clf.__class__.__name__] = {\n",
    "            'train_aucs': [], 'val_aucs': [], 'train_accs': [], 'val_accs': [], 'n_features': []\n",
    "        }\n",
    "\n",
    "    fold_selected_features = []  # Store selected features for each fold\n",
    "    fold_best_k_values = []      # Store best k for each fold\n",
    "    fold_k_cv_scores = []        # Store k optimization scores for each fold\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold_id, (train_idx, val_idx) in enumerate(skf.split(X_temp, y_temp), 1):\n",
    "        print(f\"\\nFOLD {fold_id}/5\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        X_train_fold, X_val_fold = X_temp[train_idx], X_temp[val_idx]\n",
    "        y_train_fold, y_val_fold = y_temp[train_idx], y_temp[val_idx]\n",
    "\n",
    "        # Standardize features (fit on train, transform both train and val)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "        # SelectKBest feature selection on training fold\n",
    "        print(f\"Running SelectKBest feature selection...\")\n",
    "        best_k, selected_features_idx, k_cv_scores = selectkbest_feature_selection(\n",
    "            X_train_scaled, y_train_fold, \n",
    "            k_values=None,  # Use default k values\n",
    "            cv=3,           # Use 3-fold CV within each training fold\n",
    "            scoring='roc_auc'\n",
    "        )\n",
    "        \n",
    "        fold_selected_features.append(selected_features_idx)\n",
    "        fold_best_k_values.append(best_k)\n",
    "        fold_k_cv_scores.append(k_cv_scores)\n",
    "        n_selected = len(selected_features_idx)\n",
    "        print(f\"Selected {n_selected} features out of {X_train_scaled.shape[1]} (k={best_k})\")\n",
    "\n",
    "        if n_selected == 0:\n",
    "            print(\"⚠️ No features selected in this fold. Skipping evaluation.\")\n",
    "            continue\n",
    "\n",
    "        # Apply feature selection\n",
    "        X_train_selected = X_train_scaled[:, selected_features_idx]\n",
    "        X_val_selected = X_val_scaled[:, selected_features_idx]\n",
    "\n",
    "        # Evaluate each classifier with selected features\n",
    "        for clf in classifiers:\n",
    "            print(f\"\\nEvaluating {clf.__class__.__name__}...\")\n",
    "            \n",
    "            # Tune hyperparameters on selected features\n",
    "            tuned_clf = get_tuned_model(clf, X_train_selected, y_train_fold)\n",
    "            tuned_clf.fit(X_train_selected, y_train_fold)\n",
    "\n",
    "            # Predictions\n",
    "            if hasattr(tuned_clf, 'predict_proba'):\n",
    "                y_train_proba = tuned_clf.predict_proba(X_train_selected)[:, 1]\n",
    "                y_val_proba = tuned_clf.predict_proba(X_val_selected)[:, 1]\n",
    "            else:\n",
    "                y_train_proba = tuned_clf.decision_function(X_train_selected)\n",
    "                y_val_proba = tuned_clf.decision_function(X_val_selected)\n",
    "\n",
    "            y_train_pred = tuned_clf.predict(X_train_selected)\n",
    "            y_val_pred = tuned_clf.predict(X_val_selected)\n",
    "\n",
    "            # Calculate metrics\n",
    "            train_auc = roc_auc_score(y_train_fold, y_train_proba)\n",
    "            val_auc = roc_auc_score(y_val_fold, y_val_proba)\n",
    "            train_acc = accuracy_score(y_train_fold, y_train_pred)\n",
    "            val_acc = accuracy_score(y_val_fold, y_val_pred)\n",
    "\n",
    "            # Store results\n",
    "            cv_results[clf.__class__.__name__]['train_aucs'].append(train_auc)\n",
    "            cv_results[clf.__class__.__name__]['val_aucs'].append(val_auc)\n",
    "            cv_results[clf.__class__.__name__]['train_accs'].append(train_acc)\n",
    "            cv_results[clf.__class__.__name__]['val_accs'].append(val_acc)\n",
    "            cv_results[clf.__class__.__name__]['n_features'].append(n_selected)\n",
    "\n",
    "            print(f\"  Train AUC: {train_auc:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "            print(f\"  Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 3) Build consensus features from cross-validation\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BUILDING CONSENSUS FEATURES FROM SELECTKBEST\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    print(f\"Best k values per fold: {fold_best_k_values}\")\n",
    "    if fold_best_k_values:\n",
    "        print(f\"Average best k: {np.mean(fold_best_k_values):.1f} ± {np.std(fold_best_k_values):.1f}\")\n",
    "        print(f\"k range: {min(fold_best_k_values)} - {max(fold_best_k_values)}\")\n",
    "\n",
    "    # Create consensus from fold selections\n",
    "    if fold_selected_features:\n",
    "        all_features = set()\n",
    "        for features in fold_selected_features:\n",
    "            all_features.update(features)\n",
    "        \n",
    "        # Count how many times each feature was selected\n",
    "        feature_counts = {}\n",
    "        for feature_idx in all_features:\n",
    "            count = sum(1 for features in fold_selected_features if feature_idx in features)\n",
    "            feature_counts[feature_idx] = count\n",
    "\n",
    "        # Select features that appear in at least 3/5 folds\n",
    "        consensus_threshold = 3\n",
    "        consensus_features = [idx for idx, count in feature_counts.items() if count >= consensus_threshold]\n",
    "        \n",
    "        # Fallback: if no features meet threshold, use union\n",
    "        if not consensus_features:\n",
    "            consensus_features = list(all_features)\n",
    "            print(f\"Warning: No features met {consensus_threshold}/5 threshold. Using union of all selections.\")\n",
    "        \n",
    "        consensus_features = sorted(consensus_features)\n",
    "        print(f\"Consensus features: {len(consensus_features)} selected\")\n",
    "        print(f\"Features selected in ≥{consensus_threshold} folds: {len([c for c in feature_counts.values() if c >= consensus_threshold])}\")\n",
    "        \n",
    "        # Show feature stability analysis\n",
    "        print(f\"\\nFeature Stability Analysis:\")\n",
    "        stability_counts = {}\n",
    "        for count in feature_counts.values():\n",
    "            stability_counts[count] = stability_counts.get(count, 0) + 1\n",
    "        for stability, count in sorted(stability_counts.items(), reverse=True):\n",
    "            print(f\"  {count} features selected in {stability}/5 folds\")\n",
    "    else:\n",
    "        print(\"No features selected in any fold!\")\n",
    "        consensus_features = []\n",
    "\n",
    "    # ===============================================================\n",
    "    # 4) Final evaluation on test set with consensus features\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL EVALUATION ON TEST SET\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if consensus_features:\n",
    "        # Scale full training data and test data\n",
    "        scaler_final = StandardScaler()\n",
    "        X_train_final_scaled = scaler_final.fit_transform(X_temp)\n",
    "        X_test_final_scaled = scaler_final.transform(X_test_raw)\n",
    "\n",
    "        # Apply consensus feature selection\n",
    "        X_train_final = X_train_final_scaled[:, consensus_features]\n",
    "        X_test_final = X_test_final_scaled[:, consensus_features]\n",
    "\n",
    "        print(f\"Using {len(consensus_features)} consensus features for final evaluation\")\n",
    "\n",
    "        # Final results storage\n",
    "        final_results = {}\n",
    "\n",
    "        for clf in classifiers:\n",
    "            print(f\"\\nFinal evaluation: {clf.__class__.__name__}\")\n",
    "            \n",
    "            # Tune and train on full training set with consensus features\n",
    "            tuned_clf_final = get_tuned_model(clf, X_train_final, y_temp)\n",
    "            tuned_clf_final.fit(X_train_final, y_temp)\n",
    "\n",
    "            # Test set predictions\n",
    "            if hasattr(tuned_clf_final, 'predict_proba'):\n",
    "                y_test_proba = tuned_clf_final.predict_proba(X_test_final)[:, 1]\n",
    "            else:\n",
    "                y_test_proba = tuned_clf_final.decision_function(X_test_final)\n",
    "\n",
    "            y_test_pred = tuned_clf_final.predict(X_test_final)\n",
    "\n",
    "            # Calculate test metrics\n",
    "            test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "            test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "            # Bootstrap CI for test AUC\n",
    "            test_mean_auc, test_lower, test_upper, test_valid = bootstrap_final_model_auc_ci(\n",
    "                y_test, y_test_proba, n_bootstrap=1000\n",
    "            )\n",
    "\n",
    "            final_results[clf.__class__.__name__] = {\n",
    "                'test_auc': test_auc,\n",
    "                'test_acc': test_acc,\n",
    "                'auc_ci_lower': test_lower,\n",
    "                'auc_ci_upper': test_upper\n",
    "            }\n",
    "\n",
    "            print(f\"  Test AUC: {test_auc:.4f} [95% CI: {test_lower:.4f}, {test_upper:.4f}]\")\n",
    "            print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 5) COMPREHENSIVE RESULTS SUMMARY\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COMPREHENSIVE SELECTKBEST FEATURE SELECTION RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    print(f\"\\nDATASET SUMMARY:\")\n",
    "    print(f\"- Total samples: {len(X_raw)} (Train: {len(X_temp)}, Test: {len(X_test_raw)})\")\n",
    "    print(f\"- Original features: {X_raw.shape[1]}\")\n",
    "    print(f\"- Consensus features: {len(consensus_features) if consensus_features else 0}\")\n",
    "    print(f\"- Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%), Non-LRR={len(y)-np.sum(y)} ({100*(len(y)-np.sum(y))/len(y):.1f}%)\")\n",
    "\n",
    "    # SelectKBest parameter summary\n",
    "    if fold_best_k_values:\n",
    "        print(f\"\\nSELECTKBEST PARAMETER SUMMARY:\")\n",
    "        print(f\"- k values tested per fold: varies (auto-determined)\")\n",
    "        print(f\"- Best k per fold: {fold_best_k_values}\")\n",
    "        print(f\"- Average optimal k: {np.mean(fold_best_k_values):.1f} ± {np.std(fold_best_k_values):.1f}\")\n",
    "        print(f\"- k stability: {len(set(fold_best_k_values))} unique values across 5 folds\")\n",
    "\n",
    "    # Cross-validation performance summary\n",
    "    print(f\"\\nCROSS-VALIDATION PERFORMANCE (Mean ± Std):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Classifier':<20} {'Train AUC':<15} {'Val AUC':<15} {'Train Acc':<15} {'Val Acc':<15} {'Avg Features':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for clf_name, results in cv_results.items():\n",
    "        if results['train_aucs']:  # Only if we have results\n",
    "            train_auc_mean = np.mean(results['train_aucs'])\n",
    "            train_auc_std = np.std(results['train_aucs'])\n",
    "            val_auc_mean = np.mean(results['val_aucs'])\n",
    "            val_auc_std = np.std(results['val_aucs'])\n",
    "            train_acc_mean = np.mean(results['train_accs'])\n",
    "            train_acc_std = np.std(results['train_accs'])\n",
    "            val_acc_mean = np.mean(results['val_accs'])\n",
    "            val_acc_std = np.std(results['val_accs'])\n",
    "            avg_features = np.mean(results['n_features'])\n",
    "            \n",
    "            print(f\"{clf_name:<20} {train_auc_mean:.3f}±{train_auc_std:.3f}     {val_auc_mean:.3f}±{val_auc_std:.3f}     {train_acc_mean:.3f}±{train_acc_std:.3f}     {val_acc_mean:.3f}±{val_acc_std:.3f}     {avg_features:.1f}\")\n",
    "\n",
    "    # Final test performance\n",
    "    if consensus_features and final_results:\n",
    "        print(f\"\\nFINAL TEST PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"{'Classifier':<20} {'Test AUC [95% CI]':<25} {'Test Accuracy':<15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for clf_name, results in final_results.items():\n",
    "            test_auc = results['test_auc']\n",
    "            test_lower = results['auc_ci_lower']\n",
    "            test_upper = results['auc_ci_upper']\n",
    "            test_acc = results['test_acc']\n",
    "            \n",
    "            print(f\"{clf_name:<20} {test_auc:.3f} [{test_lower:.3f},{test_upper:.3f}]     {test_acc:.3f}\")\n",
    "\n",
    "        # Best performing classifier\n",
    "        best_test_clf = max(final_results.keys(), key=lambda x: final_results[x]['test_auc'])\n",
    "        best_test_auc = final_results[best_test_clf]['test_auc']\n",
    "        best_test_acc = final_results[best_test_clf]['test_acc']\n",
    "        best_test_lower = final_results[best_test_clf]['auc_ci_lower']\n",
    "        best_test_upper = final_results[best_test_clf]['auc_ci_upper']\n",
    "        \n",
    "        print(f\"\\nBEST TEST PERFORMANCE: {best_test_clf}\")\n",
    "        print(f\"Test AUC: {best_test_auc:.4f} [95% CI: {best_test_lower:.4f}, {best_test_upper:.4f}]\")\n",
    "        print(f\"Test Accuracy: {best_test_acc:.4f}\")\n",
    "\n",
    "        # Feature selection effectiveness\n",
    "        print(f\"\\nFEATURE SELECTION EFFECTIVENESS:\")\n",
    "        print(f\"- Dimensionality reduction: {X_raw.shape[1]} → {len(consensus_features)} features ({100*len(consensus_features)/X_raw.shape[1]:.1f}% retained)\")\n",
    "        print(f\"- Feature stability: {len([c for c in feature_counts.values() if c >= 3])}/{len(feature_counts)} features appeared in ≥3/5 folds\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ No consensus features found or final evaluation skipped.\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SELECTKBEST FEATURE SELECTION PIPELINE COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Optional: Return results for further analysis\n",
    "    results_dict = {\n",
    "        'cv_results': cv_results,\n",
    "        'final_results': final_results if 'final_results' in locals() else None,\n",
    "        'consensus_features': consensus_features,\n",
    "        'fold_best_k_values': fold_best_k_values,\n",
    "        'feature_counts': feature_counts if 'feature_counts' in locals() else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
