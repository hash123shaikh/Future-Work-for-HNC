{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === **LASSO for Feature Selection to optimize feature subsets for various ML classifiers** ===\n",
    "\n",
    "-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Stable Feature Pre-selection:**\n",
    "\n",
    "* Performed initial feature selection using **bootstrapped LASSO logistic regression** (`penalty='l1'`, `solver='liblinear'`, `cv=5`, `max_iter=5000`), repeated for **100 bootstrap samples** (`n_bootstrap=100`). Features were retained if selected in **≥70%** of bootstraps (`freq_threshold=0.7`), ensuring stability against sampling variance.\n",
    "\n",
    "\n",
    "**2. Metaheuristic Feature Selection:**\n",
    "\n",
    "* Applies **Particle Swarm Optimization (PSO)** for further feature selection from the stable set, using a population of **20 particles** (`n_particles=20`) and **50 iterations** (`max_iter=50`). Each particle represented a binary feature mask, and the swarm was optimized to maximize mean ROC AUC over 5-fold stratified cross-validation (`StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`).\n",
    "\n",
    "\n",
    "**3. Comprehensive Classifier Comparison:**\n",
    "\n",
    "* Evaluated a broad suite of classifiers:\n",
    "\n",
    "  * **Logistic Regression** (`max_iter=1000`), with grid search over `C=[0.001, 0.01, 0.1, 1, 10]` and `penalty=['l1', 'l2']`\n",
    "\n",
    "  * **Gaussian Naive Bayes** (default parameters)\n",
    "\n",
    "  * **Support Vector Machines** (linear and RBF kernels, `C=[0.01, 0.1, 1, 10]`, `gamma=['scale', 'auto']`)\n",
    "\n",
    "  * **Decision Tree** (`max_depth=[3, 5, 7]`, `min_samples_split=[5, 10]`, `min_samples_leaf=[2, 4]`)\n",
    "\n",
    "  * **Random Forest** (`n_estimators=[100, 200]`, `max_depth=[5, 10]`, `min_samples_split=[5, 10]`, `min_samples_leaf=[2, 4]`)\n",
    "\n",
    "  * **VotingClassifier** ensemble combining top-tuned base models with soft voting.\n",
    "\n",
    "* Hyperparameters were tuned for each classifier using **GridSearchCV** and 5-fold stratified cross-validation, optimizing for ROC AUC.\n",
    "\n",
    "\n",
    "**4. Class Imbalance and Data Integrity Handling:**\n",
    "\n",
    "* Maintained **class distribution balance** in all data splits using stratified sampling, both in train/test partitioning (`test_size=0.2`) and during cross-validation.\n",
    "\n",
    "* For bootstrapping and CI estimation, ensured that each resample included both classes—skipping samples otherwise to avoid invalid AUC calculations.\n",
    "\n",
    "\n",
    "**5. Feature Scaling and Pipeline Safety:**\n",
    "\n",
    "* Applied **feature standardization** (`StandardScaler()`) within all pipelines, fitting scalers only on training data to prevent information leakage.\n",
    "\n",
    "* Model pipelines (`make_pipeline(StandardScaler(), classifier)`) ensured consistent preprocessing during evaluation and prediction.\n",
    "\n",
    "\n",
    "**6. Model Evaluation & Uncertainty Quantification:**\n",
    "\n",
    "* Reported **ROC AUC and accuracy** for both training and testing sets at each PSO iteration.\n",
    "\n",
    "* Computed **bootstrapped confidence intervals** for test AUC (`n_bootstrap=1000`, `ci=0.95`), resampling test predictions to quantify model uncertainty and generalization performance.\n",
    "\n",
    "\n",
    "**7. Visualization and Monitoring:**\n",
    "\n",
    "* Plotted **train/test AUC trends** across PSO iterations for convergence analysis.\n",
    "\n",
    "* Displayed final **ROC curves** for both training and testing sets, including mean AUC and 95% confidence intervals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === IMPORTS ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                                            # Core numerical computation library for arrays and matrix operations\n",
    "import pandas as pd                                                                           # Library for data manipulation and analysis (tabular data, DataFrames)\n",
    "from sklearn.base import clone                                                                # For cloning estimators (useful when building pipelines or doing cross-validation)\n",
    "import matplotlib.pyplot as plt                                                               # For plotting graphs (e.g., ROC curves, feature importances, etc.)\n",
    "from scipy.stats import bootstrap                                                             # For statistical bootstrap resampling (scipy's bootstrap is for CI, sklearn's resample for random sampling)\n",
    "from sklearn.utils import resample                                                            # Utility to randomly resample datasets (e.g., for bootstrapping in ML)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold        # For splitting data, cross-validation, and stratified folds (for imbalanced classes)\n",
    "from sklearn.preprocessing import StandardScaler                                              # For scaling features to zero mean/unit variance (important for many ML algorithms)\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score                          # For evaluating model performance: ROC AUC, ROC curve points, accuracy\n",
    "\n",
    "# === CLASSIFIERS ===\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB                                                    # Naive Bayes classifier for classification tasks\n",
    "from sklearn.svm import SVC                                                                   # Support Vector Classifier (linear & nonlinear SVMs)\n",
    "from sklearn.tree import DecisionTreeClassifier                                               # Decision Tree classifier (nonlinear, interpretable ML model)\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier                         # Random Forest classifier (ensemble of Decision Trees)\n",
    "from sklearn.pipeline import make_pipeline                                                    # For creating machine learning pipelines (combining preprocessing + models)\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV                     # Logistic Regression (standard and cross-validated, for classification)\n",
    "\n",
    "# === GRID SEARCH HYPERPARAMETER TUNING ===\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV                                              # For exhaustive grid search over hyperparameters with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === LOAD AND PREPROCESS DATA ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Load radiomics and clinical CSV files into DataFrames\n",
    "    radiomics = pd.read_csv(\"./HNC-Prospective-Radiomics-305.csv\")\n",
    "    clinical = pd.read_csv(\"./proceed_radiomics_128.csv\")\n",
    "\n",
    "    print(f\"Initial clinical data: {len(clinical)} patients\")\n",
    "    # print(f\"Unique locations in clinical data: {clinical['Location'].value_counts()}\")\n",
    "\n",
    "    # Filter clinical data to only include specific tumor locations\n",
    "    # clinical = clinical[clinical[\"Location\"].isin(['Larynx', 'Tonsil', 'Hypopharynx', 'Oropharynx', 'BOT', 'Other'])]\n",
    "    # print(f\"After location filtering: {len(clinical)} patients\")\n",
    "\n",
    "    # Standardize 'research_subject_uid' in radiomics by keeping only the part before \"_\"\n",
    "    radiomics[\"research_subject_uid\"] = radiomics[\"research_subject_uid\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "    # Remove any leading/trailing spaces from 'Project ID' in clinical data\n",
    "    clinical[\"Project ID\"] = clinical[\"Project ID\"].str.strip()\n",
    "\n",
    "    # Filter radiomics to only keep rows with research_subject_uid present in clinical Project IDs\n",
    "    radiomics_filtered = radiomics[radiomics[\"research_subject_uid\"].isin(clinical[\"Project ID\"])]\n",
    "    \n",
    "    # Filter clinical to only keep rows with Project ID present in radiomics research_subject_uid\n",
    "    clinical_filtered = clinical[clinical[\"Project ID\"].isin(radiomics[\"research_subject_uid\"])]\n",
    "\n",
    "    print(f\"Final matched data: {len(clinical_filtered)} patients\")\n",
    "\n",
    "    # Sort both DataFrames by their ID columns and reset their indices\n",
    "    radiomics_filtered = radiomics_filtered.sort_values(by=\"research_subject_uid\").reset_index(drop=True)\n",
    "    clinical_filtered = clinical_filtered.sort_values(by=\"Project ID\").reset_index(drop=True)\n",
    "\n",
    "    # Return the filtered and aligned DataFrames for further processing\n",
    "    return radiomics_filtered, clinical_filtered\n",
    "\n",
    "\n",
    "def get_radiomics_columns(data):\n",
    "    \"\"\"\n",
    "    Returns the columns from 'original_shape_Elongation' to 'original_ngtdm_Strength'.\n",
    "    These typically represent the set of radiomics features you want to extract.\n",
    "    \"\"\"\n",
    "    start_column = \"original_shape_Elongation\"\n",
    "    end_column = \"original_ngtdm_Strength\"\n",
    "    start_idx = data.columns.get_loc(start_column)\n",
    "    end_idx = data.columns.get_loc(end_column) + 1  # +1 to include the end column itself\n",
    "    return data.columns[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Define hyperparameter grids for each classifier ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These grids help tune the model to avoid overfitting by optimizing regularization and other key parameters.\n",
    "all_grid_params = {\n",
    "    'LogisticRegression': {\n",
    "        'C': [1e-4, 3e-4, 1e-3, 3e-3, 1e-2, 3e-2, 0.1, 0.3, 1, 3, 10],          # Regularization strength (lower = stronger regularization)\n",
    "        'penalty': ['l1', 'l2'],                                                # Type of regularization: L1 (Lasso), L2 (Ridge)\n",
    "        'solver': ['liblinear'],                                                # Solver that supports both l1 and l2\n",
    "        'class_weight': [None, \"balanced\"],\n",
    "        'max_iter': [1000],\n",
    "    },\n",
    "    'GaussianNB': {},                                                           # No tunable hyperparameters for basic Naive Bayes\n",
    "    'SVC': [\n",
    "        # Linear SVC\n",
    "        {\n",
    "            'C': [1e-3, 1e-2, 0.1, 1, 10],                                      # Regularization strength\n",
    "            'kernel': ['linear'],                                               # Linear kernel\n",
    "            'probability': [True],                                              # Needed for probability predictions (e.g., ROC AUC)\n",
    "            'class_weight': [None, \"balanced\"],\n",
    "        },\n",
    "        # RBF SVC\n",
    "        {\n",
    "            'C': [1e-3, 1e-2, 0.1, 1, 10],                                      # Regularization strength\n",
    "            'gamma': ['scale', 'auto', 1e-3, 1e-2, 1e-1],                       # Kernel coefficient for RBF\n",
    "            'kernel': ['rbf'],                                                  # RBF (nonlinear) kernel\n",
    "            'probability': [True],                                              # Probability estimates\n",
    "            'class_weight': [None, \"balanced\"],\n",
    "        }\n",
    "    ],\n",
    "    'DecisionTreeClassifier': {\n",
    "        'criterion': ['gini', 'entropy'],                                       # Split quality metric\n",
    "        'max_depth': [2, 3, 4, 5, 7],                                           # Controls tree depth (regularization)\n",
    "        'min_samples_split': [5, 10, 15],                                       # Minimum samples required to split a node\n",
    "        'min_samples_leaf': [2, 4, 6],                                          # Minimum samples per leaf node\n",
    "        'max_features': ['sqrt', 'log2', None],                                 # Number of features considered at each split\n",
    "        'class_weight': [None, \"balanced\"],\n",
    "        'random_state': [42],\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [100, 200, 400],                                        # Number of trees\n",
    "        'max_depth': [3, 5, 7, 10],                                             # Maximum depth of trees\n",
    "        'min_samples_split': [5, 10],                                           # Minimum samples to split an internal node\n",
    "        'min_samples_leaf': [2, 4],                                             # Minimum samples at a leaf node\n",
    "        'max_features': ['sqrt', 'log2'],                                       # Number of features considered at each split\n",
    "        'bootstrap': [True],                                                    # Use bootstrap samples\n",
    "        'n_jobs': [-1],                                                         # Use all available CPU cores for parallel processing\n",
    "        'class_weight': [None, \"balanced\", \"balanced_subsample\"],\n",
    "        'random_state': [42],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# === Utility function to tune a classifier's hyperparameters using grid search and cross-validation ===\n",
    "\n",
    "def get_tuned_model(classifier, X_train, y_train):\n",
    "    name = classifier.__class__.__name__                                 # Get class name as a string (e.g., 'LogisticRegression')\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)      # 5-fold stratified cross-validation\n",
    "    \n",
    "    # Special handling for SVC as its grid is a list (to support both linear & RBF kernels)\n",
    "    if name == 'SVC':\n",
    "        grid = GridSearchCV(\n",
    "            clone(classifier),            # Clone base estimator to avoid data leakage between folds\n",
    "            all_grid_params['SVC'],\n",
    "            scoring='roc_auc',            # Use ROC AUC for model selection (works for imbalanced data)\n",
    "            cv=cv,                        # Use stratified k-fold\n",
    "            n_jobs=-1,                    # Use all CPU cores\n",
    "            refit=True,\n",
    "        )\n",
    "        grid.fit(X_train, y_train)       # Fit grid search\n",
    "        return grid.best_estimator_      # Return the model with best hyperparameters\n",
    "\n",
    "    # For all other classifiers with defined grid parameters\n",
    "    elif name in all_grid_params and all_grid_params[name]:\n",
    "        grid = GridSearchCV(\n",
    "            clone(classifier),\n",
    "            all_grid_params[name],\n",
    "            scoring='roc_auc',\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "            refit=True,\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        return grid.best_estimator_\n",
    "\n",
    "    # If no hyperparameters to tune (e.g., GaussianNB), return the original classifier\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === BOOTSTRAP LASSO FEATURE SELECTION ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_lasso_fs(X, y, n_bootstrap=1000, freq_threshold=0.5, random_state=42):\n",
    "    \"\"\"\n",
    "    Selects stable features using bootstrapped Lasso logistic regression.\n",
    "    - X: feature matrix (numpy array)\n",
    "    - y: target labels\n",
    "    - n_bootstrap: number of bootstrap samples to draw\n",
    "    - freq_threshold: minimum frequency for a feature to be considered stable\n",
    "    - random_state: for reproducibility\n",
    "\n",
    "    Returns the indices of stable features.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    selected_counts = np.zeros(X.shape[1])  # To count selection frequency for each feature\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        # Resample data with replacement (bootstrapping), stratified by class\n",
    "        X_resampled, y_resampled = resample(X, y, stratify=y, random_state=random_state+i)\n",
    "        \n",
    "        # L1-penalized logistic regression with cross-validation for feature selection\n",
    "        model = LogisticRegressionCV(\n",
    "            penalty='l1',\n",
    "            solver='liblinear',\n",
    "            cv=5,\n",
    "            scoring='roc_auc',\n",
    "            max_iter=1000,\n",
    "            n_jobs=-1,\n",
    "            refit=True\n",
    "        ).fit(X_resampled, y_resampled)\n",
    "\n",
    "        # Count features selected (non-zero coefficient means selected)\n",
    "        selected_counts += (model.coef_[0] != 0).astype(int)\n",
    "\n",
    "    # Calculate frequency of each feature being selected across bootstraps\n",
    "    selected_frequency = selected_counts / n_bootstrap\n",
    "\n",
    "    # Select features whose selection frequency >= threshold\n",
    "    stable_features_idx = np.where(selected_frequency >= freq_threshold)[0]\n",
    "\n",
    "    print(f\"Stable features selected: {len(stable_features_idx)} out of {X.shape[1]}\")\n",
    "    print(f\"Selected feature indices: {stable_features_idx}\")\n",
    "    return stable_features_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Evaluate model with classifier function ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_classifier(X_train, X_test, y_train, y_test, selected_features, feature_names, classifier):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a given classifier using only the features selected by a feature selection algorithm.\n",
    "    Prints Train/Test AUC and Accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train, X_test: Feature matrices (numpy arrays)\n",
    "        y_train, y_test: Labels\n",
    "        selected_features: Binary vector indicating which features to use\n",
    "        feature_names: List of feature names (not used here, but useful for further reporting)\n",
    "        classifier: Classifier instance (e.g., LogisticRegression)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select only the features chosen by the feature selection mask\n",
    "    X_train_sel = X_train[:, selected_features == 1]\n",
    "    X_test_sel = X_test[:, selected_features == 1]\n",
    "\n",
    "    # If no features were selected, print a warning and stop\n",
    "    if X_train_sel.shape[1] == 0:\n",
    "        print(\"\\n⚠️ No features selected. Cannot train classifier.\")\n",
    "        return\n",
    "\n",
    "    # Build pipeline: scale features then fit classifier\n",
    "    model = make_pipeline(StandardScaler(), classifier)\n",
    "    model.fit(X_train_sel, y_train)  # Train the model on selected features\n",
    "\n",
    "    # Get predicted probabilities or decision function for AUC\n",
    "    y_train_proba = model.predict_proba(X_train_sel)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_train_sel)\n",
    "    y_test_proba = model.predict_proba(X_test_sel)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_test_sel)\n",
    "\n",
    "    # Get predicted labels for accuracy\n",
    "    y_train_pred = model.predict(X_train_sel)\n",
    "    y_test_pred = model.predict(X_test_sel)\n",
    "\n",
    "    # Print evaluation metrics for train and test sets\n",
    "    print(f\"\\n✅ Results for {classifier.__class__.__name__}:\")\n",
    "    print(f\"Train AUC: {roc_auc_score(y_train, y_train_proba):.4f}\")\n",
    "    print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "    print(f\"Test AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Computes a bootstrapped confidence interval for ROC AUC of the final model ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_final_model_auc_ci(\n",
    "    y_true,\n",
    "    y_pred_proba,\n",
    "    n_bootstrap: int = 1000,\n",
    "    ci: float = 0.95,\n",
    "    random_state: int = 42,\n",
    "    min_valid: int = 200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Stratified bootstrap CI for ROC AUC on small/imbalanced test sets.\n",
    "    - Preserves class counts in each bootstrap sample (positives/negatives drawn separately).\n",
    "    - Avoids invalid replicates with a single class.\n",
    "    - Returns mean AUC and (lower, upper) percentile CI.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        True binary labels. If not exactly {0,1}, they will be remapped to {0,1} by ordering.\n",
    "    y_pred_proba : array-like\n",
    "        Predicted probabilities or decision scores (higher = more likely positive).\n",
    "    n_bootstrap : int, default=2000\n",
    "        Number of bootstrap replicates.\n",
    "    ci : float, default=0.95\n",
    "        Confidence level (e.g., 0.95 for 95% CI).\n",
    "    random_state : int, default=42\n",
    "        Seed for reproducibility.\n",
    "    min_valid : int, default=200\n",
    "        Minimum recommended number of valid bootstrap replicates for a stable CI.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean_auc : float\n",
    "    lower : float\n",
    "    upper : float\n",
    "    valid : int\n",
    "        Number of valid bootstrap replicates used.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    y_true = y_true.values if hasattr(y_true, \"values\") else np.asarray(y_true)\n",
    "    y_pred_proba = y_pred_proba.values if hasattr(y_pred_proba, \"values\") else np.asarray(y_pred_proba)\n",
    "\n",
    "    # Basic checks\n",
    "    if y_true.shape[0] != y_pred_proba.shape[0]:\n",
    "        raise ValueError(\"y_true and y_pred_proba must have the same number of samples.\")\n",
    "\n",
    "    uniq = np.unique(y_true)\n",
    "    if uniq.size < 2:\n",
    "        raise ValueError(\"AUC undefined: test set has a single class.\")\n",
    "    if uniq.size > 2:\n",
    "        # Remap to binary by ordering (largest label -> positive class)\n",
    "        # This allows labels like {-1, +1} or {0, 2}\n",
    "        pos_label = uniq.max()\n",
    "        y_true = (y_true == pos_label).astype(int)\n",
    "        uniq = np.array([0, 1])\n",
    "\n",
    "    # Class counts\n",
    "    n_pos = int((y_true == 1).sum())\n",
    "    n_neg = int((y_true == 0).sum())\n",
    "    if min(n_pos, n_neg) < 3:\n",
    "        print(f\"Warning: very few positives/negatives (pos={n_pos}, neg={n_neg}); CI will be unstable.\")\n",
    "\n",
    "    # Index pools by class\n",
    "    pos_idx = np.where(y_true == 1)[0]\n",
    "    neg_idx = np.where(y_true == 0)[0]\n",
    "\n",
    "    aucs = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Stratified resample: draw with replacement within each class\n",
    "        b_pos = rng.choice(pos_idx, size=n_pos, replace=True)\n",
    "        b_neg = rng.choice(neg_idx, size=n_neg, replace=True)\n",
    "        b_idx = np.concatenate([b_pos, b_neg])\n",
    "        rng.shuffle(b_idx)  # order doesn't matter for AUC, but good practice\n",
    "\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_true[b_idx], y_pred_proba[b_idx]))\n",
    "        except ValueError:\n",
    "            # Extremely unlikely with stratified sampling; keep guard anyway\n",
    "            continue\n",
    "\n",
    "    valid = len(aucs)\n",
    "    if valid == 0:\n",
    "        print(\"Error: No valid bootstrap samples generated.\")\n",
    "        return None, None, None, 0\n",
    "    if valid < min_valid:\n",
    "        print(f\"Warning: Only {valid} valid bootstrap samples (min recommended {min_valid}). CI may be unreliable.\")\n",
    "\n",
    "    # Percentile CI\n",
    "    lower = float(np.percentile(aucs, (1 - ci) / 2 * 100))\n",
    "    upper = float(np.percentile(aucs, (1 + ci) / 2 * 100))\n",
    "    mean_auc = float(np.mean(aucs))\n",
    "\n",
    "    print(f\"Bootstrapped {int(ci*100)}% CI for Final Model Test AUC: {mean_auc:.4f} [{lower:.4f}, {upper:.4f}] \"\n",
    "          f\"(valid reps = {valid})\")\n",
    "    return mean_auc, lower, upper, valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === `__main__` integration block with Bootstrap LASSO ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial clinical data: 128 patients\n",
      "Final matched data: 128 patients\n",
      "DATASET INFORMATION:\n",
      "Total samples: 128\n",
      "Total features: 103\n",
      "Class distribution: LRR=47, Non-LRR=81\n",
      "LRR percentage: 36.7%\n",
      "\n",
      "DATA SPLIT:\n",
      "Train/val samples: 102\n",
      "Test samples: 26\n",
      "Train/val class dist: LRR=37, Non-LRR=65\n",
      "Test class dist: LRR=10, Non-LRR=16\n",
      "\n",
      "============================================================\n",
      "LASSO FEATURE SELECTION WITH 5-FOLD CROSS-VALIDATION\n",
      "============================================================\n",
      "\n",
      "FOLD 1/5\n",
      "----------------------------------------\n",
      "Running Bootstrap LASSO feature selection...\n",
      "Stable features selected: 23 out of 103\n",
      "Selected feature indices: [ 0  1  4  5  6  9 10 18 22 27 33 36 42 45 48 49 64 69 73 77 78 97 99]\n",
      "Selected 23 features out of 103\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "  Train AUC: 0.7838, Val AUC: 0.6346\n",
      "  Train Acc: 0.6667, Val Acc: 0.5714\n",
      "\n",
      "Evaluating GaussianNB...\n",
      "  Train AUC: 0.7294, Val AUC: 0.6442\n",
      "  Train Acc: 0.6790, Val Acc: 0.7619\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.8203, Val AUC: 0.5865\n",
      "  Train Acc: 0.8025, Val Acc: 0.6190\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.8203, Val AUC: 0.5865\n",
      "  Train Acc: 0.8025, Val Acc: 0.6190\n",
      "\n",
      "Evaluating DecisionTreeClassifier...\n",
      "  Train AUC: 0.7278, Val AUC: 0.6010\n",
      "  Train Acc: 0.7407, Val Acc: 0.6190\n",
      "\n",
      "Evaluating RandomForestClassifier...\n",
      "  Train AUC: 0.9741, Val AUC: 0.6923\n",
      "  Train Acc: 0.8025, Val Acc: 0.7143\n",
      "\n",
      "FOLD 2/5\n",
      "----------------------------------------\n",
      "Running Bootstrap LASSO feature selection...\n",
      "Stable features selected: 37 out of 103\n",
      "Selected feature indices: [  0   1   2   3   4   5   6   9  10  13  18  19  22  23  27  36  39  42\n",
      "  44  45  48  49  62  64  68  69  73  74  77  78  82  84  87  97  98  99\n",
      " 102]\n",
      "Selected 37 features out of 103\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "  Train AUC: 0.9834, Val AUC: 0.4808\n",
      "  Train Acc: 0.9259, Val Acc: 0.4286\n",
      "\n",
      "Evaluating GaussianNB...\n",
      "  Train AUC: 0.7460, Val AUC: 0.6442\n",
      "  Train Acc: 0.7284, Val Acc: 0.5238\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.9655, Val AUC: 0.4904\n",
      "  Train Acc: 0.8765, Val Acc: 0.5238\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.9655, Val AUC: 0.4904\n",
      "  Train Acc: 0.8765, Val Acc: 0.5238\n",
      "\n",
      "Evaluating DecisionTreeClassifier...\n",
      "  Train AUC: 0.7613, Val AUC: 0.6202\n",
      "  Train Acc: 0.7778, Val Acc: 0.6190\n",
      "\n",
      "Evaluating RandomForestClassifier...\n",
      "  Train AUC: 0.9536, Val AUC: 0.5865\n",
      "  Train Acc: 0.8272, Val Acc: 0.6667\n",
      "\n",
      "FOLD 3/5\n",
      "----------------------------------------\n",
      "Running Bootstrap LASSO feature selection...\n",
      "Stable features selected: 22 out of 103\n",
      "Selected feature indices: [ 0  1  4  5  6 10 18 22 27 36 42 45 48 49 64 73 77 87 93 97 98 99]\n",
      "Selected 22 features out of 103\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "  Train AUC: 0.7122, Val AUC: 0.6374\n",
      "  Train Acc: 0.7195, Val Acc: 0.5500\n",
      "\n",
      "Evaluating GaussianNB...\n",
      "  Train AUC: 0.7365, Val AUC: 0.6484\n",
      "  Train Acc: 0.7439, Val Acc: 0.6500\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.2891, Val AUC: 0.3626\n",
      "  Train Acc: 0.7195, Val Acc: 0.6000\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.2891, Val AUC: 0.3626\n",
      "  Train Acc: 0.7195, Val Acc: 0.6000\n",
      "\n",
      "Evaluating DecisionTreeClassifier...\n",
      "  Train AUC: 0.7106, Val AUC: 0.5659\n",
      "  Train Acc: 0.7195, Val Acc: 0.6500\n",
      "\n",
      "Evaluating RandomForestClassifier...\n",
      "  Train AUC: 0.9583, Val AUC: 0.6374\n",
      "  Train Acc: 0.8293, Val Acc: 0.6500\n",
      "\n",
      "FOLD 4/5\n",
      "----------------------------------------\n",
      "Running Bootstrap LASSO feature selection...\n",
      "Stable features selected: 29 out of 103\n",
      "Selected feature indices: [  0   1   2   3   4   5   6   9  10  13  18  22  27  36  42  45  48  49\n",
      "  64  73  77  78  80  84  92  97  99 101 102]\n",
      "Selected 29 features out of 103\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "  Train AUC: 0.7295, Val AUC: 0.5385\n",
      "  Train Acc: 0.6585, Val Acc: 0.4000\n",
      "\n",
      "Evaluating GaussianNB...\n",
      "  Train AUC: 0.7487, Val AUC: 0.5824\n",
      "  Train Acc: 0.7195, Val Acc: 0.6500\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.7135, Val AUC: 0.5275\n",
      "  Train Acc: 0.6341, Val Acc: 0.6500\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.7135, Val AUC: 0.5275\n",
      "  Train Acc: 0.6341, Val Acc: 0.6500\n",
      "\n",
      "Evaluating DecisionTreeClassifier...\n",
      "  Train AUC: 0.7766, Val AUC: 0.5934\n",
      "  Train Acc: 0.7561, Val Acc: 0.6500\n",
      "\n",
      "Evaluating RandomForestClassifier...\n",
      "  Train AUC: 0.9577, Val AUC: 0.5604\n",
      "  Train Acc: 0.8902, Val Acc: 0.7000\n",
      "\n",
      "FOLD 5/5\n",
      "----------------------------------------\n",
      "Running Bootstrap LASSO feature selection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/home/radiomicsserver/anaconda3/envs/radiomics/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable features selected: 55 out of 103\n",
      "Selected feature indices: [  0   1   2   3   4   5   6   7   8   9  10  12  13  15  17  18  19  22\n",
      "  23  27  36  39  40  42  43  44  45  46  47  48  49  64  67  68  69  72\n",
      "  73  74  76  77  78  80  81  83  84  85  86  87  88  92  97  98  99 101\n",
      " 102]\n",
      "Selected 55 features out of 103\n",
      "\n",
      "Evaluating LogisticRegression...\n",
      "  Train AUC: 0.6994, Val AUC: 0.6044\n",
      "  Train Acc: 0.6951, Val Acc: 0.6500\n",
      "\n",
      "Evaluating GaussianNB...\n",
      "  Train AUC: 0.7090, Val AUC: 0.5659\n",
      "  Train Acc: 0.7317, Val Acc: 0.6000\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.2981, Val AUC: 0.3956\n",
      "  Train Acc: 0.7317, Val Acc: 0.6000\n",
      "\n",
      "Evaluating SVC...\n",
      "  Train AUC: 0.2981, Val AUC: 0.3956\n",
      "  Train Acc: 0.7317, Val Acc: 0.6000\n",
      "\n",
      "Evaluating DecisionTreeClassifier...\n",
      "  Train AUC: 0.9545, Val AUC: 0.5165\n",
      "  Train Acc: 0.8780, Val Acc: 0.5000\n",
      "\n",
      "Evaluating RandomForestClassifier...\n",
      "  Train AUC: 0.9506, Val AUC: 0.5714\n",
      "  Train Acc: 0.8537, Val Acc: 0.5000\n",
      "\n",
      "============================================================\n",
      "BUILDING CONSENSUS FEATURES\n",
      "============================================================\n",
      "Consensus features: 29 selected\n",
      "Features selected in ≥3 folds: 29\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION ON TEST SET\n",
      "============================================================\n",
      "Using 29 consensus features for final evaluation\n",
      "\n",
      "Final evaluation: LogisticRegression\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6247 [0.3873, 0.8375] (valid reps = 1000)\n",
      "  Test AUC: 0.6250 [95% CI: 0.3873, 0.8375]\n",
      "  Test Accuracy: 0.7308\n",
      "\n",
      "Final evaluation: GaussianNB\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6305 [0.4000, 0.8344] (valid reps = 1000)\n",
      "  Test AUC: 0.6312 [95% CI: 0.4000, 0.8344]\n",
      "  Test Accuracy: 0.6538\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3757 [0.1750, 0.6000] (valid reps = 1000)\n",
      "  Test AUC: 0.3750 [95% CI: 0.1750, 0.6000]\n",
      "  Test Accuracy: 0.6154\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3757 [0.1750, 0.6000] (valid reps = 1000)\n",
      "  Test AUC: 0.3750 [95% CI: 0.1750, 0.6000]\n",
      "  Test Accuracy: 0.6154\n",
      "\n",
      "Final evaluation: DecisionTreeClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.5546 [0.3405, 0.7720] (valid reps = 1000)\n",
      "  Test AUC: 0.5563 [95% CI: 0.3405, 0.7720]\n",
      "  Test Accuracy: 0.4231\n",
      "\n",
      "Final evaluation: RandomForestClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6259 [0.3875, 0.8500] (valid reps = 1000)\n",
      "  Test AUC: 0.6250 [95% CI: 0.3875, 0.8500]\n",
      "  Test Accuracy: 0.6923\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE LASSO FEATURE SELECTION RESULTS\n",
      "================================================================================\n",
      "\n",
      "DATASET SUMMARY:\n",
      "- Total samples: 128 (Train: 102, Test: 26)\n",
      "- Original features: 103\n",
      "- Consensus features: 29\n",
      "- Class distribution: LRR=47 (36.7%), Non-LRR=81 (63.3%)\n",
      "\n",
      "CROSS-VALIDATION PERFORMANCE (Mean ± Std):\n",
      "--------------------------------------------------------------------------------\n",
      "Classifier           Train AUC       Val AUC         Train Acc       Val Acc         Avg Features\n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression   0.782±0.105     0.579±0.061     0.733±0.099     0.520±0.093     33.2\n",
      "GaussianNB           0.734±0.014     0.617±0.035     0.721±0.022     0.637±0.078     33.2\n",
      "SVC                  0.617±0.276     0.473±0.083     0.753±0.082     0.599±0.042     33.2\n",
      "DecisionTreeClassifier 0.786±0.087     0.579±0.036     0.774±0.055     0.608±0.056     33.2\n",
      "RandomForestClassifier 0.959±0.008     0.610±0.049     0.841±0.030     0.646±0.077     33.2\n",
      "\n",
      "FINAL TEST PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\n",
      "----------------------------------------------------------------------\n",
      "Classifier           Test AUC [95% CI]         Test Accuracy  \n",
      "----------------------------------------------------------------------\n",
      "LogisticRegression   0.625 [0.387,0.837]     0.731\n",
      "GaussianNB           0.631 [0.400,0.834]     0.654\n",
      "SVC                  0.375 [0.175,0.600]     0.615\n",
      "DecisionTreeClassifier 0.556 [0.341,0.772]     0.423\n",
      "RandomForestClassifier 0.625 [0.388,0.850]     0.692\n",
      "\n",
      "BEST TEST PERFORMANCE: GaussianNB\n",
      "Test AUC: 0.6312, Test Accuracy: 0.6538\n",
      "\n",
      "================================================================================\n",
      "LASSO FEATURE SELECTION PIPELINE COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ---- Load data and extract radiomics features/labels ----\n",
    "    radiomics_data, clinical_data = load_data()\n",
    "    radiomics_cols = get_radiomics_columns(radiomics_data)\n",
    "    X_raw = radiomics_data[radiomics_cols].values\n",
    "    y = clinical_data[\"LocoRegeonalRecurrence\"].values\n",
    "\n",
    "    # Print dataset information\n",
    "    print(\"DATASET INFORMATION:\")\n",
    "    print(f\"Total samples: {len(X_raw)}\")\n",
    "    print(f\"Total features: {X_raw.shape[1]}\")\n",
    "    print(f\"Class distribution: LRR={np.sum(y)}, Non-LRR={len(y)-np.sum(y)}\")\n",
    "    print(f\"LRR percentage: {100*np.sum(y)/len(y):.1f}%\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 1) Hold-out TEST set (20%), keep untouched till the very end\n",
    "    # ===============================================================\n",
    "    X_temp, X_test_raw, y_temp, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"\\nDATA SPLIT:\")\n",
    "    print(f\"Train/val samples: {len(X_temp)}\")\n",
    "    print(f\"Test samples: {len(X_test_raw)}\")\n",
    "    print(f\"Train/val class dist: LRR={np.sum(y_temp)}, Non-LRR={len(y_temp)-np.sum(y_temp)}\")\n",
    "    print(f\"Test class dist: LRR={np.sum(y_test)}, Non-LRR={len(y_test)-np.sum(y_test)}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 2) LASSO Feature Selection with Cross-Validation\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"LASSO FEATURE SELECTION WITH 5-FOLD CROSS-VALIDATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Define classifiers for evaluation\n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        GaussianNB(),\n",
    "        SVC(kernel='linear', probability=True),\n",
    "        SVC(kernel='rbf', probability=True),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    ]\n",
    "\n",
    "    # 5-fold stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Storage for cross-validation results\n",
    "    cv_results = {}\n",
    "    for clf in classifiers:\n",
    "        cv_results[clf.__class__.__name__] = {\n",
    "            'train_aucs': [], 'val_aucs': [], 'train_accs': [], 'val_accs': [], 'n_features': []\n",
    "        }\n",
    "\n",
    "    fold_selected_features = []  # Store selected features for each fold\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold_id, (train_idx, val_idx) in enumerate(skf.split(X_temp, y_temp), 1):\n",
    "        print(f\"\\nFOLD {fold_id}/5\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        X_train_fold, X_val_fold = X_temp[train_idx], X_temp[val_idx]\n",
    "        y_train_fold, y_val_fold = y_temp[train_idx], y_temp[val_idx]\n",
    "\n",
    "        # Standardize features (fit on train, transform both train and val)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "        # LASSO feature selection on training fold\n",
    "        print(f\"Running Bootstrap LASSO feature selection...\")\n",
    "        selected_features_idx = bootstrap_lasso_fs(\n",
    "            X_train_scaled, y_train_fold, \n",
    "            n_bootstrap=1000, \n",
    "            freq_threshold=0.5\n",
    "        )\n",
    "        \n",
    "        fold_selected_features.append(selected_features_idx)\n",
    "        n_selected = len(selected_features_idx)\n",
    "        print(f\"Selected {n_selected} features out of {X_train_scaled.shape[1]}\")\n",
    "\n",
    "        if n_selected == 0:\n",
    "            print(\"⚠️ No features selected in this fold. Skipping evaluation.\")\n",
    "            continue\n",
    "\n",
    "        # Apply feature selection\n",
    "        X_train_selected = X_train_scaled[:, selected_features_idx]\n",
    "        X_val_selected = X_val_scaled[:, selected_features_idx]\n",
    "\n",
    "        # Evaluate each classifier with selected features\n",
    "        for clf in classifiers:\n",
    "            print(f\"\\nEvaluating {clf.__class__.__name__}...\")\n",
    "            \n",
    "            # Tune hyperparameters on selected features\n",
    "            tuned_clf = get_tuned_model(clf, X_train_selected, y_train_fold)\n",
    "            tuned_clf.fit(X_train_selected, y_train_fold)\n",
    "\n",
    "            # Predictions\n",
    "            if hasattr(tuned_clf, 'predict_proba'):\n",
    "                y_train_proba = tuned_clf.predict_proba(X_train_selected)[:, 1]\n",
    "                y_val_proba = tuned_clf.predict_proba(X_val_selected)[:, 1]\n",
    "            else:\n",
    "                y_train_proba = tuned_clf.decision_function(X_train_selected)\n",
    "                y_val_proba = tuned_clf.decision_function(X_val_selected)\n",
    "\n",
    "            y_train_pred = tuned_clf.predict(X_train_selected)\n",
    "            y_val_pred = tuned_clf.predict(X_val_selected)\n",
    "\n",
    "            # Calculate metrics\n",
    "            train_auc = roc_auc_score(y_train_fold, y_train_proba)\n",
    "            val_auc = roc_auc_score(y_val_fold, y_val_proba)\n",
    "            train_acc = accuracy_score(y_train_fold, y_train_pred)\n",
    "            val_acc = accuracy_score(y_val_fold, y_val_pred)\n",
    "\n",
    "            # Store results\n",
    "            cv_results[clf.__class__.__name__]['train_aucs'].append(train_auc)\n",
    "            cv_results[clf.__class__.__name__]['val_aucs'].append(val_auc)\n",
    "            cv_results[clf.__class__.__name__]['train_accs'].append(train_acc)\n",
    "            cv_results[clf.__class__.__name__]['val_accs'].append(val_acc)\n",
    "            cv_results[clf.__class__.__name__]['n_features'].append(n_selected)\n",
    "\n",
    "            print(f\"  Train AUC: {train_auc:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "            print(f\"  Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 3) Build consensus features from cross-validation\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BUILDING CONSENSUS FEATURES\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Create consensus from fold selections\n",
    "    if fold_selected_features:\n",
    "        all_features = set()\n",
    "        for features in fold_selected_features:\n",
    "            all_features.update(features)\n",
    "        \n",
    "        # Count how many times each feature was selected\n",
    "        feature_counts = {}\n",
    "        for feature_idx in all_features:\n",
    "            count = sum(1 for features in fold_selected_features if feature_idx in features)\n",
    "            feature_counts[feature_idx] = count\n",
    "\n",
    "        # Select features that appear in at least 3/5 folds\n",
    "        consensus_threshold = 3\n",
    "        consensus_features = [idx for idx, count in feature_counts.items() if count >= consensus_threshold]\n",
    "        \n",
    "        # Fallback: if no features meet threshold, use union\n",
    "        if not consensus_features:\n",
    "            consensus_features = list(all_features)\n",
    "            print(f\"Warning: No features met {consensus_threshold}/5 threshold. Using union of all selections.\")\n",
    "        \n",
    "        consensus_features = sorted(consensus_features)\n",
    "        print(f\"Consensus features: {len(consensus_features)} selected\")\n",
    "        print(f\"Features selected in ≥{consensus_threshold} folds: {len([c for c in feature_counts.values() if c >= consensus_threshold])}\")\n",
    "    else:\n",
    "        print(\"No features selected in any fold!\")\n",
    "        consensus_features = []\n",
    "\n",
    "    # ===============================================================\n",
    "    # 4) Final evaluation on test set with consensus features\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL EVALUATION ON TEST SET\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if consensus_features:\n",
    "        # Scale full training data and test data\n",
    "        scaler_final = StandardScaler()\n",
    "        X_train_final_scaled = scaler_final.fit_transform(X_temp)\n",
    "        X_test_final_scaled = scaler_final.transform(X_test_raw)\n",
    "\n",
    "        # Apply consensus feature selection\n",
    "        X_train_final = X_train_final_scaled[:, consensus_features]\n",
    "        X_test_final = X_test_final_scaled[:, consensus_features]\n",
    "\n",
    "        print(f\"Using {len(consensus_features)} consensus features for final evaluation\")\n",
    "\n",
    "        # Final results storage\n",
    "        final_results = {}\n",
    "\n",
    "        for clf in classifiers:\n",
    "            print(f\"\\nFinal evaluation: {clf.__class__.__name__}\")\n",
    "            \n",
    "            # Tune and train on full training set with consensus features\n",
    "            tuned_clf_final = get_tuned_model(clf, X_train_final, y_temp)\n",
    "            tuned_clf_final.fit(X_train_final, y_temp)\n",
    "\n",
    "            # Test set predictions\n",
    "            if hasattr(tuned_clf_final, 'predict_proba'):\n",
    "                y_test_proba = tuned_clf_final.predict_proba(X_test_final)[:, 1]\n",
    "            else:\n",
    "                y_test_proba = tuned_clf_final.decision_function(X_test_final)\n",
    "\n",
    "            y_test_pred = tuned_clf_final.predict(X_test_final)\n",
    "\n",
    "            # Calculate test metrics\n",
    "            test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "            test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "            # Bootstrap CI for test AUC\n",
    "            test_mean_auc, test_lower, test_upper, test_valid = bootstrap_final_model_auc_ci(\n",
    "                y_test, y_test_proba, n_bootstrap=1000\n",
    "            )\n",
    "\n",
    "            final_results[clf.__class__.__name__] = {\n",
    "                'test_auc': test_auc,\n",
    "                'test_acc': test_acc,\n",
    "                'auc_ci_lower': test_lower,\n",
    "                'auc_ci_upper': test_upper\n",
    "            }\n",
    "\n",
    "            print(f\"  Test AUC: {test_auc:.4f} [95% CI: {test_lower:.4f}, {test_upper:.4f}]\")\n",
    "            print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 5) COMPREHENSIVE RESULTS SUMMARY\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COMPREHENSIVE LASSO FEATURE SELECTION RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    print(f\"\\nDATASET SUMMARY:\")\n",
    "    print(f\"- Total samples: {len(X_raw)} (Train: {len(X_temp)}, Test: {len(X_test_raw)})\")\n",
    "    print(f\"- Original features: {X_raw.shape[1]}\")\n",
    "    print(f\"- Consensus features: {len(consensus_features) if consensus_features else 0}\")\n",
    "    print(f\"- Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%), Non-LRR={len(y)-np.sum(y)} ({100*(len(y)-np.sum(y))/len(y):.1f}%)\")\n",
    "\n",
    "    # Cross-validation performance summary\n",
    "    print(f\"\\nCROSS-VALIDATION PERFORMANCE (Mean ± Std):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Classifier':<20} {'Train AUC':<15} {'Val AUC':<15} {'Train Acc':<15} {'Val Acc':<15} {'Avg Features':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for clf_name, results in cv_results.items():\n",
    "        if results['train_aucs']:  # Only if we have results\n",
    "            train_auc_mean = np.mean(results['train_aucs'])\n",
    "            train_auc_std = np.std(results['train_aucs'])\n",
    "            val_auc_mean = np.mean(results['val_aucs'])\n",
    "            val_auc_std = np.std(results['val_aucs'])\n",
    "            train_acc_mean = np.mean(results['train_accs'])\n",
    "            train_acc_std = np.std(results['train_accs'])\n",
    "            val_acc_mean = np.mean(results['val_accs'])\n",
    "            val_acc_std = np.std(results['val_accs'])\n",
    "            avg_features = np.mean(results['n_features'])\n",
    "            \n",
    "            print(f\"{clf_name:<20} {train_auc_mean:.3f}±{train_auc_std:.3f}     {val_auc_mean:.3f}±{val_auc_std:.3f}     {train_acc_mean:.3f}±{train_acc_std:.3f}     {val_acc_mean:.3f}±{val_acc_std:.3f}     {avg_features:.1f}\")\n",
    "\n",
    "    # Final test performance\n",
    "    if consensus_features and final_results:\n",
    "        print(f\"\\nFINAL TEST PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"{'Classifier':<20} {'Test AUC [95% CI]':<25} {'Test Accuracy':<15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for clf_name, results in final_results.items():\n",
    "            test_auc = results['test_auc']\n",
    "            test_lower = results['auc_ci_lower']\n",
    "            test_upper = results['auc_ci_upper']\n",
    "            test_acc = results['test_acc']\n",
    "            \n",
    "            print(f\"{clf_name:<20} {test_auc:.3f} [{test_lower:.3f},{test_upper:.3f}]     {test_acc:.3f}\")\n",
    "\n",
    "        # Best performing classifier\n",
    "        best_test_clf = max(final_results.keys(), key=lambda x: final_results[x]['test_auc'])\n",
    "        best_test_auc = final_results[best_test_clf]['test_auc']\n",
    "        best_test_acc = final_results[best_test_clf]['test_acc']\n",
    "        \n",
    "        print(f\"\\nBEST TEST PERFORMANCE: {best_test_clf}\")\n",
    "        print(f\"Test AUC: {best_test_auc:.4f}, Test Accuracy: {best_test_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"LASSO FEATURE SELECTION PIPELINE COMPLETE\")\n",
    "    print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
