{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === **Particle Swarm Optimization (PSO) for Feature Selection to optimize feature subsets for various ML classifiers** ===\n",
    "\n",
    "-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Stable Feature Pre-selection:**\n",
    "\n",
    "* Performed initial feature selection using **bootstrapped LASSO logistic regression** (`penalty='l1'`, `solver='liblinear'`, `cv=5`, `max_iter=5000`), repeated for **100 bootstrap samples** (`n_bootstrap=100`). Features were retained if selected in **≥70%** of bootstraps (`freq_threshold=0.7`), ensuring stability against sampling variance.\n",
    "\n",
    "\n",
    "**2. Metaheuristic Feature Selection:**\n",
    "\n",
    "* Applies **Particle Swarm Optimization (PSO)** for further feature selection from the stable set, using a population of **20 particles** (`n_particles=20`) and **50 iterations** (`max_iter=50`). Each particle represented a binary feature mask, and the swarm was optimized to maximize mean ROC AUC over 5-fold stratified cross-validation (`StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`).\n",
    "\n",
    "\n",
    "**3. Comprehensive Classifier Comparison:**\n",
    "\n",
    "* Evaluated a broad suite of classifiers:\n",
    "\n",
    "  * **Logistic Regression** (`max_iter=1000`), with grid search over `C=[0.001, 0.01, 0.1, 1, 10]` and `penalty=['l1', 'l2']`\n",
    "\n",
    "  * **Gaussian Naive Bayes** (default parameters)\n",
    "\n",
    "  * **Support Vector Machines** (linear and RBF kernels, `C=[0.01, 0.1, 1, 10]`, `gamma=['scale', 'auto']`)\n",
    "\n",
    "  * **Decision Tree** (`max_depth=[3, 5, 7]`, `min_samples_split=[5, 10]`, `min_samples_leaf=[2, 4]`)\n",
    "\n",
    "  * **Random Forest** (`n_estimators=[100, 200]`, `max_depth=[5, 10]`, `min_samples_split=[5, 10]`, `min_samples_leaf=[2, 4]`)\n",
    "\n",
    "  * **VotingClassifier** ensemble combining top-tuned base models with soft voting.\n",
    "\n",
    "* Hyperparameters were tuned for each classifier using **GridSearchCV** and 5-fold stratified cross-validation, optimizing for ROC AUC.\n",
    "\n",
    "\n",
    "**4. Class Imbalance and Data Integrity Handling:**\n",
    "\n",
    "* Maintained **class distribution balance** in all data splits using stratified sampling, both in train/test partitioning (`test_size=0.2`) and during cross-validation.\n",
    "\n",
    "* For bootstrapping and CI estimation, ensured that each resample included both classes—skipping samples otherwise to avoid invalid AUC calculations.\n",
    "\n",
    "\n",
    "**5. Feature Scaling and Pipeline Safety:**\n",
    "\n",
    "* Applied **feature standardization** (`StandardScaler()`) within all pipelines, fitting scalers only on training data to prevent information leakage.\n",
    "\n",
    "* Model pipelines (`make_pipeline(StandardScaler(), classifier)`) ensured consistent preprocessing during evaluation and prediction.\n",
    "\n",
    "\n",
    "**6. Model Evaluation & Uncertainty Quantification:**\n",
    "\n",
    "* Reported **ROC AUC and accuracy** for both training and testing sets at each PSO iteration.\n",
    "\n",
    "* Computed **bootstrapped confidence intervals** for test AUC (`n_bootstrap=1000`, `ci=0.95`), resampling test predictions to quantify model uncertainty and generalization performance.\n",
    "\n",
    "\n",
    "**7. Visualization and Monitoring:**\n",
    "\n",
    "* Plotted **train/test AUC trends** across PSO iterations for convergence analysis.\n",
    "\n",
    "* Displayed final **ROC curves** for both training and testing sets, including mean AUC and 95% confidence intervals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === IMPORTS ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                                            # Core numerical computation library for arrays and matrix operations\n",
    "import pandas as pd                                                                           # Library for data manipulation and analysis (tabular data, DataFrames)\n",
    "from sklearn.base import clone                                                                # For cloning estimators (useful when building pipelines or doing cross-validation)\n",
    "import matplotlib.pyplot as plt                                                               # For plotting graphs (e.g., ROC curves, feature importances, etc.)\n",
    "from scipy.stats import bootstrap                                                             # For statistical bootstrap resampling (scipy's bootstrap is for CI, sklearn's resample for random sampling)\n",
    "from sklearn.utils import resample                                                            # Utility to randomly resample datasets (e.g., for bootstrapping in ML)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold        # For splitting data, cross-validation, and stratified folds (for imbalanced classes)\n",
    "from sklearn.preprocessing import StandardScaler                                              # For scaling features to zero mean/unit variance (important for many ML algorithms)\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score                          # For evaluating model performance: ROC AUC, ROC curve points, accuracy\n",
    "from collections import Counter\n",
    "\n",
    "# === CLASSIFIERS ===\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB                                                    # Naive Bayes classifier for classification tasks\n",
    "from sklearn.svm import SVC                                                                   # Support Vector Classifier (linear & nonlinear SVMs)\n",
    "from sklearn.tree import DecisionTreeClassifier                                               # Decision Tree classifier (nonlinear, interpretable ML model)\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier                         # Random Forest classifier (ensemble of Decision Trees)\n",
    "from sklearn.pipeline import make_pipeline                                                    # For creating machine learning pipelines (combining preprocessing + models)\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV                     # Logistic Regression (standard and cross-validated, for classification)\n",
    "\n",
    "# === GRID SEARCH HYPERPARAMETER TUNING ===\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV                                              # For exhaustive grid search over hyperparameters with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === LOAD AND PREPROCESS DATA ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Load radiomics and clinical CSV files into DataFrames\n",
    "    radiomics = pd.read_csv(\"./HNC-Prospective-Radiomics-305.csv\")\n",
    "    clinical = pd.read_csv(\"./proceed_radiomics_166.csv\")\n",
    "\n",
    "    print(f\"Initial clinical data: {len(clinical)} patients\")\n",
    "    # print(f\"Unique locations in clinical data: {clinical['Location'].value_counts()}\")\n",
    "\n",
    "    # Filter clinical data to only include specific tumor locations\n",
    "    # clinical = clinical[clinical[\"Location\"].isin(['Larynx', 'Tonsil', 'Hypopharynx', 'Oropharynx', 'BOT', 'Other'])]\n",
    "    # print(f\"After location filtering: {len(clinical)} patients\")\n",
    "\n",
    "    # Standardize 'research_subject_uid' in radiomics by keeping only the part before \"_\"\n",
    "    radiomics[\"research_subject_uid\"] = radiomics[\"research_subject_uid\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "    # Remove any leading/trailing spaces from 'Project ID' in clinical data\n",
    "    clinical[\"Project ID\"] = clinical[\"Project ID\"].str.strip()\n",
    "\n",
    "    # Filter radiomics to only keep rows with research_subject_uid present in clinical Project IDs\n",
    "    radiomics_filtered = radiomics[radiomics[\"research_subject_uid\"].isin(clinical[\"Project ID\"])]\n",
    "    \n",
    "    # Filter clinical to only keep rows with Project ID present in radiomics research_subject_uid\n",
    "    clinical_filtered = clinical[clinical[\"Project ID\"].isin(radiomics[\"research_subject_uid\"])]\n",
    "\n",
    "    print(f\"Final matched data: {len(clinical_filtered)} patients\")\n",
    "\n",
    "    # Sort both DataFrames by their ID columns and reset their indices\n",
    "    radiomics_filtered = radiomics_filtered.sort_values(by=\"research_subject_uid\").reset_index(drop=True)\n",
    "    clinical_filtered = clinical_filtered.sort_values(by=\"Project ID\").reset_index(drop=True)\n",
    "\n",
    "    # Return the filtered and aligned DataFrames for further processing\n",
    "    return radiomics_filtered, clinical_filtered\n",
    "\n",
    "\n",
    "\n",
    "def get_radiomics_columns(data):\n",
    "    \"\"\"\n",
    "    Returns the columns from 'original_shape_Elongation' to 'original_ngtdm_Strength'.\n",
    "    These typically represent the set of radiomics features you want to extract.\n",
    "    \"\"\"\n",
    "    start_column = \"original_shape_Elongation\"\n",
    "    end_column = \"original_ngtdm_Strength\"\n",
    "    start_idx = data.columns.get_loc(start_column)\n",
    "    end_idx = data.columns.get_loc(end_column) + 1  # +1 to include the end column itself\n",
    "    return data.columns[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Define hyperparameter grids for each classifier ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These grids help tune the model to avoid overfitting by optimizing regularization and other key parameters.\n",
    "all_grid_params = {\n",
    "    'LogisticRegression': {\n",
    "        'C': [1e-3, 3e-3, 1e-2, 3e-2, 0.1, 0.3, 1, 3, 10],          # Regularization strength (lower = stronger regularization)\n",
    "        'penalty': ['l1', 'l2'],                                                # Type of regularization: L1 (Lasso), L2 (Ridge)\n",
    "        'solver': ['liblinear'],                                                # Solver that supports both l1 and l2\n",
    "        'class_weight': [None, \"balanced\"],\n",
    "        'max_iter': [1000],\n",
    "    },\n",
    "    'GaussianNB': {},                                                           # No tunable hyperparameters for basic Naive Bayes\n",
    "    'SVC': [\n",
    "        # Linear SVC\n",
    "        {\n",
    "            'C': [1e-3, 1e-2, 0.1, 1, 10],                                      # Regularization strength\n",
    "            'kernel': ['linear'],                                               # Linear kernel\n",
    "            'probability': [True],                                              # Needed for probability predictions (e.g., ROC AUC)\n",
    "            'class_weight': [None, \"balanced\"],\n",
    "        },\n",
    "        # RBF SVC\n",
    "        {\n",
    "            'C': [1e-3, 1e-2, 0.1, 1, 10],                                      # Regularization strength\n",
    "            'gamma': ['scale', 'auto', 1e-3, 1e-2, 1e-1],                       # Kernel coefficient for RBF\n",
    "            'kernel': ['rbf'],                                                  # RBF (nonlinear) kernel\n",
    "            'probability': [True],                                              # Probability estimates\n",
    "            'class_weight': [None, \"balanced\"],\n",
    "        }\n",
    "    ],\n",
    "    'DecisionTreeClassifier': {\n",
    "        'criterion': ['gini', 'entropy'],                                       # Split quality metric\n",
    "        'max_depth': [2, 3, 4, 5, 7],                                           # Controls tree depth (regularization)\n",
    "        'min_samples_split': [5, 10, 15],                                       # Minimum samples required to split a node\n",
    "        'min_samples_leaf': [2, 4, 6],                                          # Minimum samples per leaf node\n",
    "        'max_features': ['sqrt', 'log2', None],                                 # Number of features considered at each split\n",
    "        'class_weight': [None, \"balanced\"],\n",
    "        'random_state': [42],\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [100, 200, 400],                                        # Number of trees\n",
    "        'max_depth': [3, 5, 7, 10],                                             # Maximum depth of trees\n",
    "        'min_samples_split': [5, 10],                                           # Minimum samples to split an internal node\n",
    "        'min_samples_leaf': [2, 4],                                             # Minimum samples at a leaf node\n",
    "        'max_features': ['sqrt', 'log2'],                                       # Number of features considered at each split\n",
    "        'bootstrap': [True],                                                    # Use bootstrap samples\n",
    "        'n_jobs': [-1],                                                         # Use all available CPU cores for parallel processing\n",
    "        'class_weight': [None, \"balanced\", \"balanced_subsample\"],\n",
    "        'random_state': [42],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# === Utility function to tune a classifier's hyperparameters using grid search and cross-validation ===\n",
    "\n",
    "def get_tuned_model(classifier, X_train, y_train):\n",
    "    name = classifier.__class__.__name__                                 # Get class name as a string (e.g., 'LogisticRegression')\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)      # 5-fold stratified cross-validation\n",
    "    \n",
    "    # Special handling for SVC as its grid is a list (to support both linear & RBF kernels)\n",
    "    if name == 'SVC':\n",
    "        grid = GridSearchCV(\n",
    "            clone(classifier),            # Clone base estimator to avoid data leakage between folds\n",
    "            all_grid_params['SVC'],\n",
    "            scoring='roc_auc',            # Use ROC AUC for model selection (works for imbalanced data)\n",
    "            cv=cv,                        # Use stratified k-fold\n",
    "            n_jobs=-1,                    # Use all CPU cores\n",
    "            refit=True,\n",
    "        )\n",
    "        grid.fit(X_train, y_train)       # Fit grid search\n",
    "        return grid.best_estimator_      # Return the model with best hyperparameters\n",
    "\n",
    "    # For all other classifiers with defined grid parameters\n",
    "    elif name in all_grid_params and all_grid_params[name]:\n",
    "        grid = GridSearchCV(\n",
    "            clone(classifier),\n",
    "            all_grid_params[name],\n",
    "            scoring='roc_auc',\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "            refit=True,\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        return grid.best_estimator_\n",
    "\n",
    "    # If no hyperparameters to tune (e.g., GaussianNB), return the original classifier\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === BOOTSTRAP LASSO FEATURE SELECTION ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_lasso_fs(X, y, n_bootstrap=1000, freq_threshold=0.7, random_state=42):\n",
    "    \"\"\"\n",
    "    CONSTRAINED Bootstrap LASSO that limits features to 10-20 range.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    selected_counts = np.zeros(X.shape[1])\n",
    "    valid_bootstraps = 0\n",
    "    \n",
    "    print(f\"Running constrained Bootstrap LASSO...\")\n",
    "    print(f\"Target: 10-20 features with freq >= {freq_threshold}\")\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        try:\n",
    "            # Resample with stratification\n",
    "            X_resampled, y_resampled = resample(X, y, stratify=y, random_state=random_state+i)\n",
    "            \n",
    "            # Skip if only one class\n",
    "            if len(np.unique(y_resampled)) < 2:\n",
    "                continue\n",
    "            \n",
    "            # AGGRESSIVE regularization to select fewer features\n",
    "            model = LogisticRegressionCV(\n",
    "                Cs=np.logspace(-4, -0.5, 20),  # Stronger regularization: 0.0001 to 0.316\n",
    "                penalty='l1',\n",
    "                solver='liblinear',\n",
    "                cv=3,\n",
    "                scoring='roc_auc',\n",
    "                max_iter=2000,\n",
    "                class_weight='balanced',\n",
    "                random_state=random_state+i\n",
    "            )\n",
    "            \n",
    "            model.fit(X_resampled, y_resampled)\n",
    "            \n",
    "            # Count selected features (non-zero coefficients)\n",
    "            selected_mask = np.abs(model.coef_[0]) > 1e-6\n",
    "            selected_counts += selected_mask.astype(int)\n",
    "            valid_bootstraps += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            if i < 5:\n",
    "                print(f\"Bootstrap {i} failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if valid_bootstraps == 0:\n",
    "        print(\"ERROR: No valid bootstrap samples!\")\n",
    "        return np.array([])\n",
    "    \n",
    "    # Calculate selection frequencies\n",
    "    selection_frequencies = selected_counts / valid_bootstraps\n",
    "    print(f\"Valid bootstraps: {valid_bootstraps}/{n_bootstrap}\")\n",
    "    \n",
    "    # Apply threshold\n",
    "    stable_features = selection_frequencies >= freq_threshold\n",
    "    n_selected = np.sum(stable_features)\n",
    "    print(f\"Features at threshold {freq_threshold}: {n_selected}\")\n",
    "    \n",
    "    # ENFORCE 10-20 feature range\n",
    "    if n_selected > 20:\n",
    "        print(f\"Too many features ({n_selected}), selecting top 20...\")\n",
    "        sorted_indices = np.argsort(selection_frequencies)[::-1]\n",
    "        stable_features = np.zeros_like(selection_frequencies, dtype=bool)\n",
    "        stable_features[sorted_indices[:20]] = True\n",
    "        n_selected = 20\n",
    "        \n",
    "    elif n_selected < 10:\n",
    "        print(f\"Too few features ({n_selected}), lowering threshold...\")\n",
    "        # Gradually lower threshold to get at least 10 features\n",
    "        for new_threshold in [0.6, 0.5, 0.4, 0.3, 0.2]:\n",
    "            stable_features = selection_frequencies >= new_threshold\n",
    "            n_selected = np.sum(stable_features)\n",
    "            if n_selected >= 10:\n",
    "                print(f\"Using threshold {new_threshold}: {n_selected} features\")\n",
    "                break\n",
    "        \n",
    "        # If still too few, take top 15\n",
    "        if n_selected < 10:\n",
    "            print(\"Still too few, taking top 15 features\")\n",
    "            sorted_indices = np.argsort(selection_frequencies)[::-1]\n",
    "            stable_features = np.zeros_like(selection_frequencies, dtype=bool)\n",
    "            stable_features[sorted_indices[:15]] = True\n",
    "            n_selected = 15\n",
    "    \n",
    "    stable_features_idx = np.where(stable_features)[0]\n",
    "    print(f\"FINAL LASSO: Selected {len(stable_features_idx)} features\")\n",
    "    \n",
    "    return stable_features_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === PSO Feature Selection ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CORRECTED EVALUATE_FITNESS FUNCTION\n",
    "# ==========================================\n",
    "\n",
    "def evaluate_fitness(X, y, particle, model, random_state=42):\n",
    "    \"\"\"\n",
    "    CORRECTED: Evaluates fitness using FRESH CV splits each time with STRONG constraint for 5-8 features.\n",
    "    \n",
    "    CRITICAL FIXES:\n",
    "    1. Creates NEW StratifiedKFold for each evaluation (prevents data leakage)\n",
    "    2. Handles edge cases (0, 1, or all features selected)\n",
    "    3. Robust error handling for CV failures\n",
    "    4. Unique random state for each call\n",
    "    \n",
    "    Parameters:\n",
    "    - X: feature matrix (numpy array)\n",
    "    - y: target labels (numpy array) \n",
    "    - particle: binary vector (1: feature selected, 0: not selected)\n",
    "    - model: classifier to use\n",
    "    - random_state: for reproducible CV splits\n",
    "    \n",
    "    Returns: Mean ROC AUC from cross-validation\n",
    "    \"\"\"\n",
    "    selected_features = np.count_nonzero(particle)\n",
    "    \n",
    "    # STRICT  feature count enfocement\n",
    "    if selected_features == 0:\n",
    "        return 0.0  # No features = no predictive power\n",
    "    elif selected_features < 3:\n",
    "        return 0.2  # Too few features\n",
    "    elif selected_features > 10:\n",
    "        return 0.1  # Heavy penalty for too many features\n",
    "    \n",
    "    # Select features\n",
    "    X_selected = X[:, particle == 1]\n",
    "    \n",
    "    try:\n",
    "        # CRITICAL FIX: Create FRESH CV splits each time\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        \n",
    "        # Perform cross-validation with robust error handling\n",
    "        scores = cross_val_score(clone(model), X_selected, y, cv=cv, scoring='roc_auc', n_jobs=1) # n_jobs=1 to avoid conflicts\n",
    "        \n",
    "        # Check for invalid scores\n",
    "        if np.any(np.isnan(scores)) or len(scores) == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        base_score = np.mean(scores)\n",
    "\n",
    "        # REWARD optimal feature counts (5-7 features)\n",
    "        if 5 <= selected_features <= 7:\n",
    "            return base_score * 1.2  # 20% bonus for optimal range\n",
    "        elif selected_features == 8:\n",
    "            return base_score * 1.0  # No penalty\n",
    "        elif selected_features <= 4:\n",
    "            return base_score * 0.8  # Small penalty for too few\n",
    "        elif selected_features >= 9:\n",
    "            return base_score * 0.6  # Larger penalty for too many\n",
    "        else:\n",
    "            return base_score\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        # Handle any CV failures (e.g., class imbalance in small folds)\n",
    "        print(f\"Warning: CV failed for {selected_features} features: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === PSO Model for Feature Selection ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pso(X_train, y_train, X_val, y_val, model, \n",
    "           n_particles=20, max_iter=50, w=0.7, c1=1.4, c2=1.4, verbose=True):\n",
    "    \"\"\"\n",
    "    CORRECTED PSO implementation that fixes the critical data leakage issue.\n",
    "\n",
    "    ## KEY CORRECTIONS:\n",
    "    ----------------\n",
    "    1. Uses fresh CV splits for each fitness evaluation\n",
    "    2. Proper random state management to ensure unique CV splits\n",
    "    3. Better initialization and edge case handling\n",
    "    4. Enhanced progress tracking and early stopping\n",
    "    5. Cleaner separation between fitness evaluation and performance monitoring\n",
    "    \n",
    "    ## Parameters:\n",
    "    -----------\n",
    "    n_particles : int, default=20\n",
    "        Number of particles in the swarm\n",
    "    max_iter : int, default=50  \n",
    "        Maximum number of iterations\n",
    "    w : float, default=0.7\n",
    "        Inertia weight (controls exploration vs exploitation)\n",
    "    c1 : float, default=1.4\n",
    "        Cognitive component (attraction to personal best)\n",
    "    c2 : float, default=1.4\n",
    "        Social component (attraction to global best)\n",
    "    \"\"\"\n",
    "    \n",
    "    TARGET_FEATURES = 6\n",
    "    \n",
    "    def sigmoid_transfer(velocity):\n",
    "        return 1 / (1 + np.exp(-np.clip(velocity, -500, 500)))\n",
    "\n",
    "    def enforce_feature_constraints(particle):\n",
    "        n_selected = int(np.sum(particle))  # ← FIXED: Convert to int\n",
    "        \n",
    "        if n_selected == TARGET_FEATURES:\n",
    "            return particle\n",
    "        \n",
    "        elif n_selected > TARGET_FEATURES:\n",
    "            selected_idx = np.where(particle == 1)[0]\n",
    "            remove_count = int(n_selected - TARGET_FEATURES)  # ← FIXED: Convert to int\n",
    "            remove_idx = np.random.choice(selected_idx, size=remove_count, replace=False)\n",
    "            particle[remove_idx] = 0\n",
    "\n",
    "        else:\n",
    "            unselected_idx = np.where(particle == 0)[0]\n",
    "            add_count = int(TARGET_FEATURES - n_selected)  # ← FIXED: Convert to int\n",
    "            if len(unselected_idx) >= add_count:\n",
    "                add_idx = np.random.choice(unselected_idx, size=add_count, replace=False)\n",
    "                particle[add_idx] = 1\n",
    "            else:\n",
    "                particle[unselected_idx] = 1\n",
    "\n",
    "        return particle\n",
    "\n",
    "    def update_velocity_position(swarm, velocities, personal_best, global_best, \n",
    "                               inertia_weight, cognitive, social):\n",
    "        n_particles, n_features = swarm.shape\n",
    "        \n",
    "        for i in range(n_particles):\n",
    "            r1 = np.random.rand(n_features)\n",
    "            r2 = np.random.rand(n_features)\n",
    "            \n",
    "            # Use the passed parameters instead of hardcoded values\n",
    "            velocities[i] = (\n",
    "                inertia_weight * velocities[i] +\n",
    "                cognitive * r1 * (personal_best[i] - swarm[i]) +\n",
    "                social * r2 * (global_best - swarm[i])\n",
    "            )\n",
    "            \n",
    "            sigmoid_prob = sigmoid_transfer(velocities[i])\n",
    "            swarm[i] = (sigmoid_prob > np.random.rand(n_features)).astype(int)\n",
    "            swarm[i] = enforce_feature_constraints(swarm[i])\n",
    "                \n",
    "        return swarm, velocities\n",
    "\n",
    "    def compute_auc_scores(X_train_sel, X_val_sel, y_train, y_val, model):\n",
    "        try:\n",
    "            temp_model = clone(model)\n",
    "            temp_model.fit(X_train_sel, y_train)\n",
    "            if hasattr(temp_model, 'predict_proba'):\n",
    "                y_train_proba = temp_model.predict_proba(X_train_sel)[:, 1]\n",
    "                y_val_proba = temp_model.predict_proba(X_val_sel)[:, 1]\n",
    "            else:\n",
    "                y_train_proba = temp_model.decision_function(X_train_sel)\n",
    "                y_val_proba = temp_model.decision_function(X_val_sel)\n",
    "            train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "            val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "            return train_auc, val_auc\n",
    "        except:\n",
    "            return None, None\n",
    "\n",
    "    # Initialize swarm\n",
    "    n_features = X_train.shape[1]\n",
    "    swarm = np.zeros((n_particles, n_features))\n",
    "    velocities = np.random.uniform(-1, 1, (n_particles, n_features))\n",
    "    \n",
    "    for i in range(n_particles):\n",
    "        selected_idx = np.random.choice(n_features, size=TARGET_FEATURES, replace=False)\n",
    "        swarm[i][selected_idx] = 1\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"PSO Parameters: particles={n_particles}, iter={max_iter}, w={w}, c1={c1}, c2={c2}\")\n",
    "        print(f\"Initializing PSO with {TARGET_FEATURES} features per particle...\")\n",
    "    \n",
    "    personal_best = swarm.copy()\n",
    "    personal_best_scores = np.zeros(n_particles)\n",
    "    \n",
    "    for i in range(n_particles):\n",
    "        personal_best_scores[i] = evaluate_fitness(\n",
    "            X_train, y_train, swarm[i], model, random_state=42+i\n",
    "        )\n",
    "\n",
    "    global_best_idx = np.argmax(personal_best_scores)\n",
    "    global_best = personal_best[global_best_idx].copy()\n",
    "    global_best_score = personal_best_scores[global_best_idx]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Initial best fitness: {global_best_score:.4f}\")\n",
    "\n",
    "    train_scores, val_scores = [], []\n",
    "    no_improvement_count = 0\n",
    "\n",
    "    # Main PSO loop - now uses passed parameters\n",
    "    for iteration in range(max_iter):\n",
    "        swarm, velocities = update_velocity_position(\n",
    "            swarm, velocities, personal_best, global_best, w, c1, c2\n",
    "        )\n",
    "\n",
    "        improved = False\n",
    "        for i in range(n_particles):\n",
    "            current_fitness = evaluate_fitness(\n",
    "                X_train, y_train, swarm[i], model, \n",
    "                random_state=42 + iteration * n_particles + i\n",
    "            )\n",
    "            \n",
    "            if current_fitness > personal_best_scores[i]:\n",
    "                personal_best[i] = swarm[i].copy()\n",
    "                personal_best_scores[i] = current_fitness\n",
    "                \n",
    "                if current_fitness > global_best_score:\n",
    "                    global_best = swarm[i].copy()\n",
    "                    global_best_score = current_fitness\n",
    "                    improved = True\n",
    "                    no_improvement_count = 0\n",
    "\n",
    "        if not improved:\n",
    "            no_improvement_count += 1\n",
    "\n",
    "        # Monitor performance\n",
    "        if int(np.sum(global_best)) > 0:  # ← FIXED: Convert to int\n",
    "            selected_train = X_train[:, global_best == 1]\n",
    "            selected_val = X_val[:, global_best == 1]\n",
    "            train_auc, val_auc = compute_auc_scores(\n",
    "                selected_train, selected_val, y_train, y_val, model\n",
    "            )\n",
    "            train_scores.append(train_auc)\n",
    "            val_scores.append(val_auc)\n",
    "        else:\n",
    "            train_scores.append(None)\n",
    "            val_scores.append(None)\n",
    "\n",
    "        if verbose and (iteration + 1) % 10 == 0:\n",
    "            n_selected = int(np.sum(global_best))  # ← FIXED: Convert to int\n",
    "            print(f\"Iteration {iteration+1}: Best fitness = {global_best_score:.4f}, \"\n",
    "                  f\"Features = {n_selected}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if no_improvement_count > max_iter // 3:\n",
    "            if verbose:\n",
    "                print(f\"Early stopping at iteration {iteration+1}\")\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        n_selected = int(np.sum(global_best))  # ← FIXED: Convert to int\n",
    "        print(f\"Final fitness: {global_best_score:.4f}, Features: {n_selected}\")\n",
    "\n",
    "    return global_best, train_scores, val_scores\n",
    "\n",
    "# Additional function for parameter tuning (if you choose Option 2)\n",
    "def tune_pso_params(X_train, y_train, X_val, y_val, model, n_trials=3):\n",
    "    \"\"\"\n",
    "    Simple parameter tuning for PSO\n",
    "    \"\"\"\n",
    "    param_combinations = [\n",
    "        {'n_particles': 15, 'max_iter': 40, 'w': 0.5, 'c1': 1.2, 'c2': 1.2},\n",
    "        {'n_particles': 20, 'max_iter': 50, 'w': 0.7, 'c1': 1.4, 'c2': 1.4},\n",
    "        {'n_particles': 25, 'max_iter': 60, 'w': 0.9, 'c1': 1.6, 'c2': 1.6},\n",
    "    ]\n",
    "    \n",
    "    best_score = 0\n",
    "    best_params = param_combinations[1]  # Default to middle option\n",
    "    \n",
    "    print(\"Tuning PSO parameters...\")\n",
    "    for i, params in enumerate(param_combinations):\n",
    "        scores = []\n",
    "        for trial in range(n_trials):\n",
    "            _, _, _ = run_pso(X_train, y_train, X_val, y_val, model, \n",
    "                           verbose=False, **params)\n",
    "            # You'd need to modify this to return the final score\n",
    "            # scores.append(final_score)\n",
    "        \n",
    "        # avg_score = np.mean(scores)\n",
    "        # if avg_score > best_score:\n",
    "        #     best_score = avg_score\n",
    "        #     best_params = params\n",
    "        \n",
    "        print(f\"Config {i+1}: {params}\")\n",
    "    \n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Evaluate model with classifier function ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_classifier(X_train, X_test, y_train, y_test, selected_features, feature_names, classifier):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a given classifier using only the features selected by a feature selection algorithm.\n",
    "    Prints Train/Test AUC and Accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train, X_test: Feature matrices (numpy arrays)\n",
    "        y_train, y_test: Labels\n",
    "        selected_features: Binary vector indicating which features to use\n",
    "        feature_names: List of feature names (not used here, but useful for further reporting)\n",
    "        classifier: Classifier instance (e.g., LogisticRegression)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select only the features chosen by the feature selection mask\n",
    "    X_train_sel = X_train[:, selected_features == 1]\n",
    "    X_test_sel = X_test[:, selected_features == 1]\n",
    "\n",
    "    # If no features were selected, print a warning and stop\n",
    "    if X_train_sel.shape[1] == 0:\n",
    "        print(\"\\n⚠️ No features selected. Cannot train classifier.\")\n",
    "        return\n",
    "\n",
    "    # Build pipeline: scale features then fit classifier\n",
    "    model = make_pipeline(StandardScaler(), classifier)\n",
    "    model.fit(X_train_sel, y_train)  # Train the model on selected features\n",
    "\n",
    "    # Get predicted probabilities or decision function for AUC\n",
    "    y_train_proba = model.predict_proba(X_train_sel)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_train_sel)\n",
    "    y_test_proba = model.predict_proba(X_test_sel)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_test_sel)\n",
    "\n",
    "    # Get predicted labels for accuracy\n",
    "    y_train_pred = model.predict(X_train_sel)\n",
    "    y_test_pred = model.predict(X_test_sel)\n",
    "\n",
    "    # Print evaluation metrics for train and test sets\n",
    "    print(f\"\\n✅ Results for {classifier.__class__.__name__}:\")\n",
    "    print(f\"Train AUC: {roc_auc_score(y_train, y_train_proba):.4f}\")\n",
    "    print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "    print(f\"Test AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Computes a bootstrapped confidence interval for ROC AUC of the final model ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_final_model_auc_ci(\n",
    "    y_true,\n",
    "    y_pred_proba,\n",
    "    n_bootstrap: int = 1000,\n",
    "    ci: float = 0.95,\n",
    "    random_state: int = 42,\n",
    "    min_valid: int = 200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Stratified bootstrap CI for ROC AUC on small/imbalanced test sets.\n",
    "    - Preserves class counts in each bootstrap sample (positives/negatives drawn separately).\n",
    "    - Avoids invalid replicates with a single class.\n",
    "    - Returns mean AUC and (lower, upper) percentile CI.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        True binary labels. If not exactly {0,1}, they will be remapped to {0,1} by ordering.\n",
    "    y_pred_proba : array-like\n",
    "        Predicted probabilities or decision scores (higher = more likely positive).\n",
    "    n_bootstrap : int, default=2000\n",
    "        Number of bootstrap replicates.\n",
    "    ci : float, default=0.95\n",
    "        Confidence level (e.g., 0.95 for 95% CI).\n",
    "    random_state : int, default=42\n",
    "        Seed for reproducibility.\n",
    "    min_valid : int, default=200\n",
    "        Minimum recommended number of valid bootstrap replicates for a stable CI.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean_auc : float\n",
    "    lower : float\n",
    "    upper : float\n",
    "    valid : int\n",
    "        Number of valid bootstrap replicates used.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    y_true = y_true.values if hasattr(y_true, \"values\") else np.asarray(y_true)\n",
    "    y_pred_proba = y_pred_proba.values if hasattr(y_pred_proba, \"values\") else np.asarray(y_pred_proba)\n",
    "\n",
    "    # Basic checks\n",
    "    if y_true.shape[0] != y_pred_proba.shape[0]:\n",
    "        raise ValueError(\"y_true and y_pred_proba must have the same number of samples.\")\n",
    "\n",
    "    uniq = np.unique(y_true)\n",
    "    if uniq.size < 2:\n",
    "        raise ValueError(\"AUC undefined: test set has a single class.\")\n",
    "    if uniq.size > 2:\n",
    "        # Remap to binary by ordering (largest label -> positive class)\n",
    "        # This allows labels like {-1, +1} or {0, 2}\n",
    "        pos_label = uniq.max()\n",
    "        y_true = (y_true == pos_label).astype(int)\n",
    "        uniq = np.array([0, 1])\n",
    "\n",
    "    # Class counts\n",
    "    n_pos = int((y_true == 1).sum())\n",
    "    n_neg = int((y_true == 0).sum())\n",
    "    if min(n_pos, n_neg) < 3:\n",
    "        print(f\"Warning: very few positives/negatives (pos={n_pos}, neg={n_neg}); CI will be unstable.\")\n",
    "\n",
    "    # Index pools by class\n",
    "    pos_idx = np.where(y_true == 1)[0]\n",
    "    neg_idx = np.where(y_true == 0)[0]\n",
    "\n",
    "    aucs = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Stratified resample: draw with replacement within each class\n",
    "        b_pos = rng.choice(pos_idx, size=n_pos, replace=True)\n",
    "        b_neg = rng.choice(neg_idx, size=n_neg, replace=True)\n",
    "        b_idx = np.concatenate([b_pos, b_neg])\n",
    "        rng.shuffle(b_idx)  # order doesn't matter for AUC, but good practice\n",
    "\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_true[b_idx], y_pred_proba[b_idx]))\n",
    "        except ValueError:\n",
    "            # Extremely unlikely with stratified sampling; keep guard anyway\n",
    "            continue\n",
    "\n",
    "    valid = len(aucs)\n",
    "    if valid == 0:\n",
    "        print(\"Error: No valid bootstrap samples generated.\")\n",
    "        return None, None, None, 0\n",
    "    if valid < min_valid:\n",
    "        print(f\"Warning: Only {valid} valid bootstrap samples (min recommended {min_valid}). CI may be unreliable.\")\n",
    "\n",
    "    # Percentile CI\n",
    "    lower = float(np.percentile(aucs, (1 - ci) / 2 * 100))\n",
    "    upper = float(np.percentile(aucs, (1 + ci) / 2 * 100))\n",
    "    mean_auc = float(np.mean(aucs))\n",
    "\n",
    "    print(f\"Bootstrapped {int(ci*100)}% CI for Final Model Test AUC: {mean_auc:.4f} [{lower:.4f}, {upper:.4f}] \"\n",
    "          f\"(valid reps = {valid})\")\n",
    "    return mean_auc, lower, upper, valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === PSO with Bootstrap LASSO (Hybrid Approach) function ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrected_main_pipeline():\n",
    "    \"\"\"\n",
    "    CORRECTED main pipeline that fixes all critical methodological issues:\n",
    "    1. Fixed PSO implementation (no more CV reuse bug)\n",
    "    2. Proper feature mapping using feature names instead of indices\n",
    "    3. Methodologically sound consensus building\n",
    "    4. Proper data handling throughout the pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CORRECTED RADIOMICS FEATURE SELECTION PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ===============================================================\n",
    "    # 1) Load data and perform initial 80/20 split\n",
    "    # ===============================================================\n",
    "    print(\"\\nStep 1: Loading data and creating train/test split...\")\n",
    "    \n",
    "    radiomics_data, clinical_data = load_data()\n",
    "    radiomics_cols = get_radiomics_columns(radiomics_data)\n",
    "    X_raw = radiomics_data[radiomics_cols].values\n",
    "    y = clinical_data[\"LocoRegeonalRecurrence\"].values\n",
    "    feature_names = radiomics_data[radiomics_cols].columns.tolist()\n",
    "\n",
    "    print(f\"Dataset: {len(X_raw)} samples, {X_raw.shape[1]} features\")\n",
    "    print(f\"Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%), \"\n",
    "          f\"Non-LRR={len(y)-np.sum(y)} ({100*(len(y)-np.sum(y))/len(y):.1f}%)\")\n",
    "\n",
    "    # Proper 80/20 split with stratification\n",
    "    X_temp, X_test_raw, y_temp, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Training/Validation: {len(X_temp)} samples\")\n",
    "    print(f\"Test (held-out): {len(X_test_raw)} samples\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 2) 5-Fold CV with corrected feature selection pipeline\n",
    "    # ===============================================================\n",
    "    print(f\"\\nStep 2: 5-Fold Cross-Validation with corrected feature selection...\")\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define classifiers\n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        GaussianNB(),\n",
    "        SVC(kernel='linear', probability=True),\n",
    "        SVC(kernel='rbf', probability=True),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    ]\n",
    "\n",
    "    # CORRECTED: Store selected feature NAMES (not indices) for proper consensus\n",
    "    fold_selected_features = {}  # classifier -> [fold_features_sets]\n",
    "    classifier_fold_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        fold_selected_features[clf_name] = []\n",
    "        classifier_fold_results[clf_name] = {\n",
    "            'train_aucs': [], 'val_aucs': [], 'train_accs': [], 'val_accs': []\n",
    "        }\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold_id, (tr_idx, va_idx) in enumerate(skf.split(X_temp, y_temp), 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROCESSING FOLD {fold_id}/5\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        X_tr_raw, X_va_raw = X_temp[tr_idx], X_temp[va_idx]\n",
    "        y_tr, y_va = y_temp[tr_idx], y_temp[va_idx]\n",
    "\n",
    "        # STEP 1: Proper scaling (fit on train, transform both)\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_scaled = scaler.fit_transform(X_tr_raw)\n",
    "        X_va_scaled = scaler.transform(X_va_raw)\n",
    "\n",
    "        # STEP 2: Bootstrap LASSO feature selection (on training fold only)\n",
    "        print(f\"Applying Bootstrap LASSO feature selection...\")\n",
    "        stable_idx_fold = bootstrap_lasso_fs(\n",
    "            X_tr_scaled, y_tr, n_bootstrap=1000, freq_threshold=0.7\n",
    "        )\n",
    "        stable_idx_fold = np.asarray(stable_idx_fold)\n",
    "        \n",
    "        if len(stable_idx_fold) == 0:\n",
    "            print(f\"Warning: No stable features found in fold {fold_id}. Skipping fold.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"LASSO selected {len(stable_idx_fold)} features from {X_tr_scaled.shape[1]}\")\n",
    "\n",
    "        # Apply LASSO selection to get reduced feature matrices\n",
    "        X_tr_lasso = X_tr_scaled[:, stable_idx_fold]\n",
    "        X_va_lasso = X_va_scaled[:, stable_idx_fold]\n",
    "        \n",
    "        # CORRECTED: Get feature names for LASSO-selected features\n",
    "        lasso_feature_names = [feature_names[i] for i in stable_idx_fold]\n",
    "\n",
    "        # STEP 3: PSO feature selection per classifier (CORRECTED VERSION)\n",
    "        for clf in classifiers:\n",
    "            clf_name = clf.__class__.__name__\n",
    "            print(f\"\\nProcessing {clf_name} with corrected PSO...\")\n",
    "            \n",
    "            try:\n",
    "                # Hyperparameter tuning on LASSO-selected features\n",
    "                tuned_clf = get_tuned_model(clf, X_tr_lasso, y_tr)\n",
    "\n",
    "                # CORRECTED PSO: Uses fixed evaluate_fitness function\n",
    "                best_particle, train_auc_hist, val_auc_hist = run_pso(\n",
    "                    X_tr_lasso, y_tr, X_va_lasso, y_va, tuned_clf, \n",
    "                    n_particles=20, max_iter=50, verbose=False\n",
    "                )\n",
    "\n",
    "                # Get PSO-selected feature names (not indices)\n",
    "                pso_selected_indices = np.where(best_particle == 1)[0]\n",
    "                pso_selected_feature_names = [lasso_feature_names[i] for i in pso_selected_indices]\n",
    "                \n",
    "                # Store selected feature names for this classifier and fold\n",
    "                fold_selected_features[clf_name].append(set(pso_selected_feature_names))\n",
    "\n",
    "                # Evaluate performance with selected features\n",
    "                if len(pso_selected_indices) > 0:\n",
    "                    X_tr_final = X_tr_lasso[:, best_particle == 1]\n",
    "                    X_va_final = X_va_lasso[:, best_particle == 1]\n",
    "                    \n",
    "                    # Train final model and evaluate\n",
    "                    final_model = make_pipeline(StandardScaler(), tuned_clf)\n",
    "                    final_model.fit(X_tr_final, y_tr)\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    if hasattr(final_model, 'predict_proba'):\n",
    "                        y_tr_proba = final_model.predict_proba(X_tr_final)[:, 1]\n",
    "                        y_va_proba = final_model.predict_proba(X_va_final)[:, 1]\n",
    "                    else:\n",
    "                        y_tr_proba = final_model.decision_function(X_tr_final)\n",
    "                        y_va_proba = final_model.decision_function(X_va_final)\n",
    "                    \n",
    "                    y_tr_pred = final_model.predict(X_tr_final)\n",
    "                    y_va_pred = final_model.predict(X_va_final)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    train_auc = roc_auc_score(y_tr, y_tr_proba)\n",
    "                    val_auc = roc_auc_score(y_va, y_va_proba)\n",
    "                    train_acc = accuracy_score(y_tr, y_tr_pred)\n",
    "                    val_acc = accuracy_score(y_va, y_va_pred)\n",
    "                    \n",
    "                    # Store results\n",
    "                    classifier_fold_results[clf_name]['train_aucs'].append(train_auc)\n",
    "                    classifier_fold_results[clf_name]['val_aucs'].append(val_auc)\n",
    "                    classifier_fold_results[clf_name]['train_accs'].append(train_acc)\n",
    "                    classifier_fold_results[clf_name]['val_accs'].append(val_acc)\n",
    "                    \n",
    "                    print(f\"  {clf_name}: Train AUC={train_auc:.4f}, Val AUC={val_auc:.4f}, \"\n",
    "                          f\"Features={len(pso_selected_indices)}\")\n",
    "                else:\n",
    "                    print(f\"  Warning: {clf_name} selected no features in fold {fold_id}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {clf_name}: {e}\")\n",
    "                fold_selected_features[clf_name].append(set())\n",
    "\n",
    "    # ===============================================================\n",
    "    # 3) CORRECTED consensus building using feature names\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BUILDING CONSENSUS FEATURES (CORRECTED METHOD)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build consensus per classifier, then combine\n",
    "    classifier_consensus_features = {}\n",
    "    \n",
    "    for clf_name in fold_selected_features:\n",
    "        if len(fold_selected_features[clf_name]) == 0:\n",
    "            classifier_consensus_features[clf_name] = set()\n",
    "            continue\n",
    "            \n",
    "        # Get all unique features selected by this classifier across folds\n",
    "        all_features_for_clf = set()\n",
    "        for fold_features in fold_selected_features[clf_name]:\n",
    "            all_features_for_clf.update(fold_features)\n",
    "        \n",
    "        # Count votes for each feature\n",
    "        feature_votes = {}\n",
    "        for feature in all_features_for_clf:\n",
    "            votes = sum(1 for fold_features in fold_selected_features[clf_name] \n",
    "                       if feature in fold_features)\n",
    "            feature_votes[feature] = votes\n",
    "        \n",
    "        # Select features with majority vote (>= 3 out of 5 folds)\n",
    "        consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                 if votes >= 3}\n",
    "        \n",
    "        # Fallback: if no features meet majority threshold, use any feature selected >= 2 times\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                     if votes >= 2}\n",
    "        \n",
    "        # Final fallback: use union if still empty\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = all_features_for_clf\n",
    "            \n",
    "        classifier_consensus_features[clf_name] = consensus_features_clf\n",
    "        print(f\"{clf_name}: {len(consensus_features_clf)} consensus features\")\n",
    "\n",
    "    # FINAL CONSENSUS: Union of all classifier consensus features\n",
    "    final_consensus_features = set()\n",
    "    for clf_features in classifier_consensus_features.values():\n",
    "        final_consensus_features.update(clf_features)\n",
    "    \n",
    "    # Convert back to indices for final evaluation\n",
    "    consensus_feature_names = list(final_consensus_features)\n",
    "    consensus_indices = [feature_names.index(fname) for fname in consensus_feature_names \n",
    "                        if fname in feature_names]\n",
    "    \n",
    "    print(f\"\\nFinal consensus: {len(consensus_indices)} features\")\n",
    "    print(f\"Consensus features: {consensus_feature_names[:10]}...\" if len(consensus_feature_names) > 10 \n",
    "          else f\"Consensus features: {consensus_feature_names}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 4) Final evaluation on held-out test set\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL EVALUATION ON HELD-OUT TEST SET\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if len(consensus_indices) == 0:\n",
    "        print(\"ERROR: No consensus features found. Cannot proceed with final evaluation.\")\n",
    "        return\n",
    "    \n",
    "    # Apply final scaling and consensus feature selection\n",
    "    scaler_final = StandardScaler()\n",
    "    X_trval_scaled = scaler_final.fit_transform(X_temp)\n",
    "    X_test_scaled = scaler_final.transform(X_test_raw)\n",
    "    \n",
    "    # Select consensus features\n",
    "    X_trval_final = X_trval_scaled[:, consensus_indices]\n",
    "    X_test_final = X_test_scaled[:, consensus_indices]\n",
    "    \n",
    "    print(f\"Final training set: {X_trval_final.shape}\")\n",
    "    print(f\"Final test set: {X_test_final.shape}\")\n",
    "\n",
    "    # Final evaluation per classifier\n",
    "    final_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        print(f\"\\nFinal evaluation: {clf_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Retune on full 80% with consensus features\n",
    "            tuned_clf_final = get_tuned_model(clf, X_trval_final, y_temp)\n",
    "            tuned_clf_final.fit(X_trval_final, y_temp)\n",
    "\n",
    "            # Training performance (80% data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_train_proba = tuned_clf_final.predict_proba(X_trval_final)[:, 1]\n",
    "            else:\n",
    "                y_train_proba = tuned_clf_final.decision_function(X_trval_final)\n",
    "            \n",
    "            y_train_pred = tuned_clf_final.predict(X_trval_final)\n",
    "            train_auc = roc_auc_score(y_temp, y_train_proba)\n",
    "            train_acc = accuracy_score(y_temp, y_train_pred)\n",
    "\n",
    "            # Test performance (20% held-out data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_test_proba = tuned_clf_final.predict_proba(X_test_final)[:, 1]\n",
    "            else:\n",
    "                y_test_proba = tuned_clf_final.decision_function(X_test_final)\n",
    "            \n",
    "            y_test_pred = tuned_clf_final.predict(X_test_final)\n",
    "            test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "            test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "            # Bootstrap confidence intervals\n",
    "            train_mean_auc, train_lower, train_upper, train_valid = bootstrap_final_model_auc_ci(\n",
    "                y_temp, y_train_proba, n_bootstrap=1000\n",
    "            )\n",
    "            \n",
    "            test_mean_auc, test_lower, test_upper, test_valid = bootstrap_final_model_auc_ci(\n",
    "                y_test, y_test_proba, n_bootstrap=1000\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            final_results[clf_name] = {\n",
    "                'train_auc': train_auc,\n",
    "                'train_acc': train_acc,\n",
    "                'test_auc': test_auc,\n",
    "                'test_acc': test_acc,\n",
    "                'train_ci_lower': train_lower,\n",
    "                'train_ci_upper': train_upper,\n",
    "                'test_ci_lower': test_lower,\n",
    "                'test_ci_upper': test_upper\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {clf_name}: {e}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 5) COMPREHENSIVE RESULTS SUMMARY\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COMPREHENSIVE PERFORMANCE SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nDATASET SUMMARY:\")\n",
    "    print(f\"- Total samples: {len(X_raw)} (Train/Val: {len(X_temp)}, Test: {len(X_test_raw)})\")\n",
    "    print(f\"- Original features: {X_raw.shape[1]}\")\n",
    "    print(f\"- Consensus features: {len(consensus_indices)}\")\n",
    "    print(f\"- Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%)\")\n",
    "\n",
    "    # Cross-validation performance summary\n",
    "    print(f\"\\nCROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC':<15} {'Val AUC':<15} {'Train Acc':<15} {'Val Acc':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for clf_name, results in classifier_fold_results.items():\n",
    "        if results['train_aucs']:\n",
    "            train_auc_mean = np.mean(results['train_aucs'])\n",
    "            train_auc_std = np.std(results['train_aucs'])\n",
    "            val_auc_mean = np.mean(results['val_aucs'])\n",
    "            val_auc_std = np.std(results['val_aucs'])\n",
    "            train_acc_mean = np.mean(results['train_accs'])\n",
    "            train_acc_std = np.std(results['train_accs'])\n",
    "            val_acc_mean = np.mean(results['val_accs'])\n",
    "            val_acc_std = np.std(results['val_accs'])\n",
    "            \n",
    "            print(f\"{clf_name:<25} {train_auc_mean:.3f}±{train_auc_std:.3f}     \"\n",
    "                  f\"{val_auc_mean:.3f}±{val_auc_std:.3f}     \"\n",
    "                  f\"{train_acc_mean:.3f}±{train_acc_std:.3f}     \"\n",
    "                  f\"{val_acc_mean:.3f}±{val_acc_std:.3f}\")\n",
    "\n",
    "    # Final test performance\n",
    "    print(f\"\\nFINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC [95% CI]':<25} {'Test AUC [95% CI]':<25} {'Test Acc':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for clf_name, results in final_results.items():\n",
    "        train_auc = results['train_auc']\n",
    "        train_lower = results['train_ci_lower']\n",
    "        train_upper = results['train_ci_upper']\n",
    "        test_auc = results['test_auc']\n",
    "        test_lower = results['test_ci_lower']\n",
    "        test_upper = results['test_ci_upper']\n",
    "        test_acc = results['test_acc']\n",
    "\n",
    "        print(f\"{clf_name:<25} {train_auc:.3f} [{train_lower:.3f},{train_upper:.3f}]   \"\n",
    "              f\"{test_auc:.3f} [{test_lower:.3f},{test_upper:.3f}]   {test_acc:.3f}\")\n",
    "\n",
    "    # Best performer\n",
    "    if final_results:\n",
    "        best_clf = max(final_results.keys(), key=lambda x: final_results[x]['test_auc'])\n",
    "        best_test_auc = final_results[best_clf]['test_auc']\n",
    "        best_test_acc = final_results[best_clf]['test_acc']\n",
    "        \n",
    "        print(f\"\\nBest Test Performance: {best_clf}\")\n",
    "        print(f\"Test AUC: {best_test_auc:.4f}, Test Accuracy: {best_test_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"CORRECTED PIPELINE COMPLETE - ALL METHODOLOGICAL ISSUES FIXED\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return final_results, consensus_feature_names, classifier_fold_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Only PSO function ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pso_only_main_pipeline():\n",
    "    \"\"\"\n",
    "    PSO-ONLY feature selection pipeline (without LASSO pre-filtering).\n",
    "    This version applies PSO directly to all original features for each classifier.\n",
    "    \n",
    "    Pipeline: Raw Data → 80/20 Split → 5-Fold CV → PSO → Consensus → Final Test\n",
    "    \n",
    "    Uses the same corrected PSO implementation to ensure methodological soundness.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"PSO-ONLY RADIOMICS FEATURE SELECTION PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ===============================================================\n",
    "    # 1) Load data and perform initial 80/20 split\n",
    "    # ===============================================================\n",
    "    print(\"\\nStep 1: Loading data and creating train/test split...\")\n",
    "    \n",
    "    radiomics_data, clinical_data = load_data()\n",
    "    radiomics_cols = get_radiomics_columns(radiomics_data)\n",
    "    X_raw = radiomics_data[radiomics_cols].values\n",
    "    y = clinical_data[\"LocoRegeonalRecurrence\"].values\n",
    "    feature_names = radiomics_data[radiomics_cols].columns.tolist()\n",
    "\n",
    "    print(f\"Dataset: {len(X_raw)} samples, {X_raw.shape[1]} features\")\n",
    "    print(f\"Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%), \"\n",
    "          f\"Non-LRR={len(y)-np.sum(y)} ({100*(len(y)-np.sum(y))/len(y):.1f}%)\")\n",
    "\n",
    "    # Proper 80/20 split with stratification\n",
    "    X_temp, X_test_raw, y_temp, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Training/Validation: {len(X_temp)} samples\")\n",
    "    print(f\"Test (held-out): {len(X_test_raw)} samples\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 2) 5-Fold CV with PSO-only feature selection\n",
    "    # ===============================================================\n",
    "    print(f\"\\nStep 2: 5-Fold Cross-Validation with PSO-only feature selection...\")\n",
    "    print(\"Note: PSO will work on all original features (no LASSO pre-filtering)\")\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define classifiers\n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        GaussianNB(),\n",
    "        SVC(kernel='linear', probability=True),\n",
    "        SVC(kernel='rbf', probability=True),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    ]\n",
    "\n",
    "    # Store selected feature NAMES for proper consensus building\n",
    "    fold_selected_features = {}  # classifier -> [fold_features_sets]\n",
    "    classifier_fold_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        fold_selected_features[clf_name] = []\n",
    "        classifier_fold_results[clf_name] = {\n",
    "            'train_aucs': [], 'val_aucs': [], 'train_accs': [], 'val_accs': []\n",
    "        }\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold_id, (tr_idx, va_idx) in enumerate(skf.split(X_temp, y_temp), 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROCESSING FOLD {fold_id}/5\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        X_tr_raw, X_va_raw = X_temp[tr_idx], X_temp[va_idx]\n",
    "        y_tr, y_va = y_temp[tr_idx], y_temp[va_idx]\n",
    "\n",
    "        # STEP 1: Proper scaling (fit on train, transform both)\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_scaled = scaler.fit_transform(X_tr_raw)\n",
    "        X_va_scaled = scaler.transform(X_va_raw)\n",
    "        \n",
    "        print(f\"Working with ALL {X_tr_scaled.shape[1]} original features\")\n",
    "\n",
    "        # STEP 2: PSO feature selection per classifier (directly on all features)\n",
    "        for clf in classifiers:\n",
    "            clf_name = clf.__class__.__name__\n",
    "            print(f\"\\nProcessing {clf_name} with PSO on full feature set...\")\n",
    "            \n",
    "            try:\n",
    "                # Hyperparameter tuning on full scaled feature set\n",
    "                tuned_clf = get_tuned_model(clf, X_tr_scaled, y_tr)\n",
    "\n",
    "                # PSO feature selection on ALL features (no LASSO pre-filtering)\n",
    "                print(f\"  Running PSO on {X_tr_scaled.shape[1]} features...\")\n",
    "                best_particle, train_auc_hist, val_auc_hist = run_pso(\n",
    "                    X_tr_scaled, y_tr, X_va_scaled, y_va, tuned_clf, \n",
    "                    n_particles=30,  # Slightly more particles for larger search space\n",
    "                    max_iter=50,     # More iterations for full feature space\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "                # Get PSO-selected feature names\n",
    "                pso_selected_indices = np.where(best_particle == 1)[0]\n",
    "                pso_selected_feature_names = [feature_names[i] for i in pso_selected_indices]\n",
    "                \n",
    "                # Store selected feature names for this classifier and fold\n",
    "                fold_selected_features[clf_name].append(set(pso_selected_feature_names))\n",
    "\n",
    "                # Evaluate performance with PSO-selected features\n",
    "                if len(pso_selected_indices) > 0:\n",
    "                    X_tr_pso = X_tr_scaled[:, best_particle == 1]\n",
    "                    X_va_pso = X_va_scaled[:, best_particle == 1]\n",
    "                    \n",
    "                    # Train final model and evaluate\n",
    "                    final_model = make_pipeline(StandardScaler(), tuned_clf)\n",
    "                    final_model.fit(X_tr_pso, y_tr)\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    if hasattr(final_model, 'predict_proba'):\n",
    "                        y_tr_proba = final_model.predict_proba(X_tr_pso)[:, 1]\n",
    "                        y_va_proba = final_model.predict_proba(X_va_pso)[:, 1]\n",
    "                    else:\n",
    "                        y_tr_proba = final_model.decision_function(X_tr_pso)\n",
    "                        y_va_proba = final_model.decision_function(X_va_pso)\n",
    "                    \n",
    "                    y_tr_pred = final_model.predict(X_tr_pso)\n",
    "                    y_va_pred = final_model.predict(X_va_pso)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    train_auc = roc_auc_score(y_tr, y_tr_proba)\n",
    "                    val_auc = roc_auc_score(y_va, y_va_proba)\n",
    "                    train_acc = accuracy_score(y_tr, y_tr_pred)\n",
    "                    val_acc = accuracy_score(y_va, y_va_pred)\n",
    "                    \n",
    "                    # Store results\n",
    "                    classifier_fold_results[clf_name]['train_aucs'].append(train_auc)\n",
    "                    classifier_fold_results[clf_name]['val_aucs'].append(val_auc)\n",
    "                    classifier_fold_results[clf_name]['train_accs'].append(train_acc)\n",
    "                    classifier_fold_results[clf_name]['val_accs'].append(val_acc)\n",
    "                    \n",
    "                    print(f\"  {clf_name}: Train AUC={train_auc:.4f}, Val AUC={val_auc:.4f}, \"\n",
    "                          f\"Features selected={len(pso_selected_indices)}\")\n",
    "                else:\n",
    "                    print(f\"  Warning: {clf_name} selected no features in fold {fold_id}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {clf_name}: {e}\")\n",
    "                fold_selected_features[clf_name].append(set())\n",
    "\n",
    "    # ===============================================================\n",
    "    # 3) Build consensus features using the same method\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BUILDING CONSENSUS FEATURES FROM PSO SELECTIONS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build consensus per classifier, then combine\n",
    "    classifier_consensus_features = {}\n",
    "    \n",
    "    for clf_name in fold_selected_features:\n",
    "        if len(fold_selected_features[clf_name]) == 0:\n",
    "            classifier_consensus_features[clf_name] = set()\n",
    "            continue\n",
    "            \n",
    "        # Get all unique features selected by this classifier across folds\n",
    "        all_features_for_clf = set()\n",
    "        for fold_features in fold_selected_features[clf_name]:\n",
    "            all_features_for_clf.update(fold_features)\n",
    "        \n",
    "        # Count votes for each feature\n",
    "        feature_votes = {}\n",
    "        for feature in all_features_for_clf:\n",
    "            votes = sum(1 for fold_features in fold_selected_features[clf_name] \n",
    "                       if feature in fold_features)\n",
    "            feature_votes[feature] = votes\n",
    "        \n",
    "        # Select features with majority vote (>= 3 out of 5 folds)\n",
    "        consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                 if votes >= 3}\n",
    "        \n",
    "        # Fallback: if no features meet majority threshold, use >= 2 votes\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                     if votes >= 2}\n",
    "        \n",
    "        # Final fallback: use union if still empty\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = all_features_for_clf\n",
    "            \n",
    "        classifier_consensus_features[clf_name] = consensus_features_clf\n",
    "        print(f\"{clf_name}: {len(consensus_features_clf)} consensus features\")\n",
    "\n",
    "    # FINAL CONSENSUS: Union of all classifier consensus features\n",
    "    final_consensus_features = set()\n",
    "    for clf_features in classifier_consensus_features.values():\n",
    "        final_consensus_features.update(clf_features)\n",
    "    \n",
    "    # Convert back to indices for final evaluation\n",
    "    consensus_feature_names = list(final_consensus_features)\n",
    "    consensus_indices = [feature_names.index(fname) for fname in consensus_feature_names \n",
    "                        if fname in feature_names]\n",
    "    \n",
    "    print(f\"\\nFinal PSO consensus: {len(consensus_indices)} features\")\n",
    "    print(f\"Consensus features: {consensus_feature_names[:10]}...\" if len(consensus_feature_names) > 10 \n",
    "          else f\"Consensus features: {consensus_feature_names}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 4) Final evaluation on held-out test set\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL EVALUATION ON HELD-OUT TEST SET\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if len(consensus_indices) == 0:\n",
    "        print(\"ERROR: No consensus features found. Cannot proceed with final evaluation.\")\n",
    "        return\n",
    "    \n",
    "    # Apply final scaling and consensus feature selection\n",
    "    scaler_final = StandardScaler()\n",
    "    X_trval_scaled = scaler_final.fit_transform(X_temp)\n",
    "    X_test_scaled = scaler_final.transform(X_test_raw)\n",
    "    \n",
    "    # Select PSO consensus features\n",
    "    X_trval_final = X_trval_scaled[:, consensus_indices]\n",
    "    X_test_final = X_test_scaled[:, consensus_indices]\n",
    "    \n",
    "    print(f\"Final training set: {X_trval_final.shape}\")\n",
    "    print(f\"Final test set: {X_test_final.shape}\")\n",
    "\n",
    "    # Final evaluation per classifier\n",
    "    final_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        print(f\"\\nFinal evaluation: {clf_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Retune on full 80% with PSO consensus features\n",
    "            tuned_clf_final = get_tuned_model(clf, X_trval_final, y_temp)\n",
    "            tuned_clf_final.fit(X_trval_final, y_temp)\n",
    "\n",
    "            # Training performance (80% data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_train_proba = tuned_clf_final.predict_proba(X_trval_final)[:, 1]\n",
    "            else:\n",
    "                y_train_proba = tuned_clf_final.decision_function(X_trval_final)\n",
    "            \n",
    "            y_train_pred = tuned_clf_final.predict(X_trval_final)\n",
    "            train_auc = roc_auc_score(y_temp, y_train_proba)\n",
    "            train_acc = accuracy_score(y_temp, y_train_pred)\n",
    "\n",
    "            # Test performance (20% held-out data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_test_proba = tuned_clf_final.predict_proba(X_test_final)[:, 1]\n",
    "            else:\n",
    "                y_test_proba = tuned_clf_final.decision_function(X_test_final)\n",
    "            \n",
    "            y_test_pred = tuned_clf_final.predict(X_test_final)\n",
    "            test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "            test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "            # Bootstrap confidence intervals\n",
    "            train_mean_auc, train_lower, train_upper, train_valid = bootstrap_final_model_auc_ci(\n",
    "                y_temp, y_train_proba, n_bootstrap=1000\n",
    "            )\n",
    "            \n",
    "            test_mean_auc, test_lower, test_upper, test_valid = bootstrap_final_model_auc_ci(\n",
    "                y_test, y_test_proba, n_bootstrap=1000\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            final_results[clf_name] = {\n",
    "                'train_auc': train_auc,\n",
    "                'train_acc': train_acc,\n",
    "                'test_auc': test_auc,\n",
    "                'test_acc': test_acc,\n",
    "                'train_ci_lower': train_lower,\n",
    "                'train_ci_upper': train_upper,\n",
    "                'test_ci_lower': test_lower,\n",
    "                'test_ci_upper': test_upper\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {clf_name}: {e}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 5) COMPREHENSIVE RESULTS SUMMARY\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"PSO-ONLY PIPELINE PERFORMANCE SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nDATASET SUMMARY:\")\n",
    "    print(f\"- Total samples: {len(X_raw)} (Train/Val: {len(X_temp)}, Test: {len(X_test_raw)})\")\n",
    "    print(f\"- Original features: {X_raw.shape[1]}\")\n",
    "    print(f\"- PSO consensus features: {len(consensus_indices)}\")\n",
    "    print(f\"- Feature reduction: {X_raw.shape[1]} → {len(consensus_indices)} \"\n",
    "          f\"({100*len(consensus_indices)/X_raw.shape[1]:.1f}%)\")\n",
    "    print(f\"- Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%)\")\n",
    "\n",
    "    # Cross-validation performance summary\n",
    "    print(f\"\\nCROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC':<15} {'Val AUC':<15} {'Train Acc':<15} {'Val Acc':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for clf_name, results in classifier_fold_results.items():\n",
    "        if results['train_aucs']:\n",
    "            train_auc_mean = np.mean(results['train_aucs'])\n",
    "            train_auc_std = np.std(results['train_aucs'])\n",
    "            val_auc_mean = np.mean(results['val_aucs'])\n",
    "            val_auc_std = np.std(results['val_aucs'])\n",
    "            train_acc_mean = np.mean(results['train_accs'])\n",
    "            train_acc_std = np.std(results['train_accs'])\n",
    "            val_acc_mean = np.mean(results['val_accs'])\n",
    "            val_acc_std = np.std(results['val_accs'])\n",
    "            \n",
    "            print(f\"{clf_name:<25} {train_auc_mean:.3f}±{train_auc_std:.3f}     \"\n",
    "                  f\"{val_auc_mean:.3f}±{val_auc_std:.3f}     \"\n",
    "                  f\"{train_acc_mean:.3f}±{train_acc_std:.3f}     \"\n",
    "                  f\"{val_acc_mean:.3f}±{val_acc_std:.3f}\")\n",
    "\n",
    "    # Final test performance\n",
    "    print(f\"\\nFINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC [95% CI]':<25} {'Test AUC [95% CI]':<25} {'Test Acc':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for clf_name, results in final_results.items():\n",
    "        train_auc = results['train_auc']\n",
    "        train_lower = results['train_ci_lower']\n",
    "        train_upper = results['train_ci_upper']\n",
    "        test_auc = results['test_auc']\n",
    "        test_lower = results['test_ci_lower']\n",
    "        test_upper = results['test_ci_upper']\n",
    "        test_acc = results['test_acc']\n",
    "\n",
    "        print(f\"{clf_name:<25} {train_auc:.3f} [{train_lower:.3f},{train_upper:.3f}]   \"\n",
    "              f\"{test_auc:.3f} [{test_lower:.3f},{test_upper:.3f}]   {test_acc:.3f}\")\n",
    "\n",
    "    # Best performer and comparison insights\n",
    "    if final_results:\n",
    "        best_clf = max(final_results.keys(), key=lambda x: final_results[x]['test_auc'])\n",
    "        best_test_auc = final_results[best_clf]['test_auc']\n",
    "        best_test_acc = final_results[best_clf]['test_acc']\n",
    "        \n",
    "        print(f\"\\nBest PSO-Only Performance: {best_clf}\")\n",
    "        print(f\"Test AUC: {best_test_auc:.4f}, Test Accuracy: {best_test_acc:.4f}\")\n",
    "        \n",
    "        # Calculate average feature reduction\n",
    "        avg_features_per_classifier = np.mean([len(features) for features in classifier_consensus_features.values() if features])\n",
    "        print(f\"Average features per classifier: {avg_features_per_classifier:.1f}\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"PSO-ONLY PIPELINE COMPLETE\")\n",
    "    print(\"Compare these results with LASSO+PSO to evaluate the impact of pre-filtering\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return final_results, consensus_feature_names, classifier_fold_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === `__main__` function for LASSO+PSO Vs Only PSO ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARING LASSO+PSO VS PSO-ONLY APPROACHES\n",
      "================================================================================\n",
      "\n",
      "==================================================\n",
      "APPROACH 1: LASSO + PSO\n",
      "==================================================\n",
      "================================================================================\n",
      "CORRECTED RADIOMICS FEATURE SELECTION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Step 1: Loading data and creating train/test split...\n",
      "Initial clinical data: 166 patients\n",
      "Final matched data: 163 patients\n",
      "Dataset: 163 samples, 103 features\n",
      "Class distribution: LRR=55 (33.7%), Non-LRR=108 (66.3%)\n",
      "Training/Validation: 130 samples\n",
      "Test (held-out): 33 samples\n",
      "\n",
      "Step 2: 5-Fold Cross-Validation with corrected feature selection...\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 1/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Running constrained Bootstrap LASSO...\n",
      "Target: 10-20 features with freq >= 0.7\n",
      "Valid bootstraps: 1000/1000\n",
      "Features at threshold 0.7: 0\n",
      "Too few features (0), lowering threshold...\n",
      "Using threshold 0.2: 15 features\n",
      "FINAL LASSO: Selected 15 features\n",
      "LASSO selected 15 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected PSO...\n",
      "  LogisticRegression: Train AUC=0.6912, Val AUC=0.7292, Features=6\n",
      "\n",
      "Processing GaussianNB with corrected PSO...\n",
      "  GaussianNB: Train AUC=0.7451, Val AUC=0.7153, Features=6\n",
      "\n",
      "Processing SVC with corrected PSO...\n",
      "  SVC: Train AUC=0.7292, Val AUC=0.7639, Features=6\n",
      "\n",
      "Processing SVC with corrected PSO...\n",
      "  SVC: Train AUC=0.3407, Val AUC=0.2847, Features=6\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected PSO...\n",
      "  DecisionTreeClassifier: Train AUC=0.8940, Val AUC=0.7188, Features=6\n",
      "\n",
      "Processing RandomForestClassifier with corrected PSO...\n",
      "  RandomForestClassifier: Train AUC=0.9980, Val AUC=0.6111, Features=6\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 2/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Running constrained Bootstrap LASSO...\n",
      "Target: 10-20 features with freq >= 0.7\n",
      "Valid bootstraps: 1000/1000\n",
      "Features at threshold 0.7: 0\n",
      "Too few features (0), lowering threshold...\n",
      "Using threshold 0.2: 14 features\n",
      "FINAL LASSO: Selected 14 features\n",
      "LASSO selected 14 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected PSO...\n",
      "  LogisticRegression: Train AUC=0.7395, Val AUC=0.6863, Features=6\n",
      "\n",
      "Processing GaussianNB with corrected PSO...\n",
      "  GaussianNB: Train AUC=0.7135, Val AUC=0.6993, Features=6\n",
      "\n",
      "Processing SVC with corrected PSO...\n",
      "  SVC: Train AUC=0.7627, Val AUC=0.6209, Features=6\n",
      "\n",
      "Processing SVC with corrected PSO...\n",
      "  SVC: Train AUC=0.7752, Val AUC=0.6209, Features=6\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected PSO...\n",
      "  DecisionTreeClassifier: Train AUC=0.8826, Val AUC=0.7255, Features=6\n",
      "\n",
      "Processing RandomForestClassifier with corrected PSO...\n",
      "  RandomForestClassifier: Train AUC=0.9168, Val AUC=0.6601, Features=6\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 3/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Running constrained Bootstrap LASSO...\n",
      "Target: 10-20 features with freq >= 0.7\n",
      "Valid bootstraps: 1000/1000\n",
      "Features at threshold 0.7: 0\n",
      "Too few features (0), lowering threshold...\n",
      "Using threshold 0.2: 15 features\n",
      "FINAL LASSO: Selected 15 features\n",
      "LASSO selected 15 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected PSO...\n",
      "  LogisticRegression: Train AUC=0.7756, Val AUC=0.4641, Features=6\n",
      "\n",
      "Processing GaussianNB with corrected PSO...\n",
      "  GaussianNB: Train AUC=0.7768, Val AUC=0.4314, Features=6\n",
      "\n",
      "Processing SVC with corrected PSO...\n",
      "  SVC: Train AUC=0.8280, Val AUC=0.3922, Features=6\n",
      "\n",
      "Processing SVC with corrected PSO...\n",
      "  SVC: Train AUC=0.8075, Val AUC=0.3399, Features=6\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected PSO...\n",
      "  DecisionTreeClassifier: Train AUC=0.8872, Val AUC=0.5392, Features=6\n",
      "\n",
      "Processing RandomForestClassifier with corrected PSO...\n",
      "  RandomForestClassifier: Train AUC=0.9002, Val AUC=0.4510, Features=6\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 4/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Running constrained Bootstrap LASSO...\n",
      "Target: 10-20 features with freq >= 0.7\n",
      "Valid bootstraps: 1000/1000\n",
      "Features at threshold 0.7: 0\n",
      "Too few features (0), lowering threshold...\n",
      "Using threshold 0.2: 12 features\n",
      "FINAL LASSO: Selected 12 features\n",
      "LASSO selected 12 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected PSO...\n",
      "  LogisticRegression: Train AUC=0.7060, Val AUC=0.7386, Features=6\n",
      "\n",
      "Processing GaussianNB with corrected PSO...\n",
      "  GaussianNB: Train AUC=0.7321, Val AUC=0.7647, Features=6\n",
      "\n",
      "Processing SVC with corrected PSO...\n",
      "  SVC: Train AUC=0.2969, Val AUC=0.3007, Features=6\n",
      "\n",
      "Processing SVC with corrected PSO...\n",
      "  SVC: Train AUC=0.2957, Val AUC=0.2288, Features=6\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected PSO...\n",
      "  DecisionTreeClassifier: Train AUC=0.9112, Val AUC=0.4935, Features=6\n",
      "\n",
      "Processing RandomForestClassifier with corrected PSO...\n",
      "  RandomForestClassifier: Train AUC=0.9337, Val AUC=0.7124, Features=6\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 5/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Running constrained Bootstrap LASSO...\n",
      "Target: 10-20 features with freq >= 0.7\n",
      "Valid bootstraps: 1000/1000\n",
      "Features at threshold 0.7: 0\n",
      "Too few features (0), lowering threshold...\n",
      "Still too few, taking top 15 features\n",
      "FINAL LASSO: Selected 15 features\n",
      "LASSO selected 15 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected PSO...\n",
      "  LogisticRegression: Train AUC=0.7325, Val AUC=0.5621, Features=6\n",
      "\n",
      "Processing GaussianNB with corrected PSO...\n",
      "  GaussianNB: Train AUC=0.7545, Val AUC=0.5556, Features=6\n",
      "\n",
      "Processing SVC with corrected PSO...\n",
      "  SVC: Train AUC=0.2497, Val AUC=0.4510, Features=6\n",
      "\n",
      "Processing SVC with corrected PSO...\n",
      "  SVC: Train AUC=0.2464, Val AUC=0.4641, Features=6\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected PSO...\n",
      "  DecisionTreeClassifier: Train AUC=0.9888, Val AUC=0.4248, Features=6\n",
      "\n",
      "Processing RandomForestClassifier with corrected PSO...\n",
      "  RandomForestClassifier: Train AUC=0.9043, Val AUC=0.5752, Features=6\n",
      "\n",
      "============================================================\n",
      "BUILDING CONSENSUS FEATURES (CORRECTED METHOD)\n",
      "============================================================\n",
      "LogisticRegression: 4 consensus features\n",
      "GaussianNB: 3 consensus features\n",
      "SVC: 10 consensus features\n",
      "DecisionTreeClassifier: 5 consensus features\n",
      "RandomForestClassifier: 2 consensus features\n",
      "\n",
      "Final consensus: 11 features\n",
      "Consensus features: ['original_shape_Elongation', 'original_firstorder_Median', 'original_glcm_ClusterShade', 'original_shape_Maximum2DDiameterSlice', 'original_firstorder_Kurtosis', 'original_shape_Maximum2DDiameterRow', 'original_glszm_LargeAreaHighGrayLevelEmphasis', 'original_glcm_Idmn', 'original_shape_Flatness', 'original_glcm_Imc1']...\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION ON HELD-OUT TEST SET\n",
      "============================================================\n",
      "Final training set: (130, 11)\n",
      "Final test set: (33, 11)\n",
      "\n",
      "Final evaluation: LogisticRegression\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7143 [0.6136, 0.8058] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6553 [0.4463, 0.8595] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: GaussianNB\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7120 [0.6189, 0.8010] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7007 [0.4959, 0.8884] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.2867 [0.1950, 0.3869] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3488 [0.1488, 0.5579] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.2867 [0.1950, 0.3869] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3488 [0.1488, 0.5579] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: DecisionTreeClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7438 [0.6653, 0.8155] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6416 [0.4421, 0.8140] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: RandomForestClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.9271 [0.8795, 0.9625] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7215 [0.5411, 0.8843] (valid reps = 1000)\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "DATASET SUMMARY:\n",
      "- Total samples: 163 (Train/Val: 130, Test: 33)\n",
      "- Original features: 103\n",
      "- Consensus features: 11\n",
      "- Class distribution: LRR=55 (33.7%)\n",
      "\n",
      "CROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\n",
      "--------------------------------------------------------------------------------\n",
      "Classifier                Train AUC       Val AUC         Train Acc       Val Acc        \n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression        0.729±0.029     0.636±0.107     0.694±0.020     0.638±0.108\n",
      "GaussianNB                0.744±0.021     0.633±0.123     0.727±0.029     0.638±0.090\n",
      "SVC                       0.533±0.250     0.447±0.165     0.693±0.048     0.631±0.086\n",
      "DecisionTreeClassifier    0.913±0.039     0.580±0.121     0.842±0.047     0.600±0.110\n",
      "RandomForestClassifier    0.931±0.036     0.602±0.089     0.854±0.054     0.669±0.067\n",
      "\n",
      "FINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Classifier                Train AUC [95% CI]        Test AUC [95% CI]         Test Acc  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "LogisticRegression        0.714 [0.614,0.806]   0.661 [0.446,0.860]   0.636\n",
      "GaussianNB                0.712 [0.619,0.801]   0.707 [0.496,0.888]   0.636\n",
      "SVC                       0.287 [0.195,0.387]   0.343 [0.149,0.558]   0.667\n",
      "DecisionTreeClassifier    0.744 [0.665,0.816]   0.643 [0.442,0.814]   0.697\n",
      "RandomForestClassifier    0.927 [0.879,0.962]   0.723 [0.541,0.884]   0.667\n",
      "\n",
      "Best Test Performance: RandomForestClassifier\n",
      "Test AUC: 0.7231, Test Accuracy: 0.6667\n",
      "\n",
      "================================================================================\n",
      "CORRECTED PIPELINE COMPLETE - ALL METHODOLOGICAL ISSUES FIXED\n",
      "================================================================================\n",
      "\n",
      "==================================================\n",
      "APPROACH 2: PSO-ONLY\n",
      "==================================================\n",
      "================================================================================\n",
      "PSO-ONLY RADIOMICS FEATURE SELECTION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Step 1: Loading data and creating train/test split...\n",
      "Initial clinical data: 166 patients\n",
      "Final matched data: 163 patients\n",
      "Dataset: 163 samples, 103 features\n",
      "Class distribution: LRR=55 (33.7%), Non-LRR=108 (66.3%)\n",
      "Training/Validation: 130 samples\n",
      "Test (held-out): 33 samples\n",
      "\n",
      "Step 2: 5-Fold Cross-Validation with PSO-only feature selection...\n",
      "Note: PSO will work on all original features (no LASSO pre-filtering)\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 1/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  LogisticRegression: Train AUC=0.6703, Val AUC=0.8472, Features selected=6\n",
      "\n",
      "Processing GaussianNB with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  GaussianNB: Train AUC=0.7002, Val AUC=0.7639, Features selected=6\n",
      "\n",
      "Processing SVC with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  SVC: Train AUC=0.3333, Val AUC=0.1736, Features selected=6\n",
      "\n",
      "Processing SVC with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  SVC: Train AUC=0.3346, Val AUC=0.1667, Features selected=6\n",
      "\n",
      "Processing DecisionTreeClassifier with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.8515, Val AUC=0.5451, Features selected=6\n",
      "\n",
      "Processing RandomForestClassifier with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9134, Val AUC=0.6667, Features selected=6\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 2/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  LogisticRegression: Train AUC=0.6859, Val AUC=0.6863, Features selected=6\n",
      "\n",
      "Processing GaussianNB with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  GaussianNB: Train AUC=0.7130, Val AUC=0.7190, Features selected=6\n",
      "\n",
      "Processing SVC with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  SVC: Train AUC=0.3085, Val AUC=0.2745, Features selected=6\n",
      "\n",
      "Processing SVC with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  SVC: Train AUC=0.3023, Val AUC=0.2876, Features selected=6\n",
      "\n",
      "Processing DecisionTreeClassifier with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.8066, Val AUC=0.6438, Features selected=6\n",
      "\n",
      "Processing RandomForestClassifier with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.8807, Val AUC=0.6601, Features selected=6\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 3/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  LogisticRegression: Train AUC=0.7549, Val AUC=0.4379, Features selected=6\n",
      "\n",
      "Processing GaussianNB with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  GaussianNB: Train AUC=0.7619, Val AUC=0.4837, Features selected=6\n",
      "\n",
      "Processing SVC with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  SVC: Train AUC=0.2364, Val AUC=0.6536, Features selected=6\n",
      "\n",
      "Processing SVC with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  SVC: Train AUC=0.2327, Val AUC=0.5882, Features selected=6\n",
      "\n",
      "Processing DecisionTreeClassifier with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.9077, Val AUC=0.3105, Features selected=6\n",
      "\n",
      "Processing RandomForestClassifier with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9019, Val AUC=0.3464, Features selected=6\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 4/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  LogisticRegression: Train AUC=0.6836, Val AUC=0.7712, Features selected=6\n",
      "\n",
      "Processing GaussianNB with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  GaussianNB: Train AUC=0.7234, Val AUC=0.7974, Features selected=6\n",
      "\n",
      "Processing SVC with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  SVC: Train AUC=0.2845, Val AUC=0.2418, Features selected=6\n",
      "\n",
      "Processing SVC with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  SVC: Train AUC=0.3023, Val AUC=0.2092, Features selected=6\n",
      "\n",
      "Processing DecisionTreeClassifier with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.8716, Val AUC=0.5229, Features selected=6\n",
      "\n",
      "Processing RandomForestClassifier with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9130, Val AUC=0.6993, Features selected=6\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 5/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  LogisticRegression: Train AUC=0.7238, Val AUC=0.4902, Features selected=6\n",
      "\n",
      "Processing GaussianNB with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  GaussianNB: Train AUC=0.7168, Val AUC=0.6275, Features selected=6\n",
      "\n",
      "Processing SVC with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  SVC: Train AUC=0.2683, Val AUC=0.4118, Features selected=6\n",
      "\n",
      "Processing SVC with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  SVC: Train AUC=0.2642, Val AUC=0.4575, Features selected=6\n",
      "\n",
      "Processing DecisionTreeClassifier with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.8414, Val AUC=0.5523, Features selected=6\n",
      "\n",
      "Processing RandomForestClassifier with PSO on full feature set...\n",
      "  Running PSO on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.8890, Val AUC=0.5621, Features selected=6\n",
      "\n",
      "============================================================\n",
      "BUILDING CONSENSUS FEATURES FROM PSO SELECTIONS\n",
      "============================================================\n",
      "LogisticRegression: 4 consensus features\n",
      "GaussianNB: 2 consensus features\n",
      "SVC: 7 consensus features\n",
      "DecisionTreeClassifier: 4 consensus features\n",
      "RandomForestClassifier: 1 consensus features\n",
      "\n",
      "Final PSO consensus: 13 features\n",
      "Consensus features: ['original_shape_Elongation', 'original_glcm_ClusterProminence', 'original_shape_Maximum2DDiameterSlice', 'original_firstorder_Kurtosis', 'original_glszm_LargeAreaEmphasis', 'original_shape_SurfaceArea', 'original_shape_MinorAxisLength', 'original_glcm_DifferenceAverage', 'original_glcm_Idmn', 'original_firstorder_Maximum']...\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION ON HELD-OUT TEST SET\n",
      "============================================================\n",
      "Final training set: (130, 13)\n",
      "Final test set: (33, 13)\n",
      "\n",
      "Final evaluation: LogisticRegression\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7091 [0.6112, 0.7989] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6475 [0.4132, 0.8513] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: GaussianNB\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7272 [0.6271, 0.8081] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6895 [0.4835, 0.8802] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.2897 [0.1992, 0.3877] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3563 [0.1487, 0.5950] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.2897 [0.1992, 0.3877] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3563 [0.1487, 0.5950] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: DecisionTreeClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.8428 [0.7690, 0.9047] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6351 [0.4193, 0.8203] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: RandomForestClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.8885 [0.8298, 0.9363] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6543 [0.4421, 0.8347] (valid reps = 1000)\n",
      "\n",
      "================================================================================\n",
      "PSO-ONLY PIPELINE PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "DATASET SUMMARY:\n",
      "- Total samples: 163 (Train/Val: 130, Test: 33)\n",
      "- Original features: 103\n",
      "- PSO consensus features: 13\n",
      "- Feature reduction: 103 → 13 (12.6%)\n",
      "- Class distribution: LRR=55 (33.7%)\n",
      "\n",
      "CROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\n",
      "--------------------------------------------------------------------------------\n",
      "Classifier                Train AUC       Val AUC         Train Acc       Val Acc        \n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression        0.704±0.031     0.647±0.158     0.700±0.020     0.677±0.125\n",
      "GaussianNB                0.723±0.021     0.678±0.113     0.700±0.022     0.669±0.071\n",
      "SVC                       0.287±0.034     0.346±0.164     0.600±0.127     0.585±0.138\n",
      "DecisionTreeClassifier    0.856±0.033     0.515±0.110     0.794±0.023     0.569±0.095\n",
      "RandomForestClassifier    0.900±0.013     0.587±0.129     0.810±0.024     0.615±0.069\n",
      "\n",
      "FINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Classifier                Train AUC [95% CI]        Test AUC [95% CI]         Test Acc  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "LogisticRegression        0.709 [0.611,0.799]   0.653 [0.413,0.851]   0.667\n",
      "GaussianNB                0.727 [0.627,0.808]   0.694 [0.483,0.880]   0.727\n",
      "SVC                       0.290 [0.199,0.388]   0.351 [0.149,0.595]   0.667\n",
      "DecisionTreeClassifier    0.842 [0.769,0.905]   0.634 [0.419,0.820]   0.667\n",
      "RandomForestClassifier    0.889 [0.830,0.936]   0.657 [0.442,0.835]   0.667\n",
      "\n",
      "Best PSO-Only Performance: GaussianNB\n",
      "Test AUC: 0.6942, Test Accuracy: 0.7273\n",
      "Average features per classifier: 3.6\n",
      "\n",
      "================================================================================\n",
      "PSO-ONLY PIPELINE COMPLETE\n",
      "Compare these results with LASSO+PSO to evaluate the impact of pre-filtering\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FINAL COMPARISON SUMMARY\n",
      "================================================================================\n",
      "LASSO+PSO: Selected 11 consensus features\n",
      "PSO-Only:  Selected 13 consensus features\n",
      "\n",
      "Best LASSO+PSO: RandomForestClassifier (AUC: 0.7231)\n",
      "Best PSO-Only:  GaussianNB (AUC: 0.6942)\n",
      "→ LASSO+PSO outperforms PSO-only\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPARING LASSO+PSO VS PSO-ONLY APPROACHES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Approach 1: LASSO + PSO\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"APPROACH 1: LASSO + PSO\")\n",
    "    print(\"=\"*50)\n",
    "    lasso_pso_results, lasso_pso_features, lasso_pso_cv = corrected_main_pipeline()\n",
    "    \n",
    "    # Approach 2: PSO-Only  \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"APPROACH 2: PSO-ONLY\")\n",
    "    print(\"=\"*50)\n",
    "    pso_only_results, pso_only_features, pso_only_cv = pso_only_main_pipeline()\n",
    "    \n",
    "    # Comparison Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL COMPARISON SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"LASSO+PSO: Selected {len(lasso_pso_features)} consensus features\")\n",
    "    print(f\"PSO-Only:  Selected {len(pso_only_features)} consensus features\")\n",
    "    \n",
    "    # Compare best performers\n",
    "    best_lasso_pso = max(lasso_pso_results.keys(), key=lambda x: lasso_pso_results[x]['test_auc'])\n",
    "    best_pso_only = max(pso_only_results.keys(), key=lambda x: pso_only_results[x]['test_auc'])\n",
    "    \n",
    "    print(f\"\\nBest LASSO+PSO: {best_lasso_pso} (AUC: {lasso_pso_results[best_lasso_pso]['test_auc']:.4f})\")\n",
    "    print(f\"Best PSO-Only:  {best_pso_only} (AUC: {pso_only_results[best_pso_only]['test_auc']:.4f})\")\n",
    "    \n",
    "    if lasso_pso_results[best_lasso_pso]['test_auc'] > pso_only_results[best_pso_only]['test_auc']:\n",
    "        print(\"→ LASSO+PSO outperforms PSO-only\")\n",
    "    else:\n",
    "        print(\"→ PSO-only outperforms LASSO+PSO\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
