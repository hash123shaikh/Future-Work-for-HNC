{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === **Grey Wolf Optimization (GWO) for Feature Selection to optimize feature subsets for various ML classifiers** ===\n",
    "\n",
    "-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Stable Feature Pre-selection:**\n",
    "\n",
    "* Performed initial feature selection using **bootstrapped LASSO logistic regression** (`penalty='l1'`, `solver='liblinear'`, `cv=5`, `max_iter=5000`), repeated for **100 bootstrap samples** (`n_bootstrap=100`). Features were retained if selected in **≥70%** of bootstraps (`freq_threshold=0.7`), ensuring stability against sampling variance.\n",
    "\n",
    "\n",
    "**2. Metaheuristic Feature Selection:**\n",
    "\n",
    "* Applies **Particle Swarm Optimization (PSO)** for further feature selection from the stable set, using a population of **20 particles** (`n_particles=20`) and **50 iterations** (`max_iter=50`). Each particle represented a binary feature mask, and the swarm was optimized to maximize mean ROC AUC over 5-fold stratified cross-validation (`StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`).\n",
    "\n",
    "\n",
    "**3. Comprehensive Classifier Comparison:**\n",
    "\n",
    "* Evaluated a broad suite of classifiers:\n",
    "\n",
    "  * **Logistic Regression** (`max_iter=1000`), with grid search over `C=[0.001, 0.01, 0.1, 1, 10]` and `penalty=['l1', 'l2']`\n",
    "\n",
    "  * **Gaussian Naive Bayes** (default parameters)\n",
    "\n",
    "  * **Support Vector Machines** (linear and RBF kernels, `C=[0.01, 0.1, 1, 10]`, `gamma=['scale', 'auto']`)\n",
    "\n",
    "  * **Decision Tree** (`max_depth=[3, 5, 7]`, `min_samples_split=[5, 10]`, `min_samples_leaf=[2, 4]`)\n",
    "\n",
    "  * **Random Forest** (`n_estimators=[100, 200]`, `max_depth=[5, 10]`, `min_samples_split=[5, 10]`, `min_samples_leaf=[2, 4]`)\n",
    "\n",
    "  * **VotingClassifier** ensemble combining top-tuned base models with soft voting.\n",
    "\n",
    "* Hyperparameters were tuned for each classifier using **GridSearchCV** and 5-fold stratified cross-validation, optimizing for ROC AUC.\n",
    "\n",
    "\n",
    "**4. Class Imbalance and Data Integrity Handling:**\n",
    "\n",
    "* Maintained **class distribution balance** in all data splits using stratified sampling, both in train/test partitioning (`test_size=0.2`) and during cross-validation.\n",
    "\n",
    "* For bootstrapping and CI estimation, ensured that each resample included both classes—skipping samples otherwise to avoid invalid AUC calculations.\n",
    "\n",
    "\n",
    "**5. Feature Scaling and Pipeline Safety:**\n",
    "\n",
    "* Applied **feature standardization** (`StandardScaler()`) within all pipelines, fitting scalers only on training data to prevent information leakage.\n",
    "\n",
    "* Model pipelines (`make_pipeline(StandardScaler(), classifier)`) ensured consistent preprocessing during evaluation and prediction.\n",
    "\n",
    "\n",
    "**6. Model Evaluation & Uncertainty Quantification:**\n",
    "\n",
    "* Reported **ROC AUC and accuracy** for both training and testing sets at each PSO iteration.\n",
    "\n",
    "* Computed **bootstrapped confidence intervals** for test AUC (`n_bootstrap=1000`, `ci=0.95`), resampling test predictions to quantify model uncertainty and generalization performance.\n",
    "\n",
    "\n",
    "**7. Visualization and Monitoring:**\n",
    "\n",
    "* Plotted **train/test AUC trends** across PSO iterations for convergence analysis.\n",
    "\n",
    "* Displayed final **ROC curves** for both training and testing sets, including mean AUC and 95% confidence intervals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === IMPORTS ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                                            # Core numerical computation library for arrays and matrix operations\n",
    "import pandas as pd                                                                           # Library for data manipulation and analysis (tabular data, DataFrames)\n",
    "from sklearn.base import clone                                                                # For cloning estimators (useful when building pipelines or doing cross-validation)\n",
    "import matplotlib.pyplot as plt                                                               # For plotting graphs (e.g., ROC curves, feature importances, etc.)\n",
    "from scipy.stats import bootstrap                                                             # For statistical bootstrap resampling (scipy's bootstrap is for CI, sklearn's resample for random sampling)\n",
    "from sklearn.utils import resample                                                            # Utility to randomly resample datasets (e.g., for bootstrapping in ML)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold        # For splitting data, cross-validation, and stratified folds (for imbalanced classes)\n",
    "from sklearn.preprocessing import StandardScaler                                              # For scaling features to zero mean/unit variance (important for many ML algorithms)\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score                          # For evaluating model performance: ROC AUC, ROC curve points, accuracy\n",
    "\n",
    "# === CLASSIFIERS ===\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB                                                    # Naive Bayes classifier for classification tasks\n",
    "from sklearn.svm import SVC                                                                   # Support Vector Classifier (linear & nonlinear SVMs)\n",
    "from sklearn.tree import DecisionTreeClassifier                                               # Decision Tree classifier (nonlinear, interpretable ML model)\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier                         # Random Forest classifier (ensemble of Decision Trees)\n",
    "from sklearn.pipeline import make_pipeline                                                    # For creating machine learning pipelines (combining preprocessing + models)\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV                     # Logistic Regression (standard and cross-validated, for classification)\n",
    "\n",
    "# === GRID SEARCH HYPERPARAMETER TUNING ===\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV                                              # For exhaustive grid search over hyperparameters with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === LOAD AND PREPROCESS DATA ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Load radiomics and clinical CSV files into DataFrames\n",
    "    radiomics = pd.read_csv(\"./HNC-Prospective-Radiomics-305.csv\")\n",
    "    clinical = pd.read_csv(\"./proceed_radiomics_166.csv\")\n",
    "\n",
    "    print(f\"Initial clinical data: {len(clinical)} patients\")\n",
    "    # print(f\"Unique locations in clinical data: {clinical['Location'].value_counts()}\")\n",
    "\n",
    "    # Filter clinical data to only include specific tumor locations\n",
    "    # clinical = clinical[clinical[\"Location\"].isin(['Larynx', 'Tonsil', 'Hypopharynx', 'Oropharynx', 'BOT', 'Other'])]\n",
    "    # print(f\"After location filtering: {len(clinical)} patients\")\n",
    "\n",
    "    # Standardize 'research_subject_uid' in radiomics by keeping only the part before \"_\"\n",
    "    radiomics[\"research_subject_uid\"] = radiomics[\"research_subject_uid\"].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "    # Remove any leading/trailing spaces from 'Project ID' in clinical data\n",
    "    clinical[\"Project ID\"] = clinical[\"Project ID\"].str.strip()\n",
    "\n",
    "    # Filter radiomics to only keep rows with research_subject_uid present in clinical Project IDs\n",
    "    radiomics_filtered = radiomics[radiomics[\"research_subject_uid\"].isin(clinical[\"Project ID\"])]\n",
    "    \n",
    "    # Filter clinical to only keep rows with Project ID present in radiomics research_subject_uid\n",
    "    clinical_filtered = clinical[clinical[\"Project ID\"].isin(radiomics[\"research_subject_uid\"])]\n",
    "\n",
    "    print(f\"Final matched data: {len(clinical_filtered)} patients\")\n",
    "\n",
    "    # Sort both DataFrames by their ID columns and reset their indices\n",
    "    radiomics_filtered = radiomics_filtered.sort_values(by=\"research_subject_uid\").reset_index(drop=True)\n",
    "    clinical_filtered = clinical_filtered.sort_values(by=\"Project ID\").reset_index(drop=True)\n",
    "\n",
    "    # Return the filtered and aligned DataFrames for further processing\n",
    "    return radiomics_filtered, clinical_filtered\n",
    "\n",
    "\n",
    "def get_radiomics_columns(data):\n",
    "    \"\"\"\n",
    "    Returns the columns from 'original_shape_Elongation' to 'original_ngtdm_Strength'.\n",
    "    These typically represent the set of radiomics features you want to extract.\n",
    "    \"\"\"\n",
    "    start_column = \"original_shape_Elongation\"\n",
    "    end_column = \"original_ngtdm_Strength\"\n",
    "    start_idx = data.columns.get_loc(start_column)\n",
    "    end_idx = data.columns.get_loc(end_column) + 1  # +1 to include the end column itself\n",
    "    return data.columns[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Define hyperparameter grids for each classifier ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These grids help tune the model to avoid overfitting by optimizing regularization and other key parameters.\n",
    "all_grid_params = {\n",
    "    'LogisticRegression': {\n",
    "        'C': [1e-3, 3e-3, 1e-2, 3e-2, 0.1, 0.3, 1, 3, 10],          # Regularization strength (lower = stronger regularization)\n",
    "        'penalty': ['l1', 'l2'],                                                # Type of regularization: L1 (Lasso), L2 (Ridge)\n",
    "        'solver': ['liblinear'],                                                # Solver that supports both l1 and l2\n",
    "        'class_weight': [None, \"balanced\"],\n",
    "        'max_iter': [1000],\n",
    "    },\n",
    "    'GaussianNB': {},                                                           # No tunable hyperparameters for basic Naive Bayes\n",
    "    'SVC': [\n",
    "        # Linear SVC\n",
    "        {\n",
    "            'C': [1e-3, 1e-2, 0.1, 1, 10],                                      # Regularization strength\n",
    "            'kernel': ['linear'],                                               # Linear kernel\n",
    "            'probability': [True],                                              # Needed for probability predictions (e.g., ROC AUC)\n",
    "            'class_weight': [None, \"balanced\"],\n",
    "        },\n",
    "        # RBF SVC\n",
    "        {\n",
    "            'C': [1e-3, 1e-2, 0.1, 1, 10],                                      # Regularization strength\n",
    "            'gamma': ['scale', 'auto', 1e-3, 1e-2, 1e-1],                       # Kernel coefficient for RBF\n",
    "            'kernel': ['rbf'],                                                  # RBF (nonlinear) kernel\n",
    "            'probability': [True],                                              # Probability estimates\n",
    "            'class_weight': [None, \"balanced\"],\n",
    "        }\n",
    "    ],\n",
    "    'DecisionTreeClassifier': {\n",
    "        'criterion': ['gini', 'entropy'],                                       # Split quality metric\n",
    "        'max_depth': [2, 3, 4, 5, 7],                                           # Controls tree depth (regularization)\n",
    "        'min_samples_split': [5, 10, 15],                                       # Minimum samples required to split a node\n",
    "        'min_samples_leaf': [2, 4, 6],                                          # Minimum samples per leaf node\n",
    "        'max_features': ['sqrt', 'log2', None],                                 # Number of features considered at each split\n",
    "        'class_weight': [None, \"balanced\"],\n",
    "        'random_state': [42],\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [100, 200, 400],                                        # Number of trees\n",
    "        'max_depth': [3, 5, 7, 10],                                             # Maximum depth of trees\n",
    "        'min_samples_split': [5, 10],                                           # Minimum samples to split an internal node\n",
    "        'min_samples_leaf': [2, 4],                                             # Minimum samples at a leaf node\n",
    "        'max_features': ['sqrt', 'log2'],                                       # Number of features considered at each split\n",
    "        'bootstrap': [True],                                                    # Use bootstrap samples\n",
    "        'n_jobs': [-1],                                                         # Use all available CPU cores for parallel processing\n",
    "        'class_weight': [None, \"balanced\", \"balanced_subsample\"],\n",
    "        'random_state': [42],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# === Utility function to tune a classifier's hyperparameters using grid search and cross-validation ===\n",
    "\n",
    "def get_tuned_model(classifier, X_train, y_train):\n",
    "    name = classifier.__class__.__name__                                 # Get class name as a string (e.g., 'LogisticRegression')\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)      # 5-fold stratified cross-validation\n",
    "    \n",
    "    # Special handling for SVC as its grid is a list (to support both linear & RBF kernels)\n",
    "    if name == 'SVC':\n",
    "        grid = GridSearchCV(\n",
    "            clone(classifier),            # Clone base estimator to avoid data leakage between folds\n",
    "            all_grid_params['SVC'],\n",
    "            scoring='roc_auc',            # Use ROC AUC for model selection (works for imbalanced data)\n",
    "            cv=cv,                        # Use stratified k-fold\n",
    "            n_jobs=-1,                    # Use all CPU cores\n",
    "            refit=True,\n",
    "        )\n",
    "        grid.fit(X_train, y_train)       # Fit grid search\n",
    "        return grid.best_estimator_      # Return the model with best hyperparameters\n",
    "\n",
    "    # For all other classifiers with defined grid parameters\n",
    "    elif name in all_grid_params and all_grid_params[name]:\n",
    "        grid = GridSearchCV(\n",
    "            clone(classifier),\n",
    "            all_grid_params[name],\n",
    "            scoring='roc_auc',\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "            refit=True,\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        return grid.best_estimator_\n",
    "\n",
    "    # If no hyperparameters to tune (e.g., GaussianNB), return the original classifier\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === BOOTSTRAP LASSO FEATURE SELECTION ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_lasso_fs(X, y, n_bootstrap=1000, freq_threshold=0.7, random_state=42):\n",
    "    \"\"\"\n",
    "    CONSTRAINED Bootstrap LASSO that limits features to 10-20 range.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    selected_counts = np.zeros(X.shape[1])\n",
    "    valid_bootstraps = 0\n",
    "    \n",
    "    print(f\"Running constrained Bootstrap LASSO...\")\n",
    "    print(f\"Target: 10-20 features with freq >= {freq_threshold}\")\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        try:\n",
    "            # Resample with stratification\n",
    "            X_resampled, y_resampled = resample(X, y, stratify=y, random_state=random_state+i)\n",
    "            \n",
    "            # Skip if only one class\n",
    "            if len(np.unique(y_resampled)) < 2:\n",
    "                continue\n",
    "            \n",
    "            # AGGRESSIVE regularization to select fewer features\n",
    "            model = LogisticRegressionCV(\n",
    "                Cs=np.logspace(-4, -0.5, 20),  # Stronger regularization: 0.0001 to 0.316\n",
    "                penalty='l1',\n",
    "                solver='liblinear',\n",
    "                cv=3,\n",
    "                scoring='roc_auc',\n",
    "                max_iter=2000,\n",
    "                class_weight='balanced',\n",
    "                random_state=random_state+i\n",
    "            )\n",
    "            \n",
    "            model.fit(X_resampled, y_resampled)\n",
    "            \n",
    "            # Count selected features (non-zero coefficients)\n",
    "            selected_mask = np.abs(model.coef_[0]) > 1e-6\n",
    "            selected_counts += selected_mask.astype(int)\n",
    "            valid_bootstraps += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            if i < 5:\n",
    "                print(f\"Bootstrap {i} failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if valid_bootstraps == 0:\n",
    "        print(\"ERROR: No valid bootstrap samples!\")\n",
    "        return np.array([])\n",
    "    \n",
    "    # Calculate selection frequencies\n",
    "    selection_frequencies = selected_counts / valid_bootstraps\n",
    "    print(f\"Valid bootstraps: {valid_bootstraps}/{n_bootstrap}\")\n",
    "    \n",
    "    # Apply threshold\n",
    "    stable_features = selection_frequencies >= freq_threshold\n",
    "    n_selected = np.sum(stable_features)\n",
    "    print(f\"Features at threshold {freq_threshold}: {n_selected}\")\n",
    "    \n",
    "    # ENFORCE 10-20 feature range\n",
    "    if n_selected > 20:\n",
    "        print(f\"Too many features ({n_selected}), selecting top 20...\")\n",
    "        sorted_indices = np.argsort(selection_frequencies)[::-1]\n",
    "        stable_features = np.zeros_like(selection_frequencies, dtype=bool)\n",
    "        stable_features[sorted_indices[:20]] = True\n",
    "        n_selected = 20\n",
    "        \n",
    "    elif n_selected < 10:\n",
    "        print(f\"Too few features ({n_selected}), lowering threshold...\")\n",
    "        # Gradually lower threshold to get at least 10 features\n",
    "        for new_threshold in [0.6, 0.5, 0.4, 0.3, 0.2]:\n",
    "            stable_features = selection_frequencies >= new_threshold\n",
    "            n_selected = np.sum(stable_features)\n",
    "            if n_selected >= 10:\n",
    "                print(f\"Using threshold {new_threshold}: {n_selected} features\")\n",
    "                break\n",
    "        \n",
    "        # If still too few, take top 15\n",
    "        if n_selected < 10:\n",
    "            print(\"Still too few, taking top 15 features\")\n",
    "            sorted_indices = np.argsort(selection_frequencies)[::-1]\n",
    "            stable_features = np.zeros_like(selection_frequencies, dtype=bool)\n",
    "            stable_features[sorted_indices[:15]] = True\n",
    "            n_selected = 15\n",
    "    \n",
    "    stable_features_idx = np.where(stable_features)[0]\n",
    "    print(f\"FINAL LASSO: Selected {len(stable_features_idx)} features\")\n",
    "    \n",
    "    return stable_features_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === GWO FITNESS FUNCTION ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CORRECTED EVALUATE_FITNESS FOR GWO \n",
    "# ==========================================\n",
    "\n",
    "def evaluate_fitness(X, y, position, model, random_state=42):\n",
    "    \"\"\"\n",
    "    CORRECTED: Evaluates fitness using FRESH CV splits each time.\n",
    "    Same corrected approach as PSO/WOA - uses cross-validation on training data only.\n",
    "    \n",
    "    CRITICAL FIXES:\n",
    "    1. Uses CV on training data only (not train/val split)\n",
    "    2. Creates fresh StratifiedKFold for each evaluation\n",
    "    3. Handles edge cases properly\n",
    "    4. Consistent with PSO/WOA methodology\n",
    "    \n",
    "    Parameters:\n",
    "    - X: training feature matrix (numpy array)\n",
    "    - y: training target labels (numpy array) \n",
    "    - position: binary vector (1: feature selected, 0: not selected)\n",
    "    - model: classifier to use\n",
    "    - random_state: for reproducible CV splits\n",
    "\n",
    "    Returns: Mean ROC AUC from cross-validation on selected features.\n",
    "    \"\"\"\n",
    "    selected_features = np.count_nonzero(position)\n",
    "    \n",
    "    # STRICT  feature count enfocement\n",
    "    if selected_features == 0:\n",
    "        return 0.0  # No features = no predictive power\n",
    "    elif selected_features < 3:\n",
    "        return 0.2  # Too few features\n",
    "    elif selected_features > 10:\n",
    "        return 0.1  # Heavy penalty for too many features\n",
    "    \n",
    "    # Select features\n",
    "    X_selected = X[:, position == 1]\n",
    "    \n",
    "    try:\n",
    "        # CRITICAL FIX: Create FRESH CV splits each time\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        \n",
    "        # Perform cross-validation with robust error handling\n",
    "        scores = cross_val_score(clone(model), X_selected, y, cv=cv, scoring='roc_auc', n_jobs=1) # n_jobs=1 to avoid conflicts\n",
    "        \n",
    "        # Check for invalid scores\n",
    "        if np.any(np.isnan(scores)) or len(scores) == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        base_score = np.mean(scores)\n",
    "\n",
    "        # REWARD optimal feature counts (5-7 features)\n",
    "        if 5 <= selected_features <= 7:\n",
    "            return base_score * 1.2  # 20% bonus for optimal range\n",
    "        elif selected_features == 8:\n",
    "            return base_score * 1.0  # No penalty\n",
    "        elif selected_features <= 4:\n",
    "            return base_score * 0.8  # Small penalty for too few\n",
    "        elif selected_features >= 9:\n",
    "            return base_score * 0.6  # Larger penalty for too many\n",
    "        else:\n",
    "            return base_score\n",
    "    \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: CV failed for {selected_features} features: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === GWO Model for Feature Selection ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CORRECTED RUN_GWO FUNCTION\n",
    "# ==========================================\n",
    "\n",
    "def run_gwo(X_train, y_train, X_val, y_val, classifier, n_wolves=12, max_iter=20, verbose=True):\n",
    "    \"\"\"\n",
    "    CORRECTED Grey Wolf Optimizer for feature selection.\n",
    "    \n",
    "    CRITICAL FIXES:\n",
    "    1. Uses corrected evaluate_fitness with CV on training data only\n",
    "    2. Proper random state management\n",
    "    3. Enhanced error handling and progress tracking\n",
    "    4. Consistent methodology with PSO/WOA\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train, X_val: Feature matrices (training and validation)\n",
    "    - y_train, y_val: Target labels (training and validation)\n",
    "    - classifier: classifier to use\n",
    "    - n_wolves: number of wolves in the pack\n",
    "    - max_iter: maximum iterations\n",
    "    - verbose: Print progress updates\n",
    "    \n",
    "    Returns: best_position, train_auc_history, val_auc_history\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_auc_scores(X_train_sel, X_val_sel):\n",
    "        \"\"\"Compute AUC scores for selected features on train and validation sets.\"\"\"\n",
    "        temp_model = clone(classifier)\n",
    "        temp_model.fit(X_train_sel, y_train)\n",
    "        \n",
    "        # Get probabilities or decision scores\n",
    "        if hasattr(temp_model, 'predict_proba'):\n",
    "            y_train_proba = temp_model.predict_proba(X_train_sel)[:, 1]\n",
    "            y_val_proba = temp_model.predict_proba(X_val_sel)[:, 1]\n",
    "        else:\n",
    "            y_train_proba = temp_model.decision_function(X_train_sel)\n",
    "            y_val_proba = temp_model.decision_function(X_val_sel)\n",
    "        \n",
    "        train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "        val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "        return train_auc, val_auc\n",
    "    \n",
    "    n_features = X_train.shape[1]\n",
    "    \n",
    "    # Initialize wolf pack\n",
    "    wolves = np.zeros((n_wolves, n_features))\n",
    "    for i in range(n_wolves):\n",
    "        selection_prob = np.random.uniform(0.2, 0.6)\n",
    "        wolves[i] = (np.random.rand(n_features) < selection_prob).astype(int)\n",
    "        if np.sum(wolves[i]) == 0:\n",
    "            wolves[i][np.random.randint(n_features)] = 1\n",
    "    \n",
    "    # Initialize alpha, beta, delta wolves\n",
    "    alpha_pos, beta_pos, delta_pos = None, None, None\n",
    "    alpha_score = beta_score = delta_score = -np.inf\n",
    "    \n",
    "    # Track fitness and AUC histories\n",
    "    train_auc_history = []\n",
    "    val_auc_history = []\n",
    "    fitness_history = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Starting GWO optimization with {n_wolves} wolves for {max_iter} iterations...\")\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "        # CORRECTED: Evaluate fitness using CV on training data only\n",
    "        improved = False\n",
    "        for i in range(n_wolves):\n",
    "            # CRITICAL: Use corrected fitness evaluation with unique random state\n",
    "            fitness = evaluate_fitness(\n",
    "                X_train, y_train, wolves[i], classifier, \n",
    "                random_state=42 + iter * n_wolves + i\n",
    "            )\n",
    "            \n",
    "            # Update alpha, beta, delta positions\n",
    "            if fitness > alpha_score:\n",
    "                delta_score, delta_pos = beta_score, beta_pos.copy() if beta_pos is not None else None\n",
    "                beta_score, beta_pos = alpha_score, alpha_pos.copy() if alpha_pos is not None else None\n",
    "                alpha_score, alpha_pos = fitness, wolves[i].copy()\n",
    "                improved = True\n",
    "            elif fitness > beta_score:\n",
    "                delta_score, delta_pos = beta_score, beta_pos.copy() if beta_pos is not None else None\n",
    "                beta_score, beta_pos = fitness, wolves[i].copy()\n",
    "                improved = True\n",
    "            elif fitness > delta_score:\n",
    "                delta_score, delta_pos = fitness, wolves[i].copy()\n",
    "                improved = True\n",
    "        \n",
    "        # Track best fitness\n",
    "        fitness_history.append(alpha_score if alpha_score != -np.inf else 0)\n",
    "        \n",
    "        # Calculate training and validation AUC for monitoring (separate from fitness)\n",
    "        if alpha_pos is not None and np.sum(alpha_pos) > 0:\n",
    "            X_train_sel = X_train[:, alpha_pos == 1]\n",
    "            X_val_sel = X_val[:, alpha_pos == 1]\n",
    "            \n",
    "            try:\n",
    "                # Apply scaling for monitoring AUC calculation\n",
    "                scaler = StandardScaler()\n",
    "                X_train_sel_scaled = scaler.fit_transform(X_train_sel)\n",
    "                X_val_sel_scaled = scaler.transform(X_val_sel)\n",
    "                \n",
    "                train_auc, val_auc = compute_auc_scores(X_train_sel_scaled, X_val_sel_scaled)\n",
    "                train_auc_history.append(train_auc)\n",
    "                val_auc_history.append(val_auc)\n",
    "                \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"Warning: Could not compute monitoring AUC at iteration {iter+1}: {e}\")\n",
    "                train_auc_history.append(None)\n",
    "                val_auc_history.append(None)\n",
    "        else:\n",
    "            train_auc_history.append(None)\n",
    "            val_auc_history.append(None)\n",
    "\n",
    "        # Progress reporting\n",
    "        if verbose:\n",
    "            current_train_auc = train_auc_history[-1] if train_auc_history[-1] is not None else 0\n",
    "            current_val_auc = val_auc_history[-1] if val_auc_history[-1] is not None else 0\n",
    "            n_features_selected = int(np.sum(alpha_pos)) if alpha_pos is not None else 0\n",
    "            \n",
    "            print(f\"Iteration {iter+1:2d}/{max_iter} - Best Fitness: {alpha_score:.4f}, \"\n",
    "                  f\"Train AUC: {current_train_auc:.4f}, Val AUC: {current_val_auc:.4f}, \"\n",
    "                  f\"Features: {n_features_selected:3d}\")\n",
    "        \n",
    "        # Skip position update if we don't have all leaders yet\n",
    "        if alpha_pos is None or beta_pos is None or delta_pos is None:\n",
    "            continue\n",
    "            \n",
    "        # Update 'a' parameter (decreases linearly from 2 to 0)\n",
    "        a = 2 - iter * (2 / max_iter)\n",
    "        \n",
    "        # Update positions of search agents\n",
    "        for i in range(n_wolves):\n",
    "            for j in range(n_features):\n",
    "                # Calculate positions influenced by alpha, beta, delta\n",
    "                r1, r2 = np.random.rand(), np.random.rand()\n",
    "                A1 = 2 * a * r1 - a\n",
    "                C1 = 2 * r2\n",
    "                D_alpha = abs(C1 * alpha_pos[j] - wolves[i][j])\n",
    "                X1 = alpha_pos[j] - A1 * D_alpha\n",
    "\n",
    "                r1, r2 = np.random.rand(), np.random.rand()\n",
    "                A2 = 2 * a * r1 - a\n",
    "                C2 = 2 * r2\n",
    "                D_beta = abs(C2 * beta_pos[j] - wolves[i][j])\n",
    "                X2 = beta_pos[j] - A2 * D_beta\n",
    "\n",
    "                r1, r2 = np.random.rand(), np.random.rand()\n",
    "                A3 = 2 * a * r1 - a\n",
    "                C3 = 2 * r2\n",
    "                D_delta = abs(C3 * delta_pos[j] - wolves[i][j])\n",
    "                X3 = delta_pos[j] - A3 * D_delta\n",
    "\n",
    "                # Update position using weighted average\n",
    "                new_position = (X1 + X2 + X3) / 3\n",
    "                wolves[i][j] = 1 if new_position > 0.5 else 0\n",
    "            \n",
    "            # Ensure at least one feature is selected\n",
    "            if np.sum(wolves[i]) == 0:\n",
    "                wolves[i][np.random.randint(n_features)] = 1\n",
    "        \n",
    "        # Early stopping if no improvement for too long\n",
    "        if not improved and iter > max_iter // 3:\n",
    "            consecutive_no_improvement = sum(1 for k in range(max(0, len(fitness_history)-5), len(fitness_history)-1) \n",
    "                                           if fitness_history[k] == fitness_history[-1])\n",
    "            if consecutive_no_improvement >= 5:\n",
    "                if verbose:\n",
    "                    print(f\"Early stopping at iteration {iter+1} due to no improvement\")\n",
    "                break\n",
    "\n",
    "    if verbose:\n",
    "        n_selected = int(np.sum(alpha_pos)) if alpha_pos is not None else 0\n",
    "        print(f\"GWO completed! Best fitness (CV AUC): {alpha_score:.4f} with {n_selected} features\")\n",
    "    \n",
    "    return alpha_pos, train_auc_history, val_auc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Evaluate model with classifier function ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_classifier(X_train, X_test, y_train, y_test, selected_features, feature_names, classifier):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a given classifier using only the features selected by a feature selection algorithm.\n",
    "    Prints Train/Test AUC and Accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train, X_test: Feature matrices (numpy arrays)\n",
    "        y_train, y_test: Labels\n",
    "        selected_features: Binary vector indicating which features to use\n",
    "        feature_names: List of feature names (not used here, but useful for further reporting)\n",
    "        classifier: Classifier instance (e.g., LogisticRegression)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select only the features chosen by the feature selection mask\n",
    "    X_train_sel = X_train[:, selected_features == 1]\n",
    "    X_test_sel = X_test[:, selected_features == 1]\n",
    "\n",
    "    # If no features were selected, print a warning and stop\n",
    "    if X_train_sel.shape[1] == 0:\n",
    "        print(\"\\n⚠️ No features selected. Cannot train classifier.\")\n",
    "        return\n",
    "\n",
    "    # Build pipeline: scale features then fit classifier\n",
    "    model = make_pipeline(StandardScaler(), classifier)\n",
    "    model.fit(X_train_sel, y_train)  # Train the model on selected features\n",
    "\n",
    "    # Get predicted probabilities or decision function for AUC\n",
    "    y_train_proba = model.predict_proba(X_train_sel)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_train_sel)\n",
    "    y_test_proba = model.predict_proba(X_test_sel)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_test_sel)\n",
    "\n",
    "    # Get predicted labels for accuracy\n",
    "    y_train_pred = model.predict(X_train_sel)\n",
    "    y_test_pred = model.predict(X_test_sel)\n",
    "\n",
    "    # Print evaluation metrics for train and test sets\n",
    "    print(f\"\\n✅ Results for {classifier.__class__.__name__}:\")\n",
    "    print(f\"Train AUC: {roc_auc_score(y_train, y_train_proba):.4f}\")\n",
    "    print(f\"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "    print(f\"Test AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Computes a bootstraped confidence interval for ROC AUC of the final model ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_final_model_auc_ci(\n",
    "    y_true,\n",
    "    y_pred_proba,\n",
    "    n_bootstrap: int = 1000,\n",
    "    ci: float = 0.95,\n",
    "    random_state: int = 42,\n",
    "    min_valid: int = 200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Stratified bootstrap CI for ROC AUC on small/imbalanced test sets.\n",
    "    - Preserves class counts in each bootstrap sample (positives/negatives drawn separately).\n",
    "    - Avoids invalid replicates with a single class.\n",
    "    - Returns mean AUC and (lower, upper) percentile CI.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        True binary labels. If not exactly {0,1}, they will be remapped to {0,1} by ordering.\n",
    "    y_pred_proba : array-like\n",
    "        Predicted probabilities or decision scores (higher = more likely positive).\n",
    "    n_bootstrap : int, default=2000\n",
    "        Number of bootstrap replicates.\n",
    "    ci : float, default=0.95\n",
    "        Confidence level (e.g., 0.95 for 95% CI).\n",
    "    random_state : int, default=42\n",
    "        Seed for reproducibility.\n",
    "    min_valid : int, default=200\n",
    "        Minimum recommended number of valid bootstrap replicates for a stable CI.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean_auc : float\n",
    "    lower : float\n",
    "    upper : float\n",
    "    valid : int\n",
    "        Number of valid bootstrap replicates used.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    y_true = y_true.values if hasattr(y_true, \"values\") else np.asarray(y_true)\n",
    "    y_pred_proba = y_pred_proba.values if hasattr(y_pred_proba, \"values\") else np.asarray(y_pred_proba)\n",
    "\n",
    "    # Basic checks\n",
    "    if y_true.shape[0] != y_pred_proba.shape[0]:\n",
    "        raise ValueError(\"y_true and y_pred_proba must have the same number of samples.\")\n",
    "\n",
    "    uniq = np.unique(y_true)\n",
    "    if uniq.size < 2:\n",
    "        raise ValueError(\"AUC undefined: test set has a single class.\")\n",
    "    if uniq.size > 2:\n",
    "        # Remap to binary by ordering (largest label -> positive class)\n",
    "        # This allows labels like {-1, +1} or {0, 2}\n",
    "        pos_label = uniq.max()\n",
    "        y_true = (y_true == pos_label).astype(int)\n",
    "        uniq = np.array([0, 1])\n",
    "\n",
    "    # Class counts\n",
    "    n_pos = int((y_true == 1).sum())\n",
    "    n_neg = int((y_true == 0).sum())\n",
    "    if min(n_pos, n_neg) < 3:\n",
    "        print(f\"Warning: very few positives/negatives (pos={n_pos}, neg={n_neg}); CI will be unstable.\")\n",
    "\n",
    "    # Index pools by class\n",
    "    pos_idx = np.where(y_true == 1)[0]\n",
    "    neg_idx = np.where(y_true == 0)[0]\n",
    "\n",
    "    aucs = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Stratified resample: draw with replacement within each class\n",
    "        b_pos = rng.choice(pos_idx, size=n_pos, replace=True)\n",
    "        b_neg = rng.choice(neg_idx, size=n_neg, replace=True)\n",
    "        b_idx = np.concatenate([b_pos, b_neg])\n",
    "        rng.shuffle(b_idx)  # order doesn't matter for AUC, but good practice\n",
    "\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_true[b_idx], y_pred_proba[b_idx]))\n",
    "        except ValueError:\n",
    "            # Extremely unlikely with stratified sampling; keep guard anyway\n",
    "            continue\n",
    "\n",
    "    valid = len(aucs)\n",
    "    if valid == 0:\n",
    "        print(\"Error: No valid bootstrap samples generated.\")\n",
    "        return None, None, None, 0\n",
    "    if valid < min_valid:\n",
    "        print(f\"Warning: Only {valid} valid bootstrap samples (min recommended {min_valid}). CI may be unreliable.\")\n",
    "\n",
    "    # Percentile CI\n",
    "    lower = float(np.percentile(aucs, (1 - ci) / 2 * 100))\n",
    "    upper = float(np.percentile(aucs, (1 + ci) / 2 * 100))\n",
    "    mean_auc = float(np.mean(aucs))\n",
    "\n",
    "    print(f\"Bootstrapped {int(ci*100)}% CI for Final Model Test AUC: {mean_auc:.4f} [{lower:.4f}, {upper:.4f}] \"\n",
    "          f\"(valid reps = {valid})\")\n",
    "    return mean_auc, lower, upper, valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === `__main__` integration block with GWO with Bootstrap LASSO (Hybrid Approach) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CORRECTED GWO RADIOMICS FEATURE SELECTION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Step 1: Loading data and creating train/test split...\n",
      "Initial clinical data: 166 patients\n",
      "Final matched data: 163 patients\n",
      "Dataset: 163 samples, 103 features\n",
      "Class distribution: LRR=55 (33.7%), Non-LRR=108 (66.3%)\n",
      "Training/Validation: 130 samples\n",
      "Test (held-out): 33 samples\n",
      "\n",
      "Step 2: 5-Fold Cross-Validation with corrected GWO feature selection...\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 1/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Stable features (freq >= 0.5): [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102]\n",
      "LASSO selected 103 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected GWO...\n",
      "  LogisticRegression: Train AUC=0.6724, Val AUC=0.8194, Features=24\n",
      "\n",
      "Processing GaussianNB with corrected GWO...\n",
      "  GaussianNB: Train AUC=0.7173, Val AUC=0.7778, Features=43\n",
      "\n",
      "Processing SVC with corrected GWO...\n",
      "  SVC: Train AUC=0.3366, Val AUC=0.2083, Features=30\n",
      "\n",
      "Processing SVC with corrected GWO...\n",
      "  SVC: Train AUC=0.3313, Val AUC=0.1944, Features=49\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected GWO...\n",
      "  DecisionTreeClassifier: Train AUC=0.8254, Val AUC=0.6146, Features=35\n",
      "\n",
      "Processing RandomForestClassifier with corrected GWO...\n",
      "  RandomForestClassifier: Train AUC=0.9424, Val AUC=0.7153, Features=43\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 2/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Stable features (freq >= 0.5): [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102]\n",
      "LASSO selected 103 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected GWO...\n",
      "  LogisticRegression: Train AUC=0.6882, Val AUC=0.6797, Features=43\n",
      "\n",
      "Processing GaussianNB with corrected GWO...\n",
      "  GaussianNB: Train AUC=0.7255, Val AUC=0.6993, Features=38\n",
      "\n",
      "Processing SVC with corrected GWO...\n",
      "  SVC: Train AUC=0.3118, Val AUC=0.3333, Features=24\n",
      "\n",
      "Processing SVC with corrected GWO...\n",
      "  SVC: Train AUC=0.3072, Val AUC=0.3333, Features=49\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected GWO...\n",
      "  DecisionTreeClassifier: Train AUC=0.8029, Val AUC=0.5752, Features=19\n",
      "\n",
      "Processing RandomForestClassifier with corrected GWO...\n",
      "  RandomForestClassifier: Train AUC=0.9143, Val AUC=0.6667, Features=43\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 3/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Stable features (freq >= 0.5): [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102]\n",
      "LASSO selected 103 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected GWO...\n",
      "  LogisticRegression: Train AUC=0.7660, Val AUC=0.4379, Features=40\n",
      "\n",
      "Processing GaussianNB with corrected GWO...\n",
      "  GaussianNB: Train AUC=0.7747, Val AUC=0.4444, Features=32\n",
      "\n",
      "Processing SVC with corrected GWO...\n",
      "  SVC: Train AUC=0.7470, Val AUC=0.3922, Features=29\n",
      "\n",
      "Processing SVC with corrected GWO...\n",
      "  SVC: Train AUC=0.7532, Val AUC=0.4118, Features=55\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected GWO...\n",
      "  DecisionTreeClassifier: Train AUC=0.8783, Val AUC=0.3758, Features=53\n",
      "\n",
      "Processing RandomForestClassifier with corrected GWO...\n",
      "  RandomForestClassifier: Train AUC=0.9209, Val AUC=0.3464, Features=44\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 4/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Stable features (freq >= 0.5): [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102]\n",
      "LASSO selected 103 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected GWO...\n",
      "  LogisticRegression: Train AUC=0.6650, Val AUC=0.7647, Features=36\n",
      "\n",
      "Processing GaussianNB with corrected GWO...\n",
      "  GaussianNB: Train AUC=0.6770, Val AUC=0.6863, Features=39\n",
      "\n",
      "Processing SVC with corrected GWO...\n",
      "  SVC: Train AUC=0.3329, Val AUC=0.2157, Features=22\n",
      "\n",
      "Processing SVC with corrected GWO...\n",
      "  SVC: Train AUC=0.3263, Val AUC=0.2222, Features=52\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected GWO...\n",
      "  DecisionTreeClassifier: Train AUC=0.9089, Val AUC=0.6275, Features=52\n",
      "\n",
      "Processing RandomForestClassifier with corrected GWO...\n",
      "  RandomForestClassifier: Train AUC=0.9284, Val AUC=0.6797, Features=30\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 5/5\n",
      "============================================================\n",
      "Applying Bootstrap LASSO feature selection...\n",
      "Stable features (freq >= 0.5): [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102]\n",
      "LASSO selected 103 features from 103\n",
      "\n",
      "Processing LogisticRegression with corrected GWO...\n",
      "  LogisticRegression: Train AUC=0.7159, Val AUC=0.5686, Features=28\n",
      "\n",
      "Processing GaussianNB with corrected GWO...\n",
      "  GaussianNB: Train AUC=0.7021, Val AUC=0.5294, Features=31\n",
      "\n",
      "Processing SVC with corrected GWO...\n",
      "  SVC: Train AUC=0.7159, Val AUC=0.5621, Features=45\n",
      "\n",
      "Processing SVC with corrected GWO...\n",
      "  SVC: Train AUC=0.2870, Val AUC=0.4314, Features=36\n",
      "\n",
      "Processing DecisionTreeClassifier with corrected GWO...\n",
      "  DecisionTreeClassifier: Train AUC=0.8335, Val AUC=0.4412, Features=31\n",
      "\n",
      "Processing RandomForestClassifier with corrected GWO...\n",
      "  RandomForestClassifier: Train AUC=0.9052, Val AUC=0.5490, Features=41\n",
      "\n",
      "============================================================\n",
      "BUILDING CONSENSUS FEATURES (CORRECTED METHOD)\n",
      "============================================================\n",
      "LogisticRegression: 24 consensus features\n",
      "GaussianNB: 28 consensus features\n",
      "SVC: 81 consensus features\n",
      "DecisionTreeClassifier: 30 consensus features\n",
      "RandomForestClassifier: 36 consensus features\n",
      "\n",
      "Final GWO consensus: 94 features\n",
      "Consensus features: ['original_glszm_LargeAreaHighGrayLevelEmphasis', 'original_gldm_DependenceNonUniformityNormalized', 'original_glszm_GrayLevelNonUniformityNormalized', 'original_glcm_SumEntropy', 'original_gldm_GrayLevelVariance', 'original_glszm_GrayLevelVariance', 'original_glrlm_GrayLevelNonUniformityNormalized', 'original_glcm_JointEntropy', 'original_firstorder_90Percentile', 'original_glrlm_ShortRunHighGrayLevelEmphasis']...\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION ON HELD-OUT TEST SET\n",
      "============================================================\n",
      "Final training set: (130, 94)\n",
      "Final test set: (33, 94)\n",
      "\n",
      "Final evaluation: LogisticRegression\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6960 [0.5901, 0.7910] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6188 [0.3801, 0.8307] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: GaussianNB\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7183 [0.6226, 0.8046] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6704 [0.4628, 0.8595] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3038 [0.2119, 0.3999] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3351 [0.1281, 0.5455] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3038 [0.2119, 0.3999] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3351 [0.1281, 0.5455] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: DecisionTreeClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.8073 [0.7339, 0.8739] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6124 [0.4049, 0.8017] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: RandomForestClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.9063 [0.8515, 0.9479] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6496 [0.4213, 0.8388] (valid reps = 1000)\n",
      "\n",
      "================================================================================\n",
      "GWO PIPELINE COMPREHENSIVE PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "DATASET SUMMARY:\n",
      "- Total samples: 163 (Train/Val: 130, Test: 33)\n",
      "- Original features: 103\n",
      "- GWO consensus features: 94\n",
      "- Class distribution: LRR=55 (33.7%)\n",
      "\n",
      "CROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\n",
      "--------------------------------------------------------------------------------\n",
      "Classifier                Train AUC       Val AUC         Train Acc       Val Acc        \n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression        0.702±0.037     0.654±0.137     0.698±0.010     0.638±0.116\n",
      "GaussianNB                0.719±0.032     0.627±0.122     0.677±0.091     0.585±0.113\n",
      "SVC                       0.445±0.193     0.330±0.115     0.602±0.142     0.531±0.123\n",
      "DecisionTreeClassifier    0.850±0.038     0.527±0.100     0.787±0.032     0.538±0.054\n",
      "RandomForestClassifier    0.922±0.013     0.591±0.135     0.827±0.016     0.623±0.066\n",
      "\n",
      "FINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Classifier                Train AUC [95% CI]        Test AUC [95% CI]         Test Acc  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "LogisticRegression        0.696 [0.590,0.791]   0.624 [0.380,0.831]   0.727\n",
      "GaussianNB                0.719 [0.623,0.805]   0.674 [0.463,0.860]   0.697\n",
      "SVC                       0.304 [0.212,0.400]   0.331 [0.128,0.545]   0.667\n",
      "DecisionTreeClassifier    0.808 [0.734,0.874]   0.614 [0.405,0.802]   0.636\n",
      "RandomForestClassifier    0.906 [0.851,0.948]   0.653 [0.421,0.839]   0.667\n",
      "\n",
      "Best GWO Test Performance: GaussianNB\n",
      "Test AUC: 0.6736, Test Accuracy: 0.6970\n",
      "\n",
      "================================================================================\n",
      "CORRECTED GWO PIPELINE COMPLETE - MATCHES PSO/WOA METHODOLOGY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CORRECTED GWO MAIN PIPELINE (MATCHING PSO/WOA STRUCTURE)\n",
    "# ==========================================\n",
    "\n",
    "def corrected_gwo_main_pipeline():\n",
    "    \"\"\"\n",
    "    GWO main pipeline that matches the EXACT same structure as PSO/WOA pipelines:\n",
    "    1. 80/20 split\n",
    "    2. 5-Fold CV with LASSO+GWO per fold \n",
    "    3. Feature name-based consensus\n",
    "    4. Final evaluation on held-out test set\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CORRECTED GWO RADIOMICS FEATURE SELECTION PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ===============================================================\n",
    "    # 1) Load data and perform initial 80/20 split  \n",
    "    # ===============================================================\n",
    "    print(\"\\nStep 1: Loading data and creating train/test split...\")\n",
    "    \n",
    "    radiomics_data, clinical_data = load_data()\n",
    "    radiomics_cols = get_radiomics_columns(radiomics_data)\n",
    "    X_raw = radiomics_data[radiomics_cols].values\n",
    "    y = clinical_data[\"LocoRegeonalRecurrence\"].values\n",
    "    feature_names = radiomics_data[radiomics_cols].columns.tolist()\n",
    "\n",
    "    print(f\"Dataset: {len(X_raw)} samples, {X_raw.shape[1]} features\")\n",
    "    print(f\"Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%), \"\n",
    "          f\"Non-LRR={len(y)-np.sum(y)} ({100*(len(y)-np.sum(y))/len(y):.1f}%)\")\n",
    "\n",
    "    # Proper 80/20 split with stratification\n",
    "    X_temp, X_test_raw, y_temp, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Training/Validation: {len(X_temp)} samples\")\n",
    "    print(f\"Test (held-out): {len(X_test_raw)} samples\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 2) 5-Fold CV with corrected feature selection pipeline\n",
    "    # ===============================================================\n",
    "    print(f\"\\nStep 2: 5-Fold Cross-Validation with corrected GWO feature selection...\")\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define classifiers\n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        GaussianNB(),\n",
    "        SVC(kernel='linear', probability=True),\n",
    "        SVC(kernel='rbf', probability=True),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    ]\n",
    "\n",
    "    # Store selected feature NAMES (not indices) for proper consensus\n",
    "    fold_selected_features = {}  # classifier -> [fold_features_sets]\n",
    "    classifier_fold_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        fold_selected_features[clf_name] = []\n",
    "        classifier_fold_results[clf_name] = {\n",
    "            'train_aucs': [], 'val_aucs': [], 'train_accs': [], 'val_accs': []\n",
    "        }\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold_id, (tr_idx, va_idx) in enumerate(skf.split(X_temp, y_temp), 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROCESSING FOLD {fold_id}/5\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        X_tr_raw, X_va_raw = X_temp[tr_idx], X_temp[va_idx]\n",
    "        y_tr, y_va = y_temp[tr_idx], y_temp[va_idx]\n",
    "\n",
    "        # STEP 1: Proper scaling (fit on train, transform both)\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_scaled = scaler.fit_transform(X_tr_raw)\n",
    "        X_va_scaled = scaler.transform(X_va_raw)\n",
    "\n",
    "        # STEP 2: Bootstrap LASSO feature selection (on training fold only)\n",
    "        print(f\"Applying Bootstrap LASSO feature selection...\")\n",
    "        stable_idx_fold = bootstrap_lasso_fs(\n",
    "            X_tr_scaled, y_tr, n_bootstrap=1000, freq_threshold=0.7\n",
    "        )\n",
    "        stable_idx_fold = np.asarray(stable_idx_fold)\n",
    "        \n",
    "        if len(stable_idx_fold) == 0:\n",
    "            print(f\"Warning: No stable features found in fold {fold_id}. Skipping fold.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"LASSO selected {len(stable_idx_fold)} features from {X_tr_scaled.shape[1]}\")\n",
    "\n",
    "        # Apply LASSO selection to get reduced feature matrices\n",
    "        X_tr_lasso = X_tr_scaled[:, stable_idx_fold]\n",
    "        X_va_lasso = X_va_scaled[:, stable_idx_fold]\n",
    "        \n",
    "        # Get feature names for LASSO-selected features\n",
    "        lasso_feature_names = [feature_names[i] for i in stable_idx_fold]\n",
    "\n",
    "        # STEP 3: GWO feature selection per classifier (CORRECTED VERSION)\n",
    "        for clf in classifiers:\n",
    "            clf_name = clf.__class__.__name__\n",
    "            print(f\"\\nProcessing {clf_name} with corrected GWO...\")\n",
    "            \n",
    "            try:\n",
    "                # Hyperparameter tuning on LASSO-selected features\n",
    "                tuned_clf = get_tuned_model(clf, X_tr_lasso, y_tr)\n",
    "\n",
    "                # CORRECTED GWO: Uses fixed evaluate_fitness function\n",
    "                best_wolf, train_auc_hist, val_auc_hist = run_gwo(\n",
    "                    X_tr_lasso, y_tr, X_va_lasso, y_va, tuned_clf, \n",
    "                    n_wolves=12, max_iter=20, verbose=False\n",
    "                )\n",
    "\n",
    "                # Get GWO-selected feature names (not indices)\n",
    "                gwo_selected_indices = np.where(best_wolf == 1)[0]\n",
    "                gwo_selected_feature_names = [lasso_feature_names[i] for i in gwo_selected_indices]\n",
    "                \n",
    "                # Store selected feature names for this classifier and fold\n",
    "                fold_selected_features[clf_name].append(set(gwo_selected_feature_names))\n",
    "\n",
    "                # Evaluate performance with selected features\n",
    "                if len(gwo_selected_indices) > 0:\n",
    "                    X_tr_final = X_tr_lasso[:, best_wolf == 1]\n",
    "                    X_va_final = X_va_lasso[:, best_wolf == 1]\n",
    "                    \n",
    "                    # Train final model and evaluate\n",
    "                    final_model = make_pipeline(StandardScaler(), tuned_clf)\n",
    "                    final_model.fit(X_tr_final, y_tr)\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    if hasattr(final_model, 'predict_proba'):\n",
    "                        y_tr_proba = final_model.predict_proba(X_tr_final)[:, 1]\n",
    "                        y_va_proba = final_model.predict_proba(X_va_final)[:, 1]\n",
    "                    else:\n",
    "                        y_tr_proba = final_model.decision_function(X_tr_final)\n",
    "                        y_va_proba = final_model.decision_function(X_va_final)\n",
    "                    \n",
    "                    y_tr_pred = final_model.predict(X_tr_final)\n",
    "                    y_va_pred = final_model.predict(X_va_final)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    train_auc = roc_auc_score(y_tr, y_tr_proba)\n",
    "                    val_auc = roc_auc_score(y_va, y_va_proba)\n",
    "                    train_acc = accuracy_score(y_tr, y_tr_pred)\n",
    "                    val_acc = accuracy_score(y_va, y_va_pred)\n",
    "                    \n",
    "                    # Store results\n",
    "                    classifier_fold_results[clf_name]['train_aucs'].append(train_auc)\n",
    "                    classifier_fold_results[clf_name]['val_aucs'].append(val_auc)\n",
    "                    classifier_fold_results[clf_name]['train_accs'].append(train_acc)\n",
    "                    classifier_fold_results[clf_name]['val_accs'].append(val_acc)\n",
    "                    \n",
    "                    print(f\"  {clf_name}: Train AUC={train_auc:.4f}, Val AUC={val_auc:.4f}, \"\n",
    "                          f\"Features={len(gwo_selected_indices)}\")\n",
    "                else:\n",
    "                    print(f\"  Warning: {clf_name} selected no features in fold {fold_id}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {clf_name}: {e}\")\n",
    "                fold_selected_features[clf_name].append(set())\n",
    "\n",
    "    # ===============================================================\n",
    "    # 3) CORRECTED consensus building using feature names\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BUILDING CONSENSUS FEATURES (CORRECTED METHOD)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build consensus per classifier, then combine (same as PSO/WOA)\n",
    "    classifier_consensus_features = {}\n",
    "    \n",
    "    for clf_name in fold_selected_features:\n",
    "        if len(fold_selected_features[clf_name]) == 0:\n",
    "            classifier_consensus_features[clf_name] = set()\n",
    "            continue\n",
    "            \n",
    "        # Get all unique features selected by this classifier across folds\n",
    "        all_features_for_clf = set()\n",
    "        for fold_features in fold_selected_features[clf_name]:\n",
    "            all_features_for_clf.update(fold_features)\n",
    "        \n",
    "        # Count votes for each feature\n",
    "        feature_votes = {}\n",
    "        for feature in all_features_for_clf:\n",
    "            votes = sum(1 for fold_features in fold_selected_features[clf_name] \n",
    "                       if feature in fold_features)\n",
    "            feature_votes[feature] = votes\n",
    "        \n",
    "        # Select features with majority vote (>= 3 out of 5 folds)\n",
    "        consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                 if votes >= 3}\n",
    "        \n",
    "        # Fallback: if no features meet majority threshold, use >= 2 votes\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                     if votes >= 2}\n",
    "        \n",
    "        # Final fallback: use union if still empty\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = all_features_for_clf\n",
    "            \n",
    "        classifier_consensus_features[clf_name] = consensus_features_clf\n",
    "        print(f\"{clf_name}: {len(consensus_features_clf)} consensus features\")\n",
    "\n",
    "    # FINAL CONSENSUS: Union of all classifier consensus features\n",
    "    final_consensus_features = set()\n",
    "    for clf_features in classifier_consensus_features.values():\n",
    "        final_consensus_features.update(clf_features)\n",
    "    \n",
    "    # Convert back to indices for final evaluation\n",
    "    consensus_feature_names = list(final_consensus_features)\n",
    "    consensus_indices = [feature_names.index(fname) for fname in consensus_feature_names \n",
    "                        if fname in feature_names]\n",
    "    \n",
    "    print(f\"\\nFinal GWO consensus: {len(consensus_indices)} features\")\n",
    "    print(f\"Consensus features: {consensus_feature_names[:10]}...\" if len(consensus_feature_names) > 10 \n",
    "          else f\"Consensus features: {consensus_feature_names}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 4) Final evaluation on held-out test set (same as PSO/WOA)\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL EVALUATION ON HELD-OUT TEST SET\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if len(consensus_indices) == 0:\n",
    "        print(\"ERROR: No consensus features found. Cannot proceed with final evaluation.\")\n",
    "        return\n",
    "    \n",
    "    # Apply final scaling and consensus feature selection\n",
    "    scaler_final = StandardScaler()\n",
    "    X_trval_scaled = scaler_final.fit_transform(X_temp)\n",
    "    X_test_scaled = scaler_final.transform(X_test_raw)\n",
    "    \n",
    "    # Select consensus features\n",
    "    X_trval_final = X_trval_scaled[:, consensus_indices]\n",
    "    X_test_final = X_test_scaled[:, consensus_indices]\n",
    "    \n",
    "    print(f\"Final training set: {X_trval_final.shape}\")\n",
    "    print(f\"Final test set: {X_test_final.shape}\")\n",
    "\n",
    "    # Final evaluation per classifier (same structure as PSO/WOA)\n",
    "    final_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        print(f\"\\nFinal evaluation: {clf_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Retune on full 80% with consensus features\n",
    "            tuned_clf_final = get_tuned_model(clf, X_trval_final, y_temp)\n",
    "            tuned_clf_final.fit(X_trval_final, y_temp)\n",
    "\n",
    "            # Training performance (80% data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_train_proba = tuned_clf_final.predict_proba(X_trval_final)[:, 1]\n",
    "            else:\n",
    "                y_train_proba = tuned_clf_final.decision_function(X_trval_final)\n",
    "            \n",
    "            y_train_pred = tuned_clf_final.predict(X_trval_final)\n",
    "            train_auc = roc_auc_score(y_temp, y_train_proba)\n",
    "            train_acc = accuracy_score(y_temp, y_train_pred)\n",
    "\n",
    "            # Test performance (20% held-out data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_test_proba = tuned_clf_final.predict_proba(X_test_final)[:, 1]\n",
    "            else:\n",
    "                y_test_proba = tuned_clf_final.decision_function(X_test_final)\n",
    "            \n",
    "            y_test_pred = tuned_clf_final.predict(X_test_final)\n",
    "            test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "            test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "            # Bootstrap confidence intervals\n",
    "            train_mean_auc, train_lower, train_upper, train_valid = bootstrap_final_model_auc_ci(\n",
    "                y_temp, y_train_proba, n_bootstrap=1000\n",
    "            )\n",
    "            \n",
    "            test_mean_auc, test_lower, test_upper, test_valid = bootstrap_final_model_auc_ci(\n",
    "                y_test, y_test_proba, n_bootstrap=1000\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            final_results[clf_name] = {\n",
    "                'train_auc': train_auc,\n",
    "                'train_acc': train_acc,\n",
    "                'test_auc': test_auc,\n",
    "                'test_acc': test_acc,\n",
    "                'train_ci_lower': train_lower,\n",
    "                'train_ci_upper': train_upper,\n",
    "                'test_ci_lower': test_lower,\n",
    "                'test_ci_upper': test_upper\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {clf_name}: {e}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 5) COMPREHENSIVE RESULTS SUMMARY (same as PSO/WOA)\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"GWO PIPELINE COMPREHENSIVE PERFORMANCE SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nDATASET SUMMARY:\")\n",
    "    print(f\"- Total samples: {len(X_raw)} (Train/Val: {len(X_temp)}, Test: {len(X_test_raw)})\")\n",
    "    print(f\"- Original features: {X_raw.shape[1]}\")\n",
    "    print(f\"- GWO consensus features: {len(consensus_indices)}\")\n",
    "    print(f\"- Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%)\")\n",
    "\n",
    "    # Cross-validation performance summary\n",
    "    print(f\"\\nCROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC':<15} {'Val AUC':<15} {'Train Acc':<15} {'Val Acc':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for clf_name, results in classifier_fold_results.items():\n",
    "        if results['train_aucs']:\n",
    "            train_auc_mean = np.mean(results['train_aucs'])\n",
    "            train_auc_std = np.std(results['train_aucs'])\n",
    "            val_auc_mean = np.mean(results['val_aucs'])\n",
    "            val_auc_std = np.std(results['val_aucs'])\n",
    "            train_acc_mean = np.mean(results['train_accs'])\n",
    "            train_acc_std = np.std(results['train_accs'])\n",
    "            val_acc_mean = np.mean(results['val_accs'])\n",
    "            val_acc_std = np.std(results['val_accs'])\n",
    "            \n",
    "            print(f\"{clf_name:<25} {train_auc_mean:.3f}±{train_auc_std:.3f}     \"\n",
    "                  f\"{val_auc_mean:.3f}±{val_auc_std:.3f}     \"\n",
    "                  f\"{train_acc_mean:.3f}±{train_acc_std:.3f}     \"\n",
    "                  f\"{val_acc_mean:.3f}±{val_acc_std:.3f}\")\n",
    "\n",
    "    # Final test performance\n",
    "    print(f\"\\nFINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC [95% CI]':<25} {'Test AUC [95% CI]':<25} {'Test Acc':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for clf_name, results in final_results.items():\n",
    "        train_auc = results['train_auc']\n",
    "        train_lower = results['train_ci_lower']\n",
    "        train_upper = results['train_ci_upper']\n",
    "        test_auc = results['test_auc']\n",
    "        test_lower = results['test_ci_lower']\n",
    "        test_upper = results['test_ci_upper']\n",
    "        test_acc = results['test_acc']\n",
    "\n",
    "        print(f\"{clf_name:<25} {train_auc:.3f} [{train_lower:.3f},{train_upper:.3f}]   \"\n",
    "              f\"{test_auc:.3f} [{test_lower:.3f},{test_upper:.3f}]   {test_acc:.3f}\")\n",
    "\n",
    "    # Best performer\n",
    "    if final_results:\n",
    "        best_clf = max(final_results.keys(), key=lambda x: final_results[x]['test_auc'])\n",
    "        best_test_auc = final_results[best_clf]['test_auc']\n",
    "        best_test_acc = final_results[best_clf]['test_acc']\n",
    "        \n",
    "        print(f\"\\nBest GWO Test Performance: {best_clf}\")\n",
    "        print(f\"Test AUC: {best_test_auc:.4f}, Test Accuracy: {best_test_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"CORRECTED GWO PIPELINE COMPLETE - MATCHES PSO/WOA METHODOLOGY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return final_results, consensus_feature_names, classifier_fold_results\n",
    "\n",
    "\n",
    "# Run the corrected GWO pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    gwo_final_results, gwo_consensus_features, gwo_cv_results = corrected_gwo_main_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === `__main__` integration block with only GWO ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GWO-ONLY RADIOMICS FEATURE SELECTION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Step 1: Loading data and creating train/test split...\n",
      "Initial clinical data: 166 patients\n",
      "Final matched data: 163 patients\n",
      "Dataset: 163 samples, 103 features\n",
      "Class distribution: LRR=55 (33.7%), Non-LRR=108 (66.3%)\n",
      "Training/Validation: 130 samples\n",
      "Test (held-out): 33 samples\n",
      "\n",
      "Step 2: 5-Fold Cross-Validation with GWO-only feature selection...\n",
      "Note: GWO will work on all original features (no LASSO pre-filtering)\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 1/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  LogisticRegression: Train AUC=0.6699, Val AUC=0.8264, Features selected=37\n",
      "\n",
      "Processing GaussianNB with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  GaussianNB: Train AUC=0.7173, Val AUC=0.8333, Features selected=35\n",
      "\n",
      "Processing SVC with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  SVC: Train AUC=0.3207, Val AUC=0.2083, Features selected=22\n",
      "\n",
      "Processing SVC with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  SVC: Train AUC=0.3288, Val AUC=0.1736, Features selected=49\n",
      "\n",
      "Processing DecisionTreeClassifier with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.7845, Val AUC=0.6354, Features selected=25\n",
      "\n",
      "Processing RandomForestClassifier with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9293, Val AUC=0.7292, Features selected=38\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 2/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  LogisticRegression: Train AUC=0.6741, Val AUC=0.7059, Features selected=45\n",
      "\n",
      "Processing GaussianNB with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  GaussianNB: Train AUC=0.7416, Val AUC=0.6797, Features selected=37\n",
      "\n",
      "Processing SVC with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  SVC: Train AUC=0.3180, Val AUC=0.3203, Features selected=37\n",
      "\n",
      "Processing SVC with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  SVC: Train AUC=0.3118, Val AUC=0.3007, Features selected=45\n",
      "\n",
      "Processing DecisionTreeClassifier with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.8112, Val AUC=0.6405, Features selected=40\n",
      "\n",
      "Processing RandomForestClassifier with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9275, Val AUC=0.6275, Features selected=42\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 3/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  LogisticRegression: Train AUC=0.7607, Val AUC=0.4248, Features selected=33\n",
      "\n",
      "Processing GaussianNB with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  GaussianNB: Train AUC=0.7708, Val AUC=0.3856, Features selected=39\n",
      "\n",
      "Processing SVC with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  SVC: Train AUC=0.2513, Val AUC=0.6144, Features selected=45\n",
      "\n",
      "Processing SVC with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  SVC: Train AUC=0.2460, Val AUC=0.5752, Features selected=45\n",
      "\n",
      "Processing DecisionTreeClassifier with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.8754, Val AUC=0.4314, Features selected=22\n",
      "\n",
      "Processing RandomForestClassifier with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9052, Val AUC=0.3529, Features selected=30\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 4/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  LogisticRegression: Train AUC=0.6787, Val AUC=0.7908, Features selected=44\n",
      "\n",
      "Processing GaussianNB with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  GaussianNB: Train AUC=0.6712, Val AUC=0.6732, Features selected=36\n",
      "\n",
      "Processing SVC with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  SVC: Train AUC=0.3106, Val AUC=0.2680, Features selected=18\n",
      "\n",
      "Processing SVC with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  SVC: Train AUC=0.3308, Val AUC=0.2157, Features selected=41\n",
      "\n",
      "Processing DecisionTreeClassifier with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.8704, Val AUC=0.4608, Features selected=32\n",
      "\n",
      "Processing RandomForestClassifier with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9176, Val AUC=0.6993, Features selected=23\n",
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 5/5\n",
      "============================================================\n",
      "Working with ALL 103 original features\n",
      "\n",
      "Processing LogisticRegression with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  LogisticRegression: Train AUC=0.7110, Val AUC=0.5686, Features selected=44\n",
      "\n",
      "Processing GaussianNB with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  GaussianNB: Train AUC=0.6836, Val AUC=0.5556, Features selected=41\n",
      "\n",
      "Processing SVC with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  SVC: Train AUC=0.2886, Val AUC=0.4575, Features selected=25\n",
      "\n",
      "Processing SVC with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  SVC: Train AUC=0.2845, Val AUC=0.4575, Features selected=30\n",
      "\n",
      "Processing DecisionTreeClassifier with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  DecisionTreeClassifier: Train AUC=0.7996, Val AUC=0.5065, Features selected=38\n",
      "\n",
      "Processing RandomForestClassifier with GWO on full feature set...\n",
      "  Running GWO on 103 features...\n",
      "  RandomForestClassifier: Train AUC=0.9118, Val AUC=0.5163, Features selected=31\n",
      "\n",
      "============================================================\n",
      "BUILDING CONSENSUS FEATURES FROM GWO SELECTIONS\n",
      "============================================================\n",
      "LogisticRegression: 31 consensus features\n",
      "GaussianNB: 28 consensus features\n",
      "SVC: 73 consensus features\n",
      "DecisionTreeClassifier: 16 consensus features\n",
      "RandomForestClassifier: 20 consensus features\n",
      "\n",
      "Final GWO consensus: 90 features\n",
      "Consensus features: ['original_glszm_LargeAreaHighGrayLevelEmphasis', 'original_gldm_DependenceNonUniformityNormalized', 'original_glszm_GrayLevelNonUniformityNormalized', 'original_gldm_GrayLevelVariance', 'original_glszm_GrayLevelVariance', 'original_glrlm_GrayLevelNonUniformityNormalized', 'original_glcm_JointEntropy', 'original_firstorder_90Percentile', 'original_glrlm_ShortRunHighGrayLevelEmphasis', 'original_gldm_DependenceEntropy']...\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION ON HELD-OUT TEST SET\n",
      "============================================================\n",
      "Final training set: (130, 90)\n",
      "Final test set: (33, 90)\n",
      "\n",
      "Final evaluation: LogisticRegression\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6960 [0.5901, 0.7910] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6188 [0.3801, 0.8307] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: GaussianNB\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.7249 [0.6287, 0.8099] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6825 [0.4874, 0.8658] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.2830 [0.1903, 0.3811] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3515 [0.1363, 0.5745] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: SVC\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.2830 [0.1903, 0.3811] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.3515 [0.1363, 0.5745] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: DecisionTreeClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.8023 [0.7254, 0.8770] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6618 [0.4648, 0.8306] (valid reps = 1000)\n",
      "\n",
      "Final evaluation: RandomForestClassifier\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.9137 [0.8610, 0.9527] (valid reps = 1000)\n",
      "Bootstrapped 95% CI for Final Model Test AUC: 0.6254 [0.3802, 0.8347] (valid reps = 1000)\n",
      "\n",
      "================================================================================\n",
      "GWO-ONLY PIPELINE PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "DATASET SUMMARY:\n",
      "- Total samples: 163 (Train/Val: 130, Test: 33)\n",
      "- Original features: 103\n",
      "- GWO consensus features: 90\n",
      "- Feature reduction: 103 → 90 (87.4%)\n",
      "- Class distribution: LRR=55 (33.7%)\n",
      "\n",
      "CROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\n",
      "--------------------------------------------------------------------------------\n",
      "Classifier                Train AUC       Val AUC         Train Acc       Val Acc        \n",
      "--------------------------------------------------------------------------------\n",
      "LogisticRegression        0.699±0.034     0.663±0.149     0.688±0.014     0.631±0.093\n",
      "GaussianNB                0.717±0.037     0.625±0.149     0.669±0.084     0.592±0.079\n",
      "SVC                       0.299±0.029     0.359±0.149     0.603±0.143     0.527±0.131\n",
      "DecisionTreeClassifier    0.828±0.037     0.535±0.087     0.769±0.022     0.615±0.064\n",
      "RandomForestClassifier    0.918±0.009     0.585±0.137     0.823±0.023     0.662±0.071\n",
      "\n",
      "FINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Classifier                Train AUC [95% CI]        Test AUC [95% CI]         Test Acc  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "LogisticRegression        0.696 [0.590,0.791]   0.624 [0.380,0.831]   0.727\n",
      "GaussianNB                0.725 [0.629,0.810]   0.686 [0.487,0.866]   0.697\n",
      "SVC                       0.283 [0.190,0.381]   0.347 [0.136,0.574]   0.667\n",
      "DecisionTreeClassifier    0.802 [0.725,0.877]   0.663 [0.465,0.831]   0.606\n",
      "RandomForestClassifier    0.914 [0.861,0.953]   0.628 [0.380,0.835]   0.727\n",
      "\n",
      "Best GWO-Only Performance: GaussianNB\n",
      "Test AUC: 0.6860, Test Accuracy: 0.6970\n",
      "Average features per classifier: 33.6\n",
      "\n",
      "================================================================================\n",
      "GWO-ONLY PIPELINE COMPLETE\n",
      "Compare these results with LASSO+GWO to evaluate the impact of pre-filtering\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# GWO-ONLY MAIN PIPELINE (WITHOUT LASSO)\n",
    "# ==========================================\n",
    "\n",
    "def gwo_only_main_pipeline():\n",
    "    \"\"\"\n",
    "    GWO-ONLY feature selection pipeline (without LASSO pre-filtering).\n",
    "    This version applies GWO directly to all original features for each classifier.\n",
    "    \n",
    "    Pipeline: Raw Data → 80/20 Split → 5-Fold CV → GWO → Consensus → Final Test\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"GWO-ONLY RADIOMICS FEATURE SELECTION PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ===============================================================\n",
    "    # 1) Load data and perform initial 80/20 split\n",
    "    # ===============================================================\n",
    "    print(\"\\nStep 1: Loading data and creating train/test split...\")\n",
    "    \n",
    "    radiomics_data, clinical_data = load_data()\n",
    "    radiomics_cols = get_radiomics_columns(radiomics_data)\n",
    "    X_raw = radiomics_data[radiomics_cols].values\n",
    "    y = clinical_data[\"LocoRegeonalRecurrence\"].values\n",
    "    feature_names = radiomics_data[radiomics_cols].columns.tolist()\n",
    "\n",
    "    print(f\"Dataset: {len(X_raw)} samples, {X_raw.shape[1]} features\")\n",
    "    print(f\"Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%), \"\n",
    "          f\"Non-LRR={len(y)-np.sum(y)} ({100*(len(y)-np.sum(y))/len(y):.1f}%)\")\n",
    "\n",
    "    # Proper 80/20 split with stratification\n",
    "    X_temp, X_test_raw, y_temp, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Training/Validation: {len(X_temp)} samples\")\n",
    "    print(f\"Test (held-out): {len(X_test_raw)} samples\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 2) 5-Fold CV with GWO-only feature selection\n",
    "    # ===============================================================\n",
    "    print(f\"\\nStep 2: 5-Fold Cross-Validation with GWO-only feature selection...\")\n",
    "    print(\"Note: GWO will work on all original features (no LASSO pre-filtering)\")\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define classifiers\n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        GaussianNB(),\n",
    "        SVC(kernel='linear', probability=True),\n",
    "        SVC(kernel='rbf', probability=True),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    ]\n",
    "\n",
    "    # Store selected feature NAMES for proper consensus building\n",
    "    fold_selected_features = {}  # classifier -> [fold_features_sets]\n",
    "    classifier_fold_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        fold_selected_features[clf_name] = []\n",
    "        classifier_fold_results[clf_name] = {\n",
    "            'train_aucs': [], 'val_aucs': [], 'train_accs': [], 'val_accs': []\n",
    "        }\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold_id, (tr_idx, va_idx) in enumerate(skf.split(X_temp, y_temp), 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROCESSING FOLD {fold_id}/5\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        X_tr_raw, X_va_raw = X_temp[tr_idx], X_temp[va_idx]\n",
    "        y_tr, y_va = y_temp[tr_idx], y_temp[va_idx]\n",
    "\n",
    "        # STEP 1: Proper scaling (fit on train, transform both)\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_scaled = scaler.fit_transform(X_tr_raw)\n",
    "        X_va_scaled = scaler.transform(X_va_raw)\n",
    "        \n",
    "        print(f\"Working with ALL {X_tr_scaled.shape[1]} original features\")\n",
    "\n",
    "        # STEP 2: GWO feature selection per classifier (directly on all features)\n",
    "        for clf in classifiers:\n",
    "            clf_name = clf.__class__.__name__\n",
    "            print(f\"\\nProcessing {clf_name} with GWO on full feature set...\")\n",
    "            \n",
    "            try:\n",
    "                # Hyperparameter tuning on full scaled feature set\n",
    "                tuned_clf = get_tuned_model(clf, X_tr_scaled, y_tr)\n",
    "\n",
    "                # GWO feature selection on ALL features (no LASSO pre-filtering)\n",
    "                print(f\"  Running GWO on {X_tr_scaled.shape[1]} features...\")\n",
    "                best_wolf, train_auc_hist, val_auc_hist = run_gwo(\n",
    "                    X_tr_scaled, y_tr, X_va_scaled, y_va, tuned_clf, \n",
    "                    n_wolves=15,  # Slightly more wolves for larger search space\n",
    "                    max_iter=30,  # More iterations for full feature space\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "                # Get GWO-selected feature names\n",
    "                gwo_selected_indices = np.where(best_wolf == 1)[0]\n",
    "                gwo_selected_feature_names = [feature_names[i] for i in gwo_selected_indices]\n",
    "                \n",
    "                # Store selected feature names for this classifier and fold\n",
    "                fold_selected_features[clf_name].append(set(gwo_selected_feature_names))\n",
    "\n",
    "                # Evaluate performance with GWO-selected features\n",
    "                if len(gwo_selected_indices) > 0:\n",
    "                    X_tr_gwo = X_tr_scaled[:, best_wolf == 1]\n",
    "                    X_va_gwo = X_va_scaled[:, best_wolf == 1]\n",
    "                    \n",
    "                    # Train final model and evaluate\n",
    "                    final_model = make_pipeline(StandardScaler(), tuned_clf)\n",
    "                    final_model.fit(X_tr_gwo, y_tr)\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    if hasattr(final_model, 'predict_proba'):\n",
    "                        y_tr_proba = final_model.predict_proba(X_tr_gwo)[:, 1]\n",
    "                        y_va_proba = final_model.predict_proba(X_va_gwo)[:, 1]\n",
    "                    else:\n",
    "                        y_tr_proba = final_model.decision_function(X_tr_gwo)\n",
    "                        y_va_proba = final_model.decision_function(X_va_gwo)\n",
    "                    \n",
    "                    y_tr_pred = final_model.predict(X_tr_gwo)\n",
    "                    y_va_pred = final_model.predict(X_va_gwo)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    train_auc = roc_auc_score(y_tr, y_tr_proba)\n",
    "                    val_auc = roc_auc_score(y_va, y_va_proba)\n",
    "                    train_acc = accuracy_score(y_tr, y_tr_pred)\n",
    "                    val_acc = accuracy_score(y_va, y_va_pred)\n",
    "                    \n",
    "                    # Store results\n",
    "                    classifier_fold_results[clf_name]['train_aucs'].append(train_auc)\n",
    "                    classifier_fold_results[clf_name]['val_aucs'].append(val_auc)\n",
    "                    classifier_fold_results[clf_name]['train_accs'].append(train_acc)\n",
    "                    classifier_fold_results[clf_name]['val_accs'].append(val_acc)\n",
    "                    \n",
    "                    print(f\"  {clf_name}: Train AUC={train_auc:.4f}, Val AUC={val_auc:.4f}, \"\n",
    "                          f\"Features selected={len(gwo_selected_indices)}\")\n",
    "                else:\n",
    "                    print(f\"  Warning: {clf_name} selected no features in fold {fold_id}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {clf_name}: {e}\")\n",
    "                fold_selected_features[clf_name].append(set())\n",
    "\n",
    "    # ===============================================================\n",
    "    # 3) Build consensus features using the same method\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BUILDING CONSENSUS FEATURES FROM GWO SELECTIONS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build consensus per classifier, then combine (same logic as other algorithms)\n",
    "    classifier_consensus_features = {}\n",
    "    \n",
    "    for clf_name in fold_selected_features:\n",
    "        if len(fold_selected_features[clf_name]) == 0:\n",
    "            classifier_consensus_features[clf_name] = set()\n",
    "            continue\n",
    "            \n",
    "        # Get all unique features selected by this classifier across folds\n",
    "        all_features_for_clf = set()\n",
    "        for fold_features in fold_selected_features[clf_name]:\n",
    "            all_features_for_clf.update(fold_features)\n",
    "        \n",
    "        # Count votes for each feature\n",
    "        feature_votes = {}\n",
    "        for feature in all_features_for_clf:\n",
    "            votes = sum(1 for fold_features in fold_selected_features[clf_name] \n",
    "                       if feature in fold_features)\n",
    "            feature_votes[feature] = votes\n",
    "        \n",
    "        # Select features with majority vote (>= 3 out of 5 folds)\n",
    "        consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                 if votes >= 3}\n",
    "        \n",
    "        # Fallback: if no features meet majority threshold, use >= 2 votes\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = {feature for feature, votes in feature_votes.items() \n",
    "                                     if votes >= 2}\n",
    "        \n",
    "        # Final fallback: use union if still empty\n",
    "        if len(consensus_features_clf) == 0:\n",
    "            consensus_features_clf = all_features_for_clf\n",
    "            \n",
    "        classifier_consensus_features[clf_name] = consensus_features_clf\n",
    "        print(f\"{clf_name}: {len(consensus_features_clf)} consensus features\")\n",
    "\n",
    "    # FINAL CONSENSUS: Union of all classifier consensus features\n",
    "    final_consensus_features = set()\n",
    "    for clf_features in classifier_consensus_features.values():\n",
    "        final_consensus_features.update(clf_features)\n",
    "    \n",
    "    # Convert back to indices for final evaluation\n",
    "    consensus_feature_names = list(final_consensus_features)\n",
    "    consensus_indices = [feature_names.index(fname) for fname in consensus_feature_names \n",
    "                        if fname in feature_names]\n",
    "    \n",
    "    print(f\"\\nFinal GWO consensus: {len(consensus_indices)} features\")\n",
    "    print(f\"Consensus features: {consensus_feature_names[:10]}...\" if len(consensus_feature_names) > 10 \n",
    "          else f\"Consensus features: {consensus_feature_names}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 4) Final evaluation on held-out test set\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL EVALUATION ON HELD-OUT TEST SET\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if len(consensus_indices) == 0:\n",
    "        print(\"ERROR: No consensus features found. Cannot proceed with final evaluation.\")\n",
    "        return\n",
    "    \n",
    "    # Apply final scaling and consensus feature selection\n",
    "    scaler_final = StandardScaler()\n",
    "    X_trval_scaled = scaler_final.fit_transform(X_temp)\n",
    "    X_test_scaled = scaler_final.transform(X_test_raw)\n",
    "    \n",
    "    # Select GWO consensus features\n",
    "    X_trval_final = X_trval_scaled[:, consensus_indices]\n",
    "    X_test_final = X_test_scaled[:, consensus_indices]\n",
    "    \n",
    "    print(f\"Final training set: {X_trval_final.shape}\")\n",
    "    print(f\"Final test set: {X_test_final.shape}\")\n",
    "\n",
    "    # Final evaluation per classifier\n",
    "    final_results = {}\n",
    "    \n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        print(f\"\\nFinal evaluation: {clf_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Retune on full 80% with GWO consensus features\n",
    "            tuned_clf_final = get_tuned_model(clf, X_trval_final, y_temp)\n",
    "            tuned_clf_final.fit(X_trval_final, y_temp)\n",
    "\n",
    "            # Training performance (80% data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_train_proba = tuned_clf_final.predict_proba(X_trval_final)[:, 1]\n",
    "            else:\n",
    "                y_train_proba = tuned_clf_final.decision_function(X_trval_final)\n",
    "            \n",
    "            y_train_pred = tuned_clf_final.predict(X_trval_final)\n",
    "            train_auc = roc_auc_score(y_temp, y_train_proba)\n",
    "            train_acc = accuracy_score(y_temp, y_train_pred)\n",
    "\n",
    "            # Test performance (20% held-out data)\n",
    "            if hasattr(tuned_clf_final, \"predict_proba\"):\n",
    "                y_test_proba = tuned_clf_final.predict_proba(X_test_final)[:, 1]\n",
    "            else:\n",
    "                y_test_proba = tuned_clf_final.decision_function(X_test_final)\n",
    "            \n",
    "            y_test_pred = tuned_clf_final.predict(X_test_final)\n",
    "            test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "            test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "            # Bootstrap confidence intervals\n",
    "            train_mean_auc, train_lower, train_upper, train_valid = bootstrap_final_model_auc_ci(\n",
    "                y_temp, y_train_proba, n_bootstrap=1000\n",
    "            )\n",
    "            \n",
    "            test_mean_auc, test_lower, test_upper, test_valid = bootstrap_final_model_auc_ci(\n",
    "                y_test, y_test_proba, n_bootstrap=1000\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            final_results[clf_name] = {\n",
    "                'train_auc': train_auc,\n",
    "                'train_acc': train_acc,\n",
    "                'test_auc': test_auc,\n",
    "                'test_acc': test_acc,\n",
    "                'train_ci_lower': train_lower,\n",
    "                'train_ci_upper': train_upper,\n",
    "                'test_ci_lower': test_lower,\n",
    "                'test_ci_upper': test_upper\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {clf_name}: {e}\")\n",
    "\n",
    "    # ===============================================================\n",
    "    # 5) COMPREHENSIVE RESULTS SUMMARY\n",
    "    # ===============================================================\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"GWO-ONLY PIPELINE PERFORMANCE SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nDATASET SUMMARY:\")\n",
    "    print(f\"- Total samples: {len(X_raw)} (Train/Val: {len(X_temp)}, Test: {len(X_test_raw)})\")\n",
    "    print(f\"- Original features: {X_raw.shape[1]}\")\n",
    "    print(f\"- GWO consensus features: {len(consensus_indices)}\")\n",
    "    print(f\"- Feature reduction: {X_raw.shape[1]} → {len(consensus_indices)} \"\n",
    "          f\"({100*len(consensus_indices)/X_raw.shape[1]:.1f}%)\")\n",
    "    print(f\"- Class distribution: LRR={np.sum(y)} ({100*np.sum(y)/len(y):.1f}%)\")\n",
    "\n",
    "    # Cross-validation performance summary\n",
    "    print(f\"\\nCROSS-VALIDATION PERFORMANCE (5-Fold, Mean ± Std):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC':<15} {'Val AUC':<15} {'Train Acc':<15} {'Val Acc':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for clf_name, results in classifier_fold_results.items():\n",
    "        if results['train_aucs']:\n",
    "            train_auc_mean = np.mean(results['train_aucs'])\n",
    "            train_auc_std = np.std(results['train_aucs'])\n",
    "            val_auc_mean = np.mean(results['val_aucs'])\n",
    "            val_auc_std = np.std(results['val_aucs'])\n",
    "            train_acc_mean = np.mean(results['train_accs'])\n",
    "            train_acc_std = np.std(results['train_accs'])\n",
    "            val_acc_mean = np.mean(results['val_accs'])\n",
    "            val_acc_std = np.std(results['val_accs'])\n",
    "            \n",
    "            print(f\"{clf_name:<25} {train_auc_mean:.3f}±{train_auc_std:.3f}     \"\n",
    "                  f\"{val_auc_mean:.3f}±{val_auc_std:.3f}     \"\n",
    "                  f\"{train_acc_mean:.3f}±{train_acc_std:.3f}     \"\n",
    "                  f\"{val_acc_mean:.3f}±{val_acc_std:.3f}\")\n",
    "\n",
    "    # Final test performance\n",
    "    print(f\"\\nFINAL PERFORMANCE WITH 95% BOOTSTRAP CONFIDENCE INTERVALS:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Classifier':<25} {'Train AUC [95% CI]':<25} {'Test AUC [95% CI]':<25} {'Test Acc':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for clf_name, results in final_results.items():\n",
    "        train_auc = results['train_auc']\n",
    "        train_lower = results['train_ci_lower']\n",
    "        train_upper = results['train_ci_upper']\n",
    "        test_auc = results['test_auc']\n",
    "        test_lower = results['test_ci_lower']\n",
    "        test_upper = results['test_ci_upper']\n",
    "        test_acc = results['test_acc']\n",
    "\n",
    "        print(f\"{clf_name:<25} {train_auc:.3f} [{train_lower:.3f},{train_upper:.3f}]   \"\n",
    "              f\"{test_auc:.3f} [{test_lower:.3f},{test_upper:.3f}]   {test_acc:.3f}\")\n",
    "\n",
    "    # Best performer and comparison insights\n",
    "    if final_results:\n",
    "        best_clf = max(final_results.keys(), key=lambda x: final_results[x]['test_auc'])\n",
    "        best_test_auc = final_results[best_clf]['test_auc']\n",
    "        best_test_acc = final_results[best_clf]['test_acc']\n",
    "        \n",
    "        print(f\"\\nBest GWO-Only Performance: {best_clf}\")\n",
    "        print(f\"Test AUC: {best_test_auc:.4f}, Test Accuracy: {best_test_acc:.4f}\")\n",
    "        \n",
    "        # Calculate average feature reduction\n",
    "        avg_features_per_classifier = np.mean([len(features) for features in classifier_consensus_features.values() if features])\n",
    "        print(f\"Average features per classifier: {avg_features_per_classifier:.1f}\")\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"GWO-ONLY PIPELINE COMPLETE\")\n",
    "    print(\"Compare these results with LASSO+GWO to evaluate the impact of pre-filtering\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return final_results, consensus_feature_names, classifier_fold_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === `__main__` function for LASSO+GWO Vs Only GWO ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPARING LASSO+GWO VS GWO-ONLY APPROACHES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Approach 1: LASSO + GWO\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"APPROACH 1: LASSO + GWO\")\n",
    "    print(\"=\"*50)\n",
    "    lasso_gwo_results, lasso_gwo_features, lasso_gwo_cv = corrected_gwo_main_pipeline()\n",
    "    \n",
    "    # Approach 2: GWO-Only  \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"APPROACH 2: GWO-ONLY\")\n",
    "    print(\"=\"*50)\n",
    "    gwo_only_results, gwo_only_features, gwo_only_cv = gwo_only_main_pipeline()\n",
    "    \n",
    "    # Comparison Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL COMPARISON SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"LASSO+GWO: Selected {len(lasso_gwo_features)} consensus features\")\n",
    "    print(f\"GWO-Only:  Selected {len(gwo_only_features)} consensus features\")\n",
    "    \n",
    "    # Compare best performers\n",
    "    best_lasso_gwo = max(lasso_gwo_results.keys(), key=lambda x: lasso_gwo_results[x]['test_auc'])\n",
    "    best_gwo_only = max(gwo_only_results.keys(), key=lambda x: gwo_only_results[x]['test_auc'])\n",
    "    \n",
    "    print(f\"\\nBest LASSO+GWO: {best_lasso_gwo} (AUC: {lasso_gwo_results[best_lasso_gwo]['test_auc']:.4f})\")\n",
    "    print(f\"Best GWO-Only:  {best_gwo_only} (AUC: {gwo_only_results[best_gwo_only]['test_auc']:.4f})\")\n",
    "    \n",
    "    if lasso_gwo_results[best_lasso_gwo]['test_auc'] > gwo_only_results[best_gwo_only]['test_auc']:\n",
    "        print(\"→ LASSO+GWO outperforms GWO-only\")\n",
    "    else:\n",
    "        print(\"→ GWO-only outperforms LASSO+GWO\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
